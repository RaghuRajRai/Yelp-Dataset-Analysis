{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YelpChi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:923: DeprecationWarning: builtin type EagerTensor has no __module__ attribute\n",
      "  EagerTensor = c_api.TFE_Py_InitEagerTensor(_EagerTensorBase)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "from textblob import TextBlob\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import string\n",
    "from matplotlib import pyplot\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import random\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models.callbacks import PerplexityMetric\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, TimeDistributed, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import optimizers\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "meta = pd.read_csv(r\"E:\\Yelp\\YelpChi\\output_meta_yelpResData_NRYRcleaned.txt\", sep=\" \", header=None)\n",
    "data = pd.read_table(r\"E:\\Yelp\\YelpChi\\output_review_yelpResData_NRYRcleaned.txt\", sep=\"\\\\n\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0                       1                       2  \\\n",
      "0  9/22/2012  GtwU21YOQn-wf4vWRUIx6w  bNYesZ944s6IJVowOnB0iA   \n",
      "1  9/22/2012                 0LpVTc3  TRKxLC3y-ZvP45e5iilMtw   \n",
      "2  9/19/2012           tljtLzf68Fkwf  0EMm8umAqXZzyhxNpL4M9g   \n",
      "3   9/6/2012                     iSN  DlwexC7z88ymAzu45skODw   \n",
      "4   9/9/2012                  Jmwrh7  kW2dk1CWihmh3g7k9N2G8A   \n",
      "\n",
      "                        3  4  5  6  7  8  \n",
      "0  pbEiXam9YJL3neCYHGwLUA  N  0  0  0  5  \n",
      "1  pbEiXam9YJL3neCYHGwLUA  N  0  0  0  5  \n",
      "2  pbEiXam9YJL3neCYHGwLUA  N  0  0  2  3  \n",
      "3  pbEiXam9YJL3neCYHGwLUA  N  3  0  8  3  \n",
      "4  pbEiXam9YJL3neCYHGwLUA  N  0  2  1  5  \n",
      "                                                   0\n",
      "0  Unlike Next, which we'd eaten at the previous ...\n",
      "1  Probably one of the best meals I've had ever. ...\n",
      "2  Service was impeccable. Experience and present...\n",
      "3  The problem with places like this, given the e...\n",
      "4  I have no idea how to write my review - dining...\n",
      "(61541, 9) (61541, 1)\n"
     ]
    }
   ],
   "source": [
    "print(meta.head())\n",
    "print(data.head())\n",
    "print(meta.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame()\n",
    "data1[0] = data[0]\n",
    "data1[1] = meta[4]\n",
    "data1[2] = meta[8]\n",
    "data = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0  1  2\n",
      "0  Unlike Next, which we'd eaten at the previous ...  N  5\n",
      "1  Probably one of the best meals I've had ever. ...  N  5\n",
      "2  Service was impeccable. Experience and present...  N  3\n",
      "3  The problem with places like this, given the e...  N  3\n",
      "4  I have no idea how to write my review - dining...  N  5 \n",
      " (61541, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.head(),\"\\n\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(charac):\n",
    "    if charac==\"N\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "data[1] = data[1].apply(lambda c: binarize(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Real, 1: Fake\n",
      "\n",
      " 0    53400\n",
      "1     8141\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"0: Real, 1: Fake\\n\\n\", data[1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2366eb63a79f4928b8cd5fe67f368178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61541), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unlike Next, which we'd eaten at the previous ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably one of the best meals I've had ever. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Service was impeccable. Experience and present...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The problem with places like this, given the e...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have no idea how to write my review - dining...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count\n",
       "0  Unlike Next, which we'd eaten at the previous ...  0  5         871\n",
       "1  Probably one of the best meals I've had ever. ...  0  5          66\n",
       "2  Service was impeccable. Experience and present...  0  3          45\n",
       "3  The problem with places like this, given the e...  0  3         358\n",
       "4  I have no idea how to write my review - dining...  0  5         172"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word Count\n",
    "data['word_count'] = data[0].progress_apply(lambda st: len(str(st).split()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cc7f5ee6ee44ec18a82d907b1702743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61541), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unlike Next, which we'd eaten at the previous ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>871</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably one of the best meals I've had ever. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Service was impeccable. Experience and present...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The problem with places like this, given the e...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have no idea how to write my review - dining...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  Unlike Next, which we'd eaten at the previous ...  0  5         871   \n",
       "1  Probably one of the best meals I've had ever. ...  0  5          66   \n",
       "2  Service was impeccable. Experience and present...  0  3          45   \n",
       "3  The problem with places like this, given the e...  0  3         358   \n",
       "4  I have no idea how to write my review - dining...  0  5         172   \n",
       "\n",
       "   deviation  \n",
       "0         17  \n",
       "1          0  \n",
       "2          1  \n",
       "3         12  \n",
       "4          4  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentimental Deviation\n",
    "pos_words = pd.read_table(r\"C:\\Users\\elonm\\Desktop\\Yelp-Dataset-Analysis-master\\poswords.txt\", header=None)\n",
    "neg_words = pd.read_table(r\"C:\\Users\\elonm\\Desktop\\Yelp-Dataset-Analysis-master\\negwords.txt\", header=None)\n",
    "\n",
    "def sentimental_deviation(txt):\n",
    "    dev = 0\n",
    "    flag = 0\n",
    "    for word in txt.split():\n",
    "        for pos in pos_words[0]:\n",
    "            if pos == word.lower():\n",
    "                if flag == -1:\n",
    "                    dev = dev+1\n",
    "                flag = 1\n",
    "                #print(word, dev, flag)\n",
    "        for neg in neg_words[0]:\n",
    "            if neg == word.lower():\n",
    "                if flag == 1:\n",
    "                    dev = dev+1\n",
    "                flag = -1\n",
    "                #print(word, dev, flag)\n",
    "    return dev\n",
    "\n",
    "data['deviation'] = data[0].progress_apply(lambda txt: sentimental_deviation(str((txt))))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r\"E:\\Yelp\\YelpChi\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4f90a37cb541f7aa7e2a023863aa21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61541), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unlike Next, which we'd eaten at the previous ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>871</td>\n",
       "      <td>17</td>\n",
       "      <td>0.163124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably one of the best meals I've had ever. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Service was impeccable. Experience and present...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The problem with places like this, given the e...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "      <td>12</td>\n",
       "      <td>0.131882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have no idea how to write my review - dining...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>4</td>\n",
       "      <td>0.161696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  Unlike Next, which we'd eaten at the previous ...  0  5         871   \n",
       "1  Probably one of the best meals I've had ever. ...  0  5          66   \n",
       "2  Service was impeccable. Experience and present...  0  3          45   \n",
       "3  The problem with places like this, given the e...  0  3         358   \n",
       "4  I have no idea how to write my review - dining...  0  5         172   \n",
       "\n",
       "   deviation  polarity  \n",
       "0         17  0.163124  \n",
       "1          0  0.471429  \n",
       "2          1  0.413333  \n",
       "3         12  0.131882  \n",
       "4          4  0.161696  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentiment Polarity\n",
    "data['polarity'] = data[0].progress_apply(lambda txt: TextBlob(str(txt)).sentiment.polarity)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf5a5d94bf5456694d1bbe2f8c28ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61541), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c05224a40d4561aa78de0ec65089aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61541), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pos_word_count</th>\n",
       "      <th>neg_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unlike Next, which we'd eaten at the previous ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>871</td>\n",
       "      <td>17</td>\n",
       "      <td>0.163124</td>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably one of the best meals I've had ever. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Service was impeccable. Experience and present...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The problem with places like this, given the e...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "      <td>12</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have no idea how to write my review - dining...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>4</td>\n",
       "      <td>0.161696</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  Unlike Next, which we'd eaten at the previous ...  0  5         871   \n",
       "1  Probably one of the best meals I've had ever. ...  0  5          66   \n",
       "2  Service was impeccable. Experience and present...  0  3          45   \n",
       "3  The problem with places like this, given the e...  0  3         358   \n",
       "4  I have no idea how to write my review - dining...  0  5         172   \n",
       "\n",
       "   deviation  polarity  pos_word_count  neg_word_count  \n",
       "0         17  0.163124              56              64  \n",
       "1          0  0.471429               3               2  \n",
       "2          1  0.413333               6               5  \n",
       "3         12  0.131882              26              39  \n",
       "4          4  0.161696              11              18  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Positive Negative word count\n",
    "def count_sentiment_pos(sentence):\n",
    "    count = 0\n",
    "    for word in sentence.split():\n",
    "        for sent_word in pos_words[0]:\n",
    "            if sent_word in word:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def count_sentiment_neg(sentence):\n",
    "    count = 0\n",
    "    for word in sentence.split():\n",
    "        for sent_word in neg_words[0]:\n",
    "            if sent_word in word:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "data['pos_word_count'] = data[0].progress_apply(lambda txt: count_sentiment_pos(str(txt)))\n",
    "data['neg_word_count'] = data[0].progress_apply(lambda txt: count_sentiment_neg(str(txt)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pos_word_count</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>count_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unlike Next, which we'd eaten at the previous ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>871</td>\n",
       "      <td>17</td>\n",
       "      <td>0.163124</td>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably one of the best meals I've had ever. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Service was impeccable. Experience and present...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The problem with places like this, given the e...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "      <td>12</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have no idea how to write my review - dining...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>4</td>\n",
       "      <td>0.161696</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  Unlike Next, which we'd eaten at the previous ...  0  5         871   \n",
       "1  Probably one of the best meals I've had ever. ...  0  5          66   \n",
       "2  Service was impeccable. Experience and present...  0  3          45   \n",
       "3  The problem with places like this, given the e...  0  3         358   \n",
       "4  I have no idea how to write my review - dining...  0  5         172   \n",
       "\n",
       "   deviation  polarity  pos_word_count  neg_word_count  count_sentiment  \n",
       "0         17  0.163124              56              64              120  \n",
       "1          0  0.471429               3               2                5  \n",
       "2          1  0.413333               6               5               11  \n",
       "3         12  0.131882              26              39               65  \n",
       "4          4  0.161696              11              18               29  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['count_sentiment'] = data['pos_word_count'] + data['neg_word_count']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a checkpoint\n",
    "data.to_csv(r\"E:\\Yelp\\YelpChi\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pos_word_count</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>count_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unlike Next, which we'd eaten at the previous ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>871</td>\n",
       "      <td>17</td>\n",
       "      <td>0.163124</td>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Probably one of the best meals I've had ever. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Service was impeccable. Experience and present...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The problem with places like this, given the e...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "      <td>12</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have no idea how to write my review - dining...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>4</td>\n",
       "      <td>0.161696</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  Unlike Next, which we'd eaten at the previous ...  0  5         871   \n",
       "1  Probably one of the best meals I've had ever. ...  0  5          66   \n",
       "2  Service was impeccable. Experience and present...  0  3          45   \n",
       "3  The problem with places like this, given the e...  0  3         358   \n",
       "4  I have no idea how to write my review - dining...  0  5         172   \n",
       "\n",
       "   deviation  polarity  pos_word_count  neg_word_count  count_sentiment  \n",
       "0         17  0.163124              56              64              120  \n",
       "1          0  0.471429               3               2                5  \n",
       "2          1  0.413333               6               5               11  \n",
       "3         12  0.131882              26              39               65  \n",
       "4          4  0.161696              11              18               29  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb37976072948dbaeace1028980aed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61541), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pos_word_count</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>count_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unlike next which wed eaten at the previous ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>871</td>\n",
       "      <td>17</td>\n",
       "      <td>0.163124</td>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probably one of the best meals ive had ever it...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service was impeccable experience and presenta...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the problem with places like this given the ex...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "      <td>12</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have no idea how to write my review dining a...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>4</td>\n",
       "      <td>0.161696</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  unlike next which wed eaten at the previous ni...  0  5         871   \n",
       "1  probably one of the best meals ive had ever it...  0  5          66   \n",
       "2  service was impeccable experience and presenta...  0  3          45   \n",
       "3  the problem with places like this given the ex...  0  3         358   \n",
       "4  i have no idea how to write my review dining a...  0  5         172   \n",
       "\n",
       "   deviation  polarity  pos_word_count  neg_word_count  count_sentiment  \n",
       "0         17  0.163124              56              64              120  \n",
       "1          0  0.471429               3               2                5  \n",
       "2          1  0.413333               6               5               11  \n",
       "3         12  0.131882              26              39               65  \n",
       "4          4  0.161696              11              18               29  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    trans = str.maketrans('', '', string.punctuation)\n",
    "    words = text.split()\n",
    "    stripped = [word.translate(trans) for word in words]\n",
    "    a = [x for x in stripped if x!=\"\"]\n",
    "    b = [word.lower() for word in a]\n",
    "    b = ' '.join(b)\n",
    "    return b\n",
    "\n",
    "data[0] = data[0].progress_apply(lambda text: clean_text(text))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a38833ab0e4e739f51679aaa87d9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61541), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Stemming/Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#print(lemmatizer.lemmatize(\"going\"))\n",
    "\n",
    "def nltk2wn_tag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    wn_tagged = map(lambda x: (x[0], nltk2wn_tag(x[1])), nltk_tagged)\n",
    "\n",
    "    res_words = []\n",
    "    for word, tag in wn_tagged:\n",
    "        if tag is None:            \n",
    "            res_words.append(word)\n",
    "        else:\n",
    "            res_words.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(res_words)\n",
    "\n",
    "# test =  \"You better lose yourself in the music, the moment You own it, you better never let it go You only get one shot, do not miss your chance to blow This opportunity comes once in a lifetime\"\n",
    "# print(lemmatize_sentence(test))\n",
    "\n",
    "data[0] = data[0].progress_apply(lambda text: lemmatize_sentence(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pos_word_count</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>count_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unlike next which wed eaten at the previous ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>871</td>\n",
       "      <td>17</td>\n",
       "      <td>0.163124</td>\n",
       "      <td>56</td>\n",
       "      <td>64</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>probably one of the best meal ive have ever it...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service be impeccable experience and presentat...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the problem with place like this give the exho...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>358</td>\n",
       "      <td>12</td>\n",
       "      <td>0.131882</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i have no idea how to write my review din at a...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>172</td>\n",
       "      <td>4</td>\n",
       "      <td>0.161696</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  unlike next which wed eaten at the previous ni...  0  5         871   \n",
       "1  probably one of the best meal ive have ever it...  0  5          66   \n",
       "2  service be impeccable experience and presentat...  0  3          45   \n",
       "3  the problem with place like this give the exho...  0  3         358   \n",
       "4  i have no idea how to write my review din at a...  0  5         172   \n",
       "\n",
       "   deviation  polarity  pos_word_count  neg_word_count  count_sentiment  \n",
       "0         17  0.163124              56              64              120  \n",
       "1          0  0.471429               3               2                5  \n",
       "2          1  0.413333               6               5               11  \n",
       "3         12  0.131882              26              39               65  \n",
       "4          4  0.161696              11              18               29  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_csv(r\"E:\\Yelp\\YelpChi\\data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46155, 8) (15386, 8)\n",
      "0    13340\n",
      "1     2046\n",
      "Name: 1, dtype: int64 0    40060\n",
      "1     6095\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Creating a train test split for the final processing\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[[0, 2, 'word_count', 'deviation', 'polarity', 'count_sentiment', 'pos_word_count', 'neg_word_count']], data[1], test_size=0.25, random_state=42)\n",
    "X_train.to_csv(r\"E:\\Yelp\\YelpChi\\X_train\")\n",
    "X_test.to_csv(r\"E:\\Yelp\\YelpChi\\X_test\")\n",
    "y_train.to_csv(r\"E:\\Yelp\\YelpChi\\y_train\")\n",
    "y_test.to_csv(r\"E:\\Yelp\\YelpChi\\y_test\")\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_test.value_counts(), y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[[2, 'word_count', 'deviation', 'polarity', 'count_sentiment', 'pos_word_count', 'neg_word_count']]\n",
    "X_test = X_test[[2, 'word_count', 'deviation', 'polarity', 'count_sentiment', 'pos_word_count', 'neg_word_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "svm_clf = svm.SVC(kernel='sigmoid', gamma='auto', verbose=True)\n",
    "svm_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elonm\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     13340\n",
      "           1       0.00      0.00      0.00      2046\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     15386\n",
      "   macro avg       0.43      0.50      0.46     15386\n",
      "weighted avg       0.75      0.87      0.81     15386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGB\n",
    "xgb_model = XGBClassifier(learning_rate = 0.2, objective= 'binary:logistic')\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     13340\n",
      "           1       0.27      0.00      0.00      2046\n",
      "\n",
      "   micro avg       0.87      0.87      0.87     15386\n",
      "   macro avg       0.57      0.50      0.47     15386\n",
      "weighted avg       0.79      0.87      0.81     15386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "y_pred = [round(value) for value in y_pred]\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12816691 0.25186288 0.07153502 0.2637854  0.07898659 0.07898659\n",
      " 0.1266766 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(xgb_model.feature_importances_)\n",
    "# plot\n",
    "pyplot.bar(range(len(xgb_model.feature_importances_)), xgb_model.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.to_csv(r\"E:\\Yelp\\YelpChi\\res_features.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46155, 9) (15386, 2) (46155, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(r\"E:\\Yelp\\YelpChi\\X_train\")\n",
    "X_test = pd.read_csv(r\"E:\\Yelp\\YelpChi\\X_test\")\n",
    "y_train = pd.read_csv(r\"E:\\Yelp\\YelpChi\\y_train\", header=None)\n",
    "y_test = pd.read_csv(r\"E:\\Yelp\\YelpChi\\y_test\", header=None)\n",
    "print(X_train.shape, y_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['0']\n",
    "X_test = X_test['0']\n",
    "y_train = y_train[1]\n",
    "y_test = y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', '0', '1', '2', 'word_count', 'deviation', 'polarity',\n",
       "       'pos_word_count', 'neg_word_count', 'count_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"E:\\Yelp\\YelpChi\\data.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: (53400, 10) Fake: (8141, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    #Getting tokens from text\n",
    "    tokens = []\n",
    "    text_split = text.split()\n",
    "    for token in text_split:\n",
    "        tokens.append(token)\n",
    "    #Removing stop words from the list of tokens\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    return tokens\n",
    "\n",
    "real = data[data['1'] == 0]\n",
    "fake = data[data['1'] == 1]\n",
    "print(\"Real:\",real.shape,\"Fake:\",fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411e0601ba7347e899f58cae5f1263a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61541), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Converting all our text to a list of preprocessed tokens\n",
    "review_data = []\n",
    "pbar = tqdm_notebook(total=data.shape[0])\n",
    "for text in data['1']:\n",
    "    tokens = preprocess_text(str(text))\n",
    "    review_data.append(tokens)\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53400 8141\n"
     ]
    }
   ],
   "source": [
    "#Separating real and fake reviews in different lists\n",
    "real = []\n",
    "fake = []\n",
    "\n",
    "for i in range(len(review_data)):\n",
    "    if data['1'][i] == 0:\n",
    "        real.append(review_data[i])\n",
    "    else:\n",
    "        fake.append(review_data[i])\n",
    "\n",
    "print(len(real), len(fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46155\n"
     ]
    }
   ],
   "source": [
    "rangex = X_train.shape[0]\n",
    "print(rangex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_indexes = []\n",
    "fake_indexes = []\n",
    "real_train = []\n",
    "fake_train = []\n",
    "\n",
    "for i in range(rangex):\n",
    "    if y_train[i] == 0:\n",
    "        real_train.append(X_train[i])\n",
    "    else:\n",
    "        fake_train.append(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696f42db8a3d45ae9c89e3fae6e0aeed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61541), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34b481856d24662b17259fea1b535a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61541), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "real_t = []\n",
    "fake_t = []\n",
    "pbar = tqdm_notebook(total=data.shape[0])\n",
    "for text in real_train:\n",
    "    tokens = preprocess_text(str(text))\n",
    "    real_t.append(tokens)\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "real_train = real_t\n",
    "\n",
    "pbar = tqdm_notebook(total=data.shape[0])\n",
    "for text in fake_train:\n",
    "    tokens = preprocess_text(str(text))\n",
    "    fake_t.append(tokens)\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "fake_train = fake_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of token: ['thing', 'keep', 'mind', 'place', 'busy', 'neighborhood', 'locate', 'grow', 'size', 'popularity', 'youre', 'wait', 'show', 'ive', 'pleasure', 'eat', 'lunch', 'breakfast', 'impression', 'breakfast', 'place', 'first', 'lunch', 'place', 'second', 'evidence', 'name', 'establishment', 'say', 'lunch', 'sandwich', 'hearty', 'portion', 'tasty', 'youll', 'readily', 'notice', 'traffic', 'less', 'morning', 'shift', 'worth', 'decent', 'change', 'pace', 'mood', 'entire', 'place', 'comparison', 'morning', 'seem', 'bit', 'deflated', 'lax', 'say', 'bad', 'thing', 'im', 'firm', 'belief', 'change', 'meal', 'dictate', 'equal', 'change', 'mood', 'pace', 'place', 'seem', 'mirror', 'morning', 'chaos', 'youre', 'look', 'quiet', 'meal', 'sit', 'alone', 'corner', 'pour', 'crossword', 'puzzle', 'yolk', 'would', 'first', 'choice', 'place', 'busy', 'youre', 'go', 'get', 'people', 'mob', 'waiting', 'room', 'everyone', 'either', 'busy', 'try', 'get', 'wait', 'list', 'try', 'deduce', 'turn', 'sort', 'bill', 'escape', 'craziness', 'inside', 'food', 'im', 'pretty', 'basic', 'breakfast', 'kind', 'guy', 'dont', 'require', 'fancy', 'omelet', 'special', 'pancake', 'crazy', 'juice', 'im', 'scrambled', 'eggs', 'sausage', 'link', 'toast', 'orange', 'juice', 'man', 'easy', 'straight', 'point', 'yolk', 'indeed', 'cater', 'people', 'require', 'attention', 'breakfast', 'im', 'happy', 'report', 'make', 'decent', 'meal', 'taste', 'well', 'really', 'hard', 'mess', 'scramble', 'egg', 'toast', 'sausage', 'link', 'oj', 'drink', 'people', 'misguided', 'exnfl', 'great', 'admittedly', 'place', 'bit', 'high', 'end', 'term', 'price', 'simple', 'meal', 'mine', 'dismiss', 'place', 'expensive', 'would', 'shame', 'incomplete', 'fully', 'understand', 'cheap', 'alternative', 'exist', 'certainly', 'make', 'meal', 'home', 'fraction', 'time', 'cost', 'seriously', 'doubt', 'atmosphere', 'breakfast', 'yolk', 'duplicate', 'morning', 'rush', 'experience', 'fully', 'understood', 'appreciate', 'people', 'would', 'blanch', 'understandable', 'youre', 'one', 'belief', 'breakfast', 'enjoy', 'peace', 'w', 'much', 'breathing', 'room', 'possible', 'may', 'want', 'reconsider', 'yolk', 'breakfast', 'option', 'come', 'back', 'lunch', 'however', 'enjoy', 'people', 'nearby', 'dont', 'mind', 'occasional', 'side', 'conversation', 'pervade', 'meal', 'eat', 'definitely'] || ['good', 'dawg', 'burger', 'ooo', 'good']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample of token:\",real_train[2], \"||\",fake_train[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = []\n",
    "for i in real_train:\n",
    "    review_data.append(i)\n",
    "for i in fake_train:\n",
    "    review_data.append(i)\n",
    "#Creating dictionary of our data using Gensim and saving \n",
    "dictionary = corpora.Dictionary(review_data)\n",
    "dictionary.save('dictionary.gensim')\n",
    "\n",
    "#For saving corpus, use:\n",
    "#pickle.dump(corpus, open('corpus.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.019*\"fry\" + 0.018*\"hot\" + 0.015*\"dog\" + 0.014*\"burger\" + 0.014*\"beer\" + 0.013*\"duck\" + 0.013*\"get\"')\n",
      "(1, '0.034*\"pizza\" + 0.015*\"good\" + 0.012*\"get\" + 0.010*\"place\" + 0.009*\"dish\" + 0.009*\"order\" + 0.009*\"chicken\"')\n",
      "(2, '0.012*\"get\" + 0.012*\"go\" + 0.010*\"food\" + 0.009*\"place\" + 0.009*\"us\" + 0.009*\"table\" + 0.008*\"like\"')\n",
      "(3, '0.009*\"dish\" + 0.009*\"good\" + 0.008*\"order\" + 0.008*\"pork\" + 0.008*\"like\" + 0.007*\"salad\" + 0.007*\"cheese\"')\n",
      "(4, '0.024*\"place\" + 0.023*\"great\" + 0.021*\"food\" + 0.021*\"good\" + 0.016*\"go\" + 0.011*\"love\" + 0.011*\"get\"')\n",
      "(0, '0.003*\"ear\" + 0.003*\"play\" + 0.003*\"concert\" + 0.002*\"screen\" + 0.002*\"level\" + 0.002*\"lockdown\" + 0.002*\"pain\"')\n",
      "(1, '0.002*\"trade\" + 0.002*\"whoopercheesie\" + 0.002*\"approve\" + 0.001*\"cory\" + 0.001*\"reservationgo\" + 0.001*\"unbelieve\" + 0.001*\"uphttpforksandcorkschicagocom20110114schwachicagostinypieceofculinaryheaven\"')\n",
      "(2, '0.022*\"great\" + 0.017*\"food\" + 0.013*\"good\" + 0.012*\"love\" + 0.010*\"place\" + 0.009*\"always\" + 0.007*\"restaurant\"')\n",
      "(3, '0.012*\"course\" + 0.007*\"dessert\" + 0.005*\"fondue\" + 0.005*\"cake\" + 0.005*\"chocolate\" + 0.004*\"wine\" + 0.004*\"gejas\"')\n",
      "(4, '0.014*\"go\" + 0.013*\"place\" + 0.012*\"food\" + 0.011*\"get\" + 0.011*\"good\" + 0.010*\"time\" + 0.008*\"one\"')\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 5\n",
    "\n",
    "#Getting 5 topics from real_train\n",
    "real_corpus = [dictionary.doc2bow(text) for text in real_train]\n",
    "perplexity1 = PerplexityMetric(corpus=real_corpus)\n",
    "real_model = gensim.models.ldamodel.LdaModel(real_corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=20, eval_every=1000)\n",
    "real_topics = real_model.print_topics(num_words=7)\n",
    "for topic in real_topics:\n",
    "    print(topic)\n",
    "\n",
    "#Getting 5 topics from fake_train\n",
    "fake_corpus = [dictionary.doc2bow(text) for text in fake_train]\n",
    "perplexity2 = PerplexityMetric(corpus=fake_corpus)\n",
    "fake_model = gensim.models.ldamodel.LdaModel(fake_corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=20, eval_every=1000)\n",
    "fake_topics = fake_model.print_topics(num_words=7)\n",
    "for topic in fake_topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1648818661773835445362739816\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1648818661773835445362739816_data = {\"mdsDat\": {\"x\": [-0.22388301697241111, -0.011214704060948747, 0.056461206107451596, 0.10268418005569532, 0.0759523348702131], \"y\": [-0.007382756009387615, -0.05080841111448172, 0.13154934784788005, -0.15256652466115864, 0.07920834393714798], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [6.788346767425537, 11.272130966186523, 37.3947868347168, 22.557371139526367, 21.987361907958984]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [11367.0, 30962.0, 6135.0, 21857.0, 5382.0, 29296.0, 34203.0, 6240.0, 14998.0, 3075.0, 10902.0, 7136.0, 28784.0, 30036.0, 2904.0, 3267.0, 5087.0, 8597.0, 3808.0, 13407.0, 5459.0, 7379.0, 8848.0, 2822.0, 5040.0, 13206.0, 11195.0, 9929.0, 2424.0, 5843.0, 3075.0078125, 2903.474853515625, 1623.86865234375, 1424.2305908203125, 678.9564819335938, 434.37286376953125, 350.62933349609375, 248.49172973632812, 237.00064086914062, 201.55381774902344, 195.96836853027344, 193.0474853515625, 189.6116943359375, 188.20045471191406, 188.33853149414062, 185.3933563232422, 176.34097290039062, 175.81871032714844, 173.2318572998047, 156.25222778320312, 156.15728759765625, 154.9465789794922, 148.44247436523438, 130.98211669921875, 125.31592559814453, 122.8692398071289, 119.72575378417969, 117.41395568847656, 114.98762512207031, 113.3923110961914, 113.72966766357422, 784.9767456054688, 2674.500732421875, 681.4698486328125, 3607.980712890625, 236.65036010742188, 2571.57666015625, 3850.944580078125, 469.8768310546875, 307.24896240234375, 2753.567626953125, 2261.854736328125, 323.7919006347656, 305.5578308105469, 349.8177185058594, 445.3128662109375, 726.09716796875, 1494.151123046875, 1976.60302734375, 1071.1787109375, 2672.2548828125, 1029.3304443359375, 1313.524658203125, 2112.95556640625, 2043.9097900390625, 1682.18701171875, 1151.64208984375, 826.7572021484375, 1120.118896484375, 1556.287109375, 1039.8822021484375, 1128.8914794921875, 943.9405517578125, 1054.7705078125, 960.1053466796875, 936.3092651367188, 910.6597290039062, 840.2528076171875, 11366.3671875, 1697.219970703125, 1396.5732421875, 1087.7503662109375, 920.108154296875, 857.407470703125, 839.4071044921875, 830.5982666015625, 708.0114135742188, 697.4365234375, 652.5162353515625, 634.0499877929688, 595.2426147460938, 522.7327270507812, 504.98583984375, 497.0231628417969, 472.68707275390625, 454.39666748046875, 397.0679016113281, 387.128173828125, 412.2502746582031, 371.28167724609375, 365.6049499511719, 334.4272766113281, 324.0402526855469, 271.2235412597656, 244.49887084960938, 226.63259887695312, 224.38768005371094, 200.80496215820312, 2324.18798828125, 2678.21875, 944.5302124023438, 1141.283203125, 707.6927490234375, 982.6321411132812, 1028.19873046875, 1022.0380249023438, 2897.1630859375, 2822.238037109375, 3029.594970703125, 2451.731201171875, 5139.5322265625, 2364.486083984375, 4130.7587890625, 2740.736572265625, 3016.078369140625, 2045.7470703125, 2224.307373046875, 3301.758544921875, 2867.18212890625, 2505.907958984375, 1715.3023681640625, 1933.8262939453125, 1940.1954345703125, 1639.684326171875, 1840.9984130859375, 1660.6990966796875, 1476.7022705078125, 1454.3544921875, 1700.951904296875, 1550.2763671875, 1519.8001708984375, 1436.5064697265625, 1158.31884765625, 953.1305541992188, 846.846923828125, 717.5209350585938, 675.2592163085938, 649.6365356445312, 644.9007568359375, 615.7515869140625, 571.4407958984375, 512.344970703125, 490.8363037109375, 478.217529296875, 390.530517578125, 376.90936279296875, 367.3757629394531, 360.063720703125, 346.4189453125, 330.64935302734375, 326.5976867675781, 321.8559265136719, 300.1523132324219, 337.4175109863281, 265.03338623046875, 261.7462158203125, 256.4390563964844, 257.6504821777344, 249.8466033935547, 246.0833282470703, 244.91883850097656, 245.681884765625, 763.8895874023438, 300.89276123046875, 443.53912353515625, 589.3842163085938, 2422.7919921875, 824.3607177734375, 1243.924072265625, 909.8515625, 9832.4931640625, 541.6622314453125, 4012.65234375, 868.7743530273438, 1203.29736328125, 9747.8203125, 4327.65087890625, 4405.21240234375, 2883.279296875, 726.354736328125, 642.4473266601562, 4227.03515625, 1005.1981201171875, 1456.2952880859375, 5564.86376953125, 4556.5283203125, 5923.193359375, 1100.9508056640625, 2137.080322265625, 2080.130615234375, 5675.8544921875, 3733.468017578125, 2043.010009765625, 6752.93505859375, 2930.7197265625, 3280.55615234375, 5165.02783203125, 7203.29833984375, 5156.88525390625, 3154.284423828125, 8451.92578125, 7951.30126953125, 13710.25390625, 3771.63671875, 5078.70361328125, 13596.208984375, 5839.27392578125, 4784.4970703125, 8737.2421875, 8184.365234375, 11620.9052734375, 5339.91162109375, 7177.56201171875, 7567.88818359375, 9274.8203125, 5816.57958984375, 10494.2294921875, 7865.45654296875, 6314.06005859375, 5869.712890625, 6350.8984375, 5580.40576171875, 7455.6474609375, 5183.4921875, 1479.41845703125, 1265.1982421875, 1077.5091552734375, 1024.6778564453125, 1023.023193359375, 1019.4208984375, 940.876708984375, 799.32421875, 729.6382446289062, 662.8368530273438, 607.8786010742188, 601.0238037109375, 593.456787109375, 547.84814453125, 530.0774536132812, 528.6104125976562, 497.6923828125, 485.09783935546875, 484.77508544921875, 445.0567932128906, 424.0992736816406, 414.3554382324219, 400.4281311035156, 382.4580078125, 360.830322265625, 357.45782470703125, 355.7777099609375, 352.2253723144531, 336.1109619140625, 325.8794250488281, 1012.4207763671875, 5057.4833984375, 1040.761962890625, 587.2407836914062, 1273.987548828125, 903.2000122070312, 1174.036865234375, 3153.03857421875, 4638.447265625, 1880.705078125, 3836.486328125, 1478.296142578125, 2351.657470703125, 1169.6527099609375, 2584.101318359375, 990.4688720703125, 2735.279052734375, 3698.16943359375, 4430.82177734375, 1339.2843017578125, 2862.5615234375, 6087.4580078125, 2185.861328125, 2329.406005859375, 4135.9873046875, 1916.4781494140625, 4473.2841796875, 1708.4658203125, 4125.0380859375, 2011.5933837890625, 3612.406982421875, 2310.344482421875, 1908.1783447265625, 3346.934326171875, 2554.78271484375, 5205.212890625, 3300.796142578125, 6033.1591796875, 5056.81005859375, 3324.093017578125, 2304.620361328125, 3459.661376953125, 3051.612548828125, 3170.525390625, 2711.388427734375, 2407.96435546875, 2835.665771484375, 3030.09521484375, 2595.7109375, 2810.974365234375, 2899.290771484375, 2523.35009765625, 2484.625732421875, 941.5418701171875, 703.6376342773438, 650.411376953125, 529.855224609375, 509.2573547363281, 495.28765869140625, 459.77874755859375, 438.0135192871094, 371.0186462402344, 340.9327697753906, 320.9956970214844, 309.0346374511719, 305.51788330078125, 277.31414794921875, 265.7091369628906, 262.72857666015625, 246.9117431640625, 240.0397491455078, 234.90164184570312, 228.0586700439453, 317.8518371582031, 222.20928955078125, 199.79441833496094, 194.0311737060547, 190.30908203125, 185.00399780273438, 209.28445434570312, 909.3768920898438, 219.17811584472656, 914.3753051757812, 1666.853271484375, 1041.365234375, 14815.2607421875, 3215.00537109375, 1206.45703125, 3144.814208984375, 4376.0537109375, 797.31005859375, 15483.3564453125, 13664.228515625, 7100.62890625, 1510.4490966796875, 6607.9091796875, 1095.3524169921875, 13530.7509765625, 1047.1669921875, 3269.20849609375, 2533.088623046875, 10312.59765625, 2070.906005859375, 4550.8251953125, 1537.570556640625, 3966.8203125, 3547.746337890625, 3158.14013671875, 1980.5078125, 4476.58056640625, 5628.00341796875, 4031.83740234375, 5113.9267578125, 6919.6669921875, 4399.23779296875, 2998.455078125, 2491.188232421875, 3929.661865234375, 3142.763427734375, 3202.340576171875, 4744.57861328125, 3266.806640625, 3652.364990234375, 3542.892333984375, 3235.972412109375, 3309.138427734375, 3222.273193359375], \"Term\": [\"pizza\", \"place\", \"fry\", \"great\", \"hot\", \"get\", \"good\", \"beer\", \"wait\", \"dog\", \"dish\", \"sauce\", \"food\", \"go\", \"burger\", \"duck\", \"line\", \"cheese\", \"sausage\", \"service\", \"pork\", \"chicken\", \"chicago\", \"crust\", \"hour\", \"love\", \"us\", \"best\", \"deep\", \"salad\", \"dog\", \"burger\", \"fat\", \"dougs\", \"doug\", \"falafel\", \"slider\", \"hotdog\", \"superdawg\", \"revolution\", \"belgian\", \"andouille\", \"kumas\", \"bourdain\", \"cupcake\", \"sultan\", \"reuben\", \"freezing\", \"encased\", \"kendall\", \"bier\", \"nuke\", \"ketchup\", \"peking\", \"4pm\", \"lockdown\", \"fois\", \"sauerkraut\", \"sel\", \"dawg\", \"fox\", \"gras\", \"duck\", \"foie\", \"hot\", \"ale\", \"sausage\", \"fry\", \"bun\", \"patty\", \"beer\", \"line\", \"gourmet\", \"kimchi\", \"brew\", \"cash\", \"regular\", \"cheese\", \"wait\", \"worth\", \"get\", \"hour\", \"chicago\", \"go\", \"good\", \"like\", \"best\", \"day\", \"im\", \"place\", \"ive\", \"order\", \"know\", \"time\", \"dont\", \"really\", \"love\", \"eat\", \"pizza\", \"mexican\", \"salsa\", \"wing\", \"korean\", \"churros\", \"bayless\", \"taco\", \"torta\", \"rick\", \"xoco\", \"giordanos\", \"pequods\", \"seoul\", \"sassy\", \"frontera\", \"indian\", \"pepperoni\", \"ginos\", \"mole\", \"oven\", \"tortilla\", \"tortas\", \"buddha\", \"enchilada\", \"naan\", \"garcias\", \"mayan\", \"carne\", \"milanesa\", \"deep\", \"crust\", \"delivery\", \"thin\", \"topping\", \"burrito\", \"crisp\", \"slice\", \"chicken\", \"sauce\", \"dish\", \"chicago\", \"good\", \"best\", \"get\", \"try\", \"order\", \"cheese\", \"eat\", \"place\", \"like\", \"go\", \"im\", \"really\", \"time\", \"ive\", \"one\", \"love\", \"think\", \"dont\", \"food\", \"come\", \"make\", \"well\", \"empty\", \"hostess\", \"manager\", \"alinea\", \"chair\", \"rude\", \"violet\", \"phone\", \"card\", \"woman\", \"curtain\", \"hopleaf\", \"gejas\", \"policy\", \"attitude\", \"wear\", \"inform\", \"apology\", \"pretentious\", \"contact\", \"brazzaz\", \"amazement\", \"eventually\", \"ignore\", \"attempt\", \"sincere\", \"stupid\", \"jazz\", \"apologize\", \"ten\", \"understand\", \"struggle\", \"poor\", \"receive\", \"arrive\", \"charge\", \"bartender\", \"mistake\", \"us\", \"annoy\", \"tell\", \"happen\", \"customer\", \"table\", \"minute\", \"ask\", \"call\", \"behind\", \"terrible\", \"sit\", \"bill\", \"talk\", \"drink\", \"seat\", \"people\", \"later\", \"party\", \"pay\", \"bar\", \"hour\", \"waitress\", \"take\", \"reservation\", \"leave\", \"experience\", \"say\", \"give\", \"review\", \"wait\", \"would\", \"get\", \"server\", \"want\", \"go\", \"even\", \"didnt\", \"time\", \"one\", \"food\", \"know\", \"make\", \"come\", \"like\", \"dont\", \"place\", \"order\", \"service\", \"back\", \"really\", \"think\", \"good\", \"restaurant\", \"pig\", \"roast\", \"scallop\", \"pho\", \"bone\", \"tuna\", \"noodle\", \"risotto\", \"creamy\", \"marrow\", \"filet\", \"beet\", \"squash\", \"sprout\", \"vietnamese\", \"feta\", \"purple\", \"asparagus\", \"pita\", \"octopus\", \"braise\", \"tart\", \"sea\", \"tempura\", \"cauliflower\", \"tank\", \"carrot\", \"cucumber\", \"trout\", \"eggplant\", \"lobster\", \"pork\", \"belly\", \"chinese\", \"tender\", \"mash\", \"lamb\", \"roll\", \"salad\", \"cream\", \"dessert\", \"rib\", \"beef\", \"lemon\", \"potato\", \"oil\", \"bread\", \"flavor\", \"meat\", \"butter\", \"plate\", \"dish\", \"soup\", \"chocolate\", \"sauce\", \"cake\", \"cheese\", \"shrimp\", \"taste\", \"rice\", \"chicken\", \"sweet\", \"cook\", \"meal\", \"course\", \"order\", \"delicious\", \"good\", \"like\", \"also\", \"serve\", \"come\", \"well\", \"try\", \"little\", \"wine\", \"eat\", \"one\", \"menu\", \"really\", \"brunch\", \"breakfast\", \"pancake\", \"outdoor\", \"bongo\", \"cuban\", \"benedict\", \"omelet\", \"empanadas\", \"bloody\", \"omelette\", \"oatmeal\", \"mojitos\", \"scramble\", \"mary\", \"ropa\", \"vieja\", \"shaws\", \"jones\", \"factory\", \"latin\", \"costa\", \"q\", \"corncakes\", \"glenn\", \"lux\", \"yucca\", \"rican\", \"wishbone\", \"hamcrumbs\", \"vegan\", \"andrea\", \"cafe\", \"coffee\", \"patio\", \"great\", \"atmosphere\", \"byob\", \"friendly\", \"always\", \"morning\", \"place\", \"food\", \"love\", \"weekend\", \"service\", \"diner\", \"good\", \"toast\", \"price\", \"recommend\", \"go\", \"excellent\", \"ive\", \"spot\", \"delicious\", \"nice\", \"definitely\", \"sandwich\", \"restaurant\", \"time\", \"also\", \"really\", \"get\", \"try\", \"dinner\", \"favorite\", \"back\", \"chicago\", \"menu\", \"like\", \"best\", \"one\", \"come\", \"well\", \"wait\", \"make\"], \"Total\": [11367.0, 30962.0, 6135.0, 21857.0, 5382.0, 29296.0, 34203.0, 6240.0, 14998.0, 3075.0, 10902.0, 7136.0, 28784.0, 30036.0, 2904.0, 3267.0, 5087.0, 8597.0, 3808.0, 13407.0, 5459.0, 7379.0, 8848.0, 2822.0, 5040.0, 13206.0, 11195.0, 9929.0, 2424.0, 5843.0, 3075.816162109375, 2904.289794921875, 1624.6875, 1425.0377197265625, 679.7639770507812, 435.1873474121094, 351.4610290527344, 249.29891967773438, 237.8081512451172, 202.36508178710938, 196.7854766845703, 193.86878967285156, 190.42169189453125, 189.01406860351562, 189.15304565429688, 186.20703125, 177.15733337402344, 176.635009765625, 174.03916931152344, 157.07557678222656, 156.9834442138672, 155.76925659179688, 149.2587432861328, 131.79331970214844, 126.13616943359375, 123.67827606201172, 120.544189453125, 118.23039245605469, 115.79598236083984, 114.19926452636719, 114.54228210449219, 862.4089965820312, 3267.1044921875, 776.0819091796875, 5382.76953125, 258.2672119140625, 3808.071044921875, 6135.80078125, 586.8494262695312, 370.1574401855469, 6240.0703125, 5087.7763671875, 407.3680419921875, 376.9486083984375, 489.6513366699219, 715.6810913085938, 1732.583251953125, 8597.8486328125, 14998.572265625, 5033.01953125, 29296.3984375, 5040.9375, 8848.23046875, 30036.822265625, 34203.0, 23625.578125, 9929.015625, 4478.9716796875, 10436.958984375, 30962.83984375, 10443.6904296875, 19201.0859375, 9386.8818359375, 17892.712890625, 11013.82421875, 17145.935546875, 13206.384765625, 11818.435546875, 11367.1240234375, 1697.9786376953125, 1397.3370361328125, 1088.5096435546875, 920.864013671875, 858.1666870117188, 840.16455078125, 831.3573608398438, 708.767333984375, 698.1947631835938, 653.271728515625, 634.8025512695312, 595.9959106445312, 523.4849243164062, 505.740234375, 497.77935791015625, 473.4465637207031, 455.149658203125, 397.8199768066406, 387.88519287109375, 413.06732177734375, 372.039794921875, 366.3620300292969, 335.19134521484375, 324.798095703125, 271.9813232421875, 245.2528076171875, 227.3905792236328, 225.14361572265625, 201.5597381591797, 2424.361572265625, 2822.2314453125, 1009.2975463867188, 1264.9393310546875, 806.8325805664062, 1225.591552734375, 1305.133544921875, 1585.4661865234375, 7379.7529296875, 7136.00390625, 10902.78125, 8848.23046875, 34203.0, 9929.015625, 29296.3984375, 14516.931640625, 19201.0859375, 8597.8486328125, 11818.435546875, 30962.83984375, 23625.578125, 30036.822265625, 10436.958984375, 17145.935546875, 17892.712890625, 10443.6904296875, 17135.73828125, 13206.384765625, 11417.49609375, 11013.82421875, 28784.90625, 16560.28125, 15020.3447265625, 11942.7109375, 1159.0760498046875, 953.8850708007812, 847.6002807617188, 718.2700805664062, 676.014892578125, 650.3878784179688, 645.64697265625, 616.5095825195312, 572.1979370117188, 513.1061401367188, 491.5843200683594, 478.9791564941406, 391.28277587890625, 377.6635437011719, 368.12750244140625, 360.8223571777344, 347.1772155761719, 331.40631103515625, 327.3519592285156, 322.6155700683594, 300.9120788574219, 338.332763671875, 265.80523681640625, 262.5086669921875, 257.1962585449219, 258.43463134765625, 250.60821533203125, 246.8362274169922, 245.66961669921875, 246.4408416748047, 772.6878662109375, 301.9305725097656, 448.7734680175781, 601.2073974609375, 2577.8271484375, 853.3760986328125, 1304.561767578125, 945.165283203125, 11195.12109375, 556.4030151367188, 4560.3720703125, 917.7461547851562, 1305.2647705078125, 12108.302734375, 5152.55322265625, 5284.7265625, 3376.4931640625, 766.181640625, 671.6058959960938, 5226.08984375, 1095.252685546875, 1646.5738525390625, 7205.794921875, 5816.80419921875, 7910.65625, 1212.833251953125, 2557.083984375, 2485.25537109375, 7777.3271484375, 5040.9375, 2491.287109375, 10189.091796875, 3842.039794921875, 4442.1552734375, 7628.90283203125, 11439.3828125, 7768.4833984375, 4300.5380859375, 14998.572265625, 14051.7265625, 29296.3984375, 5641.42578125, 8332.5517578125, 30036.822265625, 10096.4482421875, 7799.66455078125, 17892.712890625, 17135.73828125, 28784.90625, 9386.8818359375, 15020.3447265625, 16560.28125, 23625.578125, 11013.82421875, 30962.83984375, 19201.0859375, 13407.642578125, 12453.037109375, 17145.935546875, 11417.49609375, 34203.0, 12142.7236328125, 1480.16162109375, 1265.9461669921875, 1078.2545166015625, 1025.4217529296875, 1023.7671508789062, 1020.1654663085938, 941.6210327148438, 800.070068359375, 730.387939453125, 663.57666015625, 608.6190185546875, 601.7664794921875, 594.2074584960938, 548.5899047851562, 530.822265625, 529.3626708984375, 498.4366455078125, 485.84039306640625, 485.5291442871094, 445.8010559082031, 424.8409423828125, 415.1097412109375, 401.1721496582031, 383.2005920410156, 361.5810852050781, 358.2031555175781, 356.52532958984375, 352.9698791503906, 336.8594055175781, 326.6247253417969, 1018.7906494140625, 5459.33984375, 1076.4971923828125, 600.9071044921875, 1365.7066650390625, 952.67529296875, 1276.75732421875, 3728.070068359375, 5843.93359375, 2206.968017578125, 4936.03759765625, 1693.2923583984375, 2894.55908203125, 1320.7452392578125, 3351.6474609375, 1102.3662109375, 3698.942626953125, 5306.71435546875, 6632.61669921875, 1595.3017578125, 4036.407958984375, 10902.78125, 2982.019287109375, 3285.43212890625, 7136.00390625, 2566.235107421875, 8597.8486328125, 2244.24267578125, 7986.796875, 2887.033935546875, 7379.7529296875, 3931.10400390625, 2908.129150390625, 8352.900390625, 5148.26416015625, 19201.0859375, 9024.826171875, 34203.0, 23625.578125, 11185.796875, 4982.85107421875, 16560.28125, 11942.7109375, 14516.931640625, 8478.466796875, 5945.08642578125, 11818.435546875, 17135.73828125, 9276.09765625, 17145.935546875, 2900.053955078125, 2524.11572265625, 2485.396728515625, 942.3133544921875, 704.3988037109375, 651.17236328125, 530.6157836914062, 510.0196228027344, 496.05377197265625, 460.547119140625, 438.79327392578125, 371.78472900390625, 341.69512939453125, 321.76025390625, 309.80194091796875, 306.2781066894531, 278.0744323730469, 266.47332763671875, 263.4971618652344, 247.6769561767578, 240.80795288085938, 235.66400146484375, 228.83248901367188, 318.934814453125, 222.9726104736328, 200.5557403564453, 194.800537109375, 191.07125854492188, 185.76397705078125, 210.14772033691406, 920.7348022460938, 220.1332550048828, 951.6121826171875, 1811.749267578125, 1117.2532958984375, 21857.318359375, 4159.7333984375, 1435.3626708984375, 4278.05615234375, 6425.5361328125, 966.5540161132812, 30962.83984375, 28784.90625, 13206.384765625, 2156.03515625, 13407.642578125, 1467.020751953125, 34203.0, 1409.648681640625, 6035.732421875, 4521.9072265625, 30036.822265625, 3543.9677734375, 10443.6904296875, 2363.1201171875, 9024.826171875, 7852.47265625, 6698.96728515625, 3503.25244140625, 12142.7236328125, 17892.712890625, 11185.796875, 17145.935546875, 29296.3984375, 14516.931640625, 7383.2666015625, 5285.056640625, 12453.037109375, 8848.23046875, 9276.09765625, 23625.578125, 9929.015625, 17135.73828125, 16560.28125, 11942.7109375, 14998.572265625, 15020.3447265625], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.68969988822937, 2.68969988822937, 2.689500093460083, 2.6893999576568604, 2.688800096511841, 2.6881000995635986, 2.6875998973846436, 2.6867001056671143, 2.6865999698638916, 2.6858999729156494, 2.685800075531006, 2.685699939727783, 2.685699939727783, 2.6856000423431396, 2.6856000423431396, 2.6856000423431396, 2.68530011177063, 2.68530011177063, 2.68530011177063, 2.6847000122070312, 2.6847000122070312, 2.6847000122070312, 2.684499979019165, 2.683799982070923, 2.6833999156951904, 2.6833999156951904, 2.683199882507324, 2.683000087738037, 2.683000087738037, 2.6828999519348145, 2.682800054550171, 2.595900058746338, 2.489799976348877, 2.559999942779541, 2.289900064468384, 2.60260009765625, 2.2973999977111816, 2.224100112915039, 2.4677000045776367, 2.503700017929077, 1.871899962425232, 1.8792999982833862, 2.4602999687194824, 2.4800000190734863, 2.3536999225616455, 2.2155001163482666, 1.8202999830245972, 0.9399999976158142, 0.6633999943733215, 1.142699956893921, 0.2953999936580658, 1.1013000011444092, 0.7825000286102295, 0.035599999129772186, -0.1274999976158142, 0.04769999906420708, 0.5357000231742859, 1.0003000497817993, 0.4580000042915344, -0.3005000054836273, 0.3831000030040741, -0.14380000531673431, 0.3930000066757202, -0.14110000431537628, 0.2500999867916107, -0.2176000028848648, 0.015699999406933784, 0.04619999974966049, 2.182800054550171, 2.1823999881744385, 2.182300090789795, 2.1821000576019287, 2.181999921798706, 2.181999921798706, 2.1819000244140625, 2.1819000244140625, 2.18179988861084, 2.18179988861084, 2.1816999912261963, 2.1816999912261963, 2.1816000938415527, 2.1814000606536865, 2.181299924850464, 2.181299924850464, 2.1812000274658203, 2.1812000274658203, 2.1809000968933105, 2.1809000968933105, 2.1809000968933105, 2.180799961090088, 2.180799961090088, 2.1805999279022217, 2.180500030517578, 2.180000066757202, 2.179800033569336, 2.179500102996826, 2.179500102996826, 2.1791000366210938, 2.1405999660491943, 2.130500078201294, 2.116499900817871, 2.0799999237060547, 2.0517001152038574, 1.961899995803833, 1.9443000555038452, 1.7438000440597534, 1.2477999925613403, 1.2552000284194946, 0.9021999835968018, 0.899399995803833, 0.2874999940395355, 0.7479000091552734, 0.22380000352859497, 0.5156999826431274, 0.33180001378059387, 0.7470999956130981, 0.5126000046730042, -0.05550000071525574, 0.0737999975681305, -0.30090001225471497, 0.37709999084472656, 0.0006000000284984708, -0.03880000114440918, 0.3312999904155731, -0.04800000041723251, 0.10939999669790268, 0.13750000298023224, 0.1581999957561493, -0.645799994468689, -0.18569999933242798, -0.1080000028014183, 0.0649000033736229, 0.9829999804496765, 0.9828000068664551, 0.982699990272522, 0.9825999736785889, 0.9825000166893005, 0.9825000166893005, 0.9825000166893005, 0.9824000000953674, 0.9822999835014343, 0.982200026512146, 0.9821000099182129, 0.9819999933242798, 0.9817000031471252, 0.9815999865531921, 0.9815999865531921, 0.9815000295639038, 0.9815000295639038, 0.9814000129699707, 0.9812999963760376, 0.9812999963760376, 0.9811000227928162, 0.98089998960495, 0.9807000160217285, 0.9807000160217285, 0.9807000160217285, 0.9805999994277954, 0.9805999994277954, 0.9805999994277954, 0.9805999994277954, 0.9805999994277954, 0.9721999764442444, 0.9801999926567078, 0.9718999862670898, 0.9638000130653381, 0.9215999841690063, 0.9490000009536743, 0.9359999895095825, 0.9455999732017517, 0.8539000153541565, 0.9567999839782715, 0.8557000160217285, 0.9287999868392944, 0.9023000001907349, 0.7667999863624573, 0.8091999888420105, 0.8015999794006348, 0.8256999850273132, 0.9302999973297119, 0.939300000667572, 0.7714999914169312, 0.8978000283241272, 0.86080002784729, 0.7251999974250793, 0.7394000291824341, 0.6942999958992004, 0.886900007724762, 0.8041999936103821, 0.8057000041007996, 0.6686000227928162, 0.6833999752998352, 0.7853000164031982, 0.5723000168800354, 0.7128999829292297, 0.6804999709129333, 0.5935999751091003, 0.5210999846458435, 0.5738999843597412, 0.6736999750137329, 0.4101000130176544, 0.4142000079154968, 0.22429999709129333, 0.5809999704360962, 0.4884999990463257, 0.19099999964237213, 0.4361000061035156, 0.4948999881744385, 0.2667999863624573, 0.24469999969005585, 0.07660000026226044, 0.4194999933242798, 0.2451999932527542, 0.2004999965429306, 0.04859999939799309, 0.3452000021934509, -0.09830000251531601, 0.09120000153779984, 0.2305999994277954, 0.23149999976158142, -0.009499999694526196, 0.2678000032901764, -0.5396999716758728, 0.1324000060558319, 1.4886000156402588, 1.4884999990463257, 1.4883999824523926, 1.4883999824523926, 1.4883999824523926, 1.4883999824523926, 1.4882999658584595, 1.4881999492645264, 1.4881000518798828, 1.4880000352859497, 1.4879000186920166, 1.4879000186920166, 1.4878000020980835, 1.4878000020980835, 1.4876999855041504, 1.4876999855041504, 1.4875999689102173, 1.4875999689102173, 1.4875999689102173, 1.4874000549316406, 1.4874000549316406, 1.4873000383377075, 1.4873000383377075, 1.4872000217437744, 1.4869999885559082, 1.4869999885559082, 1.4869999885559082, 1.4869999885559082, 1.486899971961975, 1.486799955368042, 1.482800006866455, 1.412600040435791, 1.455299973487854, 1.4660999774932861, 1.419600009918213, 1.4357999563217163, 1.4052000045776367, 1.3215999603271484, 1.2581000328063965, 1.3291000127792358, 1.2371000051498413, 1.3532999753952026, 1.2813999652862549, 1.3675999641418457, 1.2289999723434448, 1.382099986076355, 1.1872999668121338, 1.128000020980835, 1.0857000350952148, 1.3142000436782837, 1.1454999446868896, 0.9063000082969666, 1.1785000562667847, 1.1452000141143799, 0.9437000155448914, 1.1971999406814575, 0.8356999754905701, 1.2163000106811523, 0.8284000158309937, 1.1277999877929688, 0.7746999859809875, 0.9575999975204468, 1.0677000284194946, 0.5745000243186951, 0.7883999943733215, 0.18379999697208405, 0.48330000042915344, -0.2459000051021576, -0.05249999836087227, 0.27570000290870667, 0.7179999947547913, -0.07670000195503235, 0.12470000237226486, -0.03229999914765358, 0.3490000069141388, 0.5853000283241272, 0.0617000013589859, -0.2434999942779541, 0.21549999713897705, -0.3190999925136566, 1.5144000053405762, 1.5144000053405762, 1.5144000053405762, 1.5139000415802002, 1.5135999917984009, 1.5134999752044678, 1.5132999420166016, 1.513200044631958, 1.513200044631958, 1.5130000114440918, 1.5128999948501587, 1.5125999450683594, 1.5125000476837158, 1.5123000144958496, 1.5121999979019165, 1.5121999979019165, 1.5119999647140503, 1.5118000507354736, 1.5118000507354736, 1.5116000175476074, 1.5115000009536743, 1.5115000009536743, 1.511299967765808, 1.511299967765808, 1.511299967765808, 1.5109000205993652, 1.510699987411499, 1.510699987411499, 1.510599970817566, 1.510599970817566, 1.5023000240325928, 1.5104000568389893, 1.4747999906539917, 1.4313000440597534, 1.4443999528884888, 1.1258000135421753, 1.257099986076355, 1.340999960899353, 1.2070000171661377, 1.1305999755859375, 1.3221999406814575, 0.8216999769210815, 0.769599974155426, 0.8942000269889832, 1.1588000059127808, 0.8070999979972839, 1.222499966621399, 0.5874000191688538, 1.2174999713897705, 0.9016000032424927, 0.9351999759674072, 0.4456000030040741, 0.977400004863739, 0.6840000152587891, 1.0849000215530396, 0.6927000284194946, 0.7202000021934509, 0.7627000212669373, 0.9444000124931335, 0.5167999863624573, 0.3580999970436096, 0.4943000078201294, 0.30489999055862427, 0.07159999758005142, 0.3208000063896179, 0.6136000156402588, 0.7626000046730042, 0.361299991607666, 0.4796000123023987, 0.4510999917984009, -0.09059999883174896, 0.40310001373291016, -0.031099999323487282, -0.027400000020861626, 0.20890000462532043, 0.0034000000450760126, -0.02459999918937683], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.1809000968933105, -4.23829984664917, -4.819399833679199, -4.9506001472473145, -5.691500186920166, -6.1381001472473145, -6.35230016708374, -6.696599960327148, -6.74399995803833, -6.906000137329102, -6.934100151062012, -6.949100017547607, -6.9670000076293945, -6.9745001792907715, -6.973800182342529, -6.989500045776367, -7.039599895477295, -7.042600154876709, -7.057400226593018, -7.1605000495910645, -7.161099910736084, -7.168900012969971, -7.2118000984191895, -7.336999893188477, -7.381199836730957, -7.400899887084961, -7.426799774169922, -7.446300029754639, -7.467199802398682, -7.481200218200684, -7.4781999588012695, -5.54640007019043, -4.320499897003174, -5.68779993057251, -4.021100044250488, -6.7453999519348145, -4.3597002029418945, -3.955899953842163, -6.059500217437744, -6.484399795532227, -4.291399955749512, -4.488100051879883, -6.4319000244140625, -6.4899001121521, -6.354599952697754, -6.1132001876831055, -5.624300003051758, -4.902699947357178, -4.622900009155273, -5.235499858856201, -4.321300029754639, -5.275300025939941, -5.031499862670898, -4.55620002746582, -4.589399814605713, -4.784200191497803, -5.163099765777588, -5.494500160217285, -5.190800189971924, -4.861999988555908, -5.265100002288818, -5.183000087738037, -5.3618998527526855, -5.250899791717529, -5.34499979019165, -5.370100021362305, -5.397799968719482, -5.478300094604492, -3.38070011138916, -5.282400131225586, -5.477399826049805, -5.72730016708374, -5.894599914550781, -5.965199947357178, -5.986400127410889, -5.997000217437744, -6.156700134277344, -6.1717000007629395, -6.23829984664917, -6.267000198364258, -6.3302001953125, -6.460100173950195, -6.49459981918335, -6.510499954223633, -6.560699939727783, -6.600200176239014, -6.735000133514404, -6.76039981842041, -6.697500228881836, -6.802199840545654, -6.817599773406982, -6.906700134277344, -6.938300132751465, -7.116199970245361, -7.219900131225586, -7.29580020904541, -7.305799961090088, -7.416800022125244, -4.9679999351501465, -4.826200008392334, -5.868500232696533, -5.679200172424316, -6.157100200653076, -5.82889986038208, -5.783599853515625, -5.789599895477295, -4.747700214385986, -4.773900032043457, -4.703000068664551, -4.914599895477295, -4.1743998527526855, -4.950799942016602, -4.392899990081787, -4.803199768066406, -4.707399845123291, -5.095600128173828, -5.011899948120117, -4.6168999671936035, -4.7581000328063965, -4.8927001953125, -5.2718000411987305, -5.151899814605713, -5.148600101470947, -5.31689977645874, -5.201099872589111, -5.304100036621094, -5.421599864959717, -5.436800003051758, -5.280200004577637, -5.373000144958496, -5.3927998542785645, -5.44920015335083, -6.86359977722168, -7.058599948883057, -7.176799774169922, -7.34250020980835, -7.403200149536133, -7.44189977645874, -7.44920015335083, -7.495500087738037, -7.570199966430664, -7.679299831390381, -7.7221999168396, -7.748300075531006, -7.950799942016602, -7.986299991607666, -8.01200008392334, -8.032099723815918, -8.070699691772461, -8.117300033569336, -8.129599571228027, -8.144200325012207, -8.21399974822998, -8.097000122070312, -8.338500022888184, -8.35099983215332, -8.371399879455566, -8.366700172424316, -8.397500038146973, -8.412699699401855, -8.417400360107422, -8.414299964904785, -7.279900074005127, -8.211600303649902, -7.823599815368652, -7.539299964904785, -6.125699996948242, -7.203700065612793, -6.792300224304199, -7.105100154876709, -4.724899768829346, -7.623700141906738, -5.621099948883057, -7.151299953460693, -6.825500011444092, -4.733500003814697, -5.545599937438965, -5.5278000831604, -5.951700210571289, -7.3302998542785645, -7.453100204467773, -5.5690999031066895, -7.00540018081665, -6.634699821472168, -5.294099807739258, -5.49399995803833, -5.2316999435424805, -6.914400100708008, -6.251100063323975, -6.278200149536133, -5.274400234222412, -5.69320011138916, -6.296199798583984, -5.100599765777588, -5.935299873352051, -5.8225998878479, -5.36870002746582, -5.035999774932861, -5.370200157165527, -5.861800193786621, -4.876200199127197, -4.93720006942749, -4.392399787902832, -5.68310022354126, -5.385499954223633, -4.4008002281188965, -5.245999813079834, -5.445199966430664, -4.8429999351501465, -4.908400058746338, -4.557799816131592, -5.335400104522705, -5.039599895477295, -4.986700057983398, -4.783299922943115, -5.249899864196777, -4.659800052642822, -4.9481000900268555, -5.167799949645996, -5.240799903869629, -5.1620001792907715, -5.291299819946289, -5.0015997886657715, -5.365099906921387, -6.113500118255615, -6.269899845123291, -6.430500030517578, -6.4807000160217285, -6.4822998046875, -6.485899925231934, -6.566100120544434, -6.729100227355957, -6.820300102233887, -6.916299819946289, -7.002900123596191, -7.014200210571289, -7.026899814605713, -7.106900215148926, -7.139800071716309, -7.142600059509277, -7.202899932861328, -7.228499889373779, -7.2291998863220215, -7.314700126647949, -7.3628997802734375, -7.386099815368652, -7.420300006866455, -7.46619987487793, -7.524499893188477, -7.53380012512207, -7.538599967956543, -7.548600196838379, -7.595399856567383, -7.626299858093262, -6.492800235748291, -4.884200096130371, -6.465199947357178, -7.037399768829346, -6.263000011444092, -6.606900215148926, -6.344699859619141, -5.3566999435424805, -4.970699787139893, -5.873499870300293, -5.160600185394287, -6.114200115203857, -5.650000095367432, -6.348400115966797, -5.555699825286865, -6.514699935913086, -5.498899936676025, -5.197299957275391, -5.016499996185303, -6.2129998207092285, -5.453400135040283, -4.69890022277832, -5.723100185394287, -5.6595001220703125, -5.085400104522705, -5.854599952697754, -5.006999969482422, -5.9695000648498535, -5.0879998207092285, -5.80620002746582, -5.220699787139893, -5.667699813842773, -5.859000205993652, -5.297100067138672, -5.5671000480651855, -4.855500221252441, -5.3109002113342285, -4.707799911499023, -4.884399890899658, -5.303899765014648, -5.670199871063232, -5.263899803161621, -5.389400005340576, -5.351200103759766, -5.507699966430664, -5.626299858093262, -5.462800025939941, -5.396500110626221, -5.551300048828125, -5.47160005569458, -5.41510009765625, -5.553899765014648, -5.569399833679199, -6.53980016708374, -6.830999851226807, -6.9096999168396, -7.114699840545654, -7.154300212860107, -7.18209981918335, -7.256499767303467, -7.304999828338623, -7.4710001945495605, -7.555600166320801, -7.615799903869629, -7.653800010681152, -7.665299892425537, -7.7621002197265625, -7.804900169372559, -7.816199779510498, -7.878200054168701, -7.906499862670898, -7.928100109100342, -7.957699775695801, -7.625699996948242, -7.983699798583984, -8.09000015258789, -8.11929988861084, -8.13860034942627, -8.166899681091309, -8.043600082397461, -6.57450008392334, -7.997399806976318, -6.568999767303467, -5.968599796295166, -6.439000129699707, -3.783900022506714, -5.311699867248535, -6.291800022125244, -5.333799839019775, -5.003399848937988, -6.705999851226807, -3.739799976348877, -3.8647000789642334, -4.5192999839782715, -6.0671000480651855, -4.591300010681152, -6.388400077819824, -3.8745999336242676, -6.4334001541137695, -5.295000076293945, -5.550099849700928, -4.146200180053711, -5.751500129699707, -4.964200019836426, -6.049300193786621, -5.101600170135498, -5.213200092315674, -5.329500198364258, -5.796199798583984, -4.9807000160217285, -4.751800060272217, -5.085299968719482, -4.847599983215332, -4.545100212097168, -4.9980998039245605, -5.381400108337402, -5.566800117492676, -5.111000061035156, -5.334400177001953, -5.3155999183654785, -4.922500133514404, -5.2957000732421875, -5.184100151062012, -5.214600086212158, -5.305200099945068, -5.282800197601318, -5.3094000816345215]}, \"token.table\": {\"Topic\": [1, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 3, 1, 5, 3, 5, 3, 3, 2, 3, 4, 1, 2, 3, 4, 5, 4, 2, 3, 4, 5, 3, 3, 1, 2, 3, 4, 5, 3, 4, 5, 3, 5, 2, 1, 2, 4, 5, 1, 2, 3, 5, 4, 1, 2, 3, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 5, 1, 4, 3, 2, 4, 5, 5, 1, 2, 5, 2, 1, 4, 1, 2, 5, 4, 5, 3, 4, 5, 4, 5, 4, 5, 1, 2, 3, 4, 5, 3, 2, 4, 1, 2, 3, 4, 3, 3, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 2, 4, 1, 2, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 5, 5, 3, 4, 2, 4, 5, 4, 2, 4, 2, 4, 5, 4, 1, 3, 3, 5, 1, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 5, 3, 4, 5, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 1, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 4, 5, 3, 1, 2, 1, 2, 3, 4, 5, 3, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 1, 1, 2, 3, 4, 5, 4, 4, 1, 2, 3, 4, 5, 1, 4, 1, 1, 2, 3, 4, 5, 1, 1, 1, 2, 3, 4, 5, 2, 1, 2, 4, 5, 2, 3, 1, 2, 3, 4, 5, 2, 2, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 4, 1, 2, 3, 4, 5, 5, 2, 3, 4, 3, 3, 1, 2, 4, 1, 1, 2, 3, 3, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 3, 5, 1, 1, 1, 2, 1, 2, 3, 4, 5, 2, 1, 1, 4, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 4, 5, 1, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 3, 4, 5, 2, 4, 2, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 2, 2, 1, 2, 3, 2, 3, 5, 2, 1, 3, 5, 2, 1, 2, 3, 4, 5, 4, 1, 5, 4, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 2, 5, 3, 4, 5, 3, 5, 1, 2, 2, 3, 4, 5, 1, 1, 2, 3, 5, 2, 2, 4, 3, 4, 4, 2, 1, 2, 3, 4, 5, 3, 4, 5, 3, 3, 4, 1, 4, 4, 5, 3, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 3, 4, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 5, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 4, 5, 5, 2, 4, 5, 2, 4, 4, 3, 4, 5, 5, 3, 2, 3, 4, 5, 2, 1, 2, 4, 5, 2, 1, 2, 4, 5, 1, 1, 2, 4, 1, 2, 3, 4, 5, 4, 5, 4, 2, 3, 5, 1, 2, 1, 2, 3, 4, 5, 3, 4, 5, 2, 3, 4, 5, 5, 4, 5, 3, 2, 3, 5, 2, 4, 1, 1, 2, 4, 5, 1, 2, 3, 4, 5, 4, 4, 3, 3, 1, 1, 1, 2, 4, 5, 3, 4, 5, 2, 1, 2, 3, 4, 5, 2, 3, 4, 5, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 4, 3, 2, 4, 2, 3, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 5, 1, 2, 2, 2, 2, 4, 1, 2, 3, 4, 5, 4, 2, 3, 3, 4, 5, 1, 5, 5, 4, 3, 1, 2, 3, 5, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 3, 4, 5, 2, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 5], \"Freq\": [0.990992546081543, 0.9176542162895203, 0.08131113648414612, 0.9996240139007568, 0.06257935613393784, 0.11711280047893524, 0.16261693835258484, 0.29716256260871887, 0.3604571223258972, 0.08481782674789429, 0.11905620992183685, 0.1150098592042923, 0.681032657623291, 0.9960607886314392, 0.995518684387207, 0.9948519468307495, 0.9741140604019165, 0.0251616183668375, 0.9972743391990662, 0.998773992061615, 0.004655083175748587, 0.9399389028549194, 0.055473074316978455, 0.04276474937796593, 0.01589486189186573, 0.8335341215133667, 0.08288035541772842, 0.02478841505944729, 0.9982702136039734, 0.0019232002086937428, 0.22261041402816772, 0.0024040001444518566, 0.7728860974311829, 0.9953488707542419, 0.9969372153282166, 0.043925028294324875, 0.05765661597251892, 0.47137096524238586, 0.11153905838727951, 0.3155856728553772, 0.7298136949539185, 0.018001042306423187, 0.25214317440986633, 0.953576922416687, 0.04599245637655258, 0.9986138939857483, 0.09189654886722565, 0.056312549859285355, 0.8125590085983276, 0.03938423842191696, 0.44134119153022766, 0.0727555900812149, 0.33108600974082947, 0.15496620535850525, 0.9987263083457947, 0.02871381863951683, 0.023493124172091484, 0.9475559592247009, 0.9960084557533264, 0.032512858510017395, 0.9670252799987793, 0.9988394975662231, 0.11602358520030975, 0.23809006810188293, 0.11793716996908188, 0.19891196489334106, 0.3290356397628784, 0.9937353730201721, 0.9175964593887329, 0.08217281848192215, 0.9988120198249817, 0.9992506504058838, 0.9994338154792786, 0.9946349859237671, 0.998020589351654, 0.9969689249992371, 0.1484207957983017, 0.7394005060195923, 0.11192387342453003, 0.9995579719543457, 0.7147943377494812, 0.2838754653930664, 0.9996365904808044, 0.9964457750320435, 0.800886869430542, 0.19766569137573242, 0.9995558857917786, 0.8020616769790649, 0.19745567440986633, 0.8393396139144897, 0.15984436869621277, 0.11007671058177948, 0.04946485161781311, 0.8402057886123657, 0.03888138383626938, 0.9604753255844116, 0.7466190457344055, 0.2528996765613556, 0.006811801344156265, 0.058344557881355286, 0.8538444638252258, 0.0556790716946125, 0.02487788163125515, 0.9979064464569092, 0.9949204921722412, 0.9985265135765076, 0.6217853426933289, 0.11597344279289246, 0.2612895667552948, 0.9983929395675659, 0.9984987378120422, 0.9655765891075134, 0.03281085565686226, 0.1737643927335739, 0.23796650767326355, 0.5202464461326599, 0.06792397052049637, 0.14850427210330963, 0.2771175503730774, 0.1636485457420349, 0.05560433864593506, 0.3552122712135315, 0.029269272461533546, 0.39256057143211365, 0.4894472658634186, 0.0886208564043045, 0.02163396030664444, 0.9768564701080322, 0.001521869795396924, 0.20514805614948273, 0.708886981010437, 0.08400721102952957, 0.9986404776573181, 0.023733967915177345, 0.056299179792404175, 0.9201052188873291, 0.02656959742307663, 0.09359744191169739, 0.4569970667362213, 0.20893365144729614, 0.2139456421136856, 0.9980919361114502, 0.00034386367769911885, 0.08837296813726425, 0.16058434545993805, 0.6560919284820557, 0.09456251561641693, 0.9970689415931702, 0.9971824288368225, 0.5036649107933044, 0.49628376960754395, 0.0702321007847786, 0.8523005247116089, 0.07748186588287354, 0.9994688630104065, 0.7876588702201843, 0.21147261559963226, 0.9488945603370667, 0.05066912621259689, 0.9981995820999146, 0.9972522258758545, 0.993904173374176, 0.9988113641738892, 0.92165207862854, 0.07737893611192703, 0.989498496055603, 0.18464060127735138, 0.11766093224287033, 0.32753053307533264, 0.08394783735275269, 0.28622642159461975, 0.9586029052734375, 0.04124797135591507, 0.025824876502156258, 0.10598648339509964, 0.19137278199195862, 0.20540478825569153, 0.4714159369468689, 0.06493199616670609, 0.11822942644357681, 0.011523767374455929, 0.36576882004737854, 0.4395652413368225, 0.9362947344779968, 0.0634104385972023, 0.056928254663944244, 0.7771415710449219, 0.16571997106075287, 0.041796669363975525, 0.06320784986019135, 0.6133596897125244, 0.22244545817375183, 0.05910510569810867, 0.1942712813615799, 0.05862221121788025, 0.7464107275009155, 0.3490324914455414, 0.24474261701107025, 0.4060533344745636, 0.2779107391834259, 0.07887895405292511, 0.5582979321479797, 0.08493245393037796, 0.99973464012146, 0.08716318756341934, 0.1320159137248993, 0.5281544327735901, 0.07581381499767303, 0.17686863243579865, 0.9988760948181152, 0.999271810054779, 0.7722950577735901, 0.0018041034927591681, 0.22579050064086914, 0.818767786026001, 0.18120020627975464, 0.07107539474964142, 0.1881805807352066, 0.33050060272216797, 0.2399640828371048, 0.1703271120786667, 0.9980873465538025, 0.9978756904602051, 0.9990716576576233, 0.9940291047096252, 0.9975427985191345, 0.05239466205239296, 0.06824181973934174, 0.578322172164917, 0.09161637723445892, 0.20938056707382202, 0.9969705939292908, 0.0674385353922844, 0.10722444951534271, 0.2409728467464447, 0.5843732357025146, 0.015598573721945286, 0.00969995278865099, 0.6770305037498474, 0.11194270104169846, 0.18560990691184998, 0.9972667694091797, 0.9972716569900513, 0.9995768666267395, 0.01589386910200119, 0.14739671349525452, 0.029895611107349396, 0.3354741632938385, 0.4713289141654968, 0.9993149042129517, 0.9989829063415527, 0.02901984006166458, 0.15037553012371063, 0.017901849001646042, 0.6968530416488647, 0.10571513324975967, 0.8774846792221069, 0.12112123519182205, 0.9954855442047119, 0.007226009387522936, 0.05909347161650658, 0.4037185311317444, 0.055272024124860764, 0.474693238735199, 0.9952656626701355, 0.9964049458503723, 0.04230893403291702, 0.012622554786503315, 0.17998827993869781, 0.029920130968093872, 0.7351469397544861, 0.99843430519104, 0.627627968788147, 0.07953321933746338, 0.2718471586704254, 0.021024150773882866, 0.9948917627334595, 0.9992772936820984, 0.09120575338602066, 0.14100709557533264, 0.4679756164550781, 0.06359143555164337, 0.23620650172233582, 0.9979388117790222, 0.9987357258796692, 0.0007723515154793859, 0.08251288533210754, 0.6638361215591431, 0.15266814827919006, 0.10027696937322617, 0.9956379532814026, 0.07034698873758316, 0.0834309309720993, 0.452644407749176, 0.050238337367773056, 0.3433452546596527, 0.059760838747024536, 0.1502792090177536, 0.21799257397651672, 0.17638804018497467, 0.3956085741519928, 0.7953495979309082, 0.04664086923003197, 0.056460000574588776, 0.10064608603715897, 0.9102409482002258, 0.08928478509187698, 0.02772526815533638, 0.06409752368927002, 0.13794006407260895, 0.09246330708265305, 0.6778050065040588, 0.9945384860038757, 0.05012279376387596, 0.9468849301338196, 0.0032688777428120375, 0.9979557394981384, 0.9990721344947815, 0.6702868938446045, 0.14304903149604797, 0.18652108311653137, 0.994789719581604, 0.204128697514534, 0.055148471146821976, 0.7405368685722351, 0.9980623126029968, 0.107310950756073, 0.16431988775730133, 0.4439990520477295, 0.13203079998493195, 0.15234322845935822, 0.9990567564964294, 0.9966091513633728, 0.09958165884017944, 0.15703260898590088, 0.18326854705810547, 0.1244770735502243, 0.43576550483703613, 0.9966121912002563, 0.998113214969635, 0.9931524991989136, 0.9915667176246643, 0.8117817640304565, 0.18835458159446716, 0.10056587308645248, 0.12197873741388321, 0.5688790082931519, 0.0986483097076416, 0.10994066298007965, 0.9990617632865906, 0.9977855086326599, 0.07988988608121872, 0.919516921043396, 0.011543218977749348, 0.04205029830336571, 0.9077917337417603, 0.03215610980987549, 0.0065961251966655254, 0.9966448545455933, 0.02746414579451084, 0.049525510519742966, 0.7386054396629333, 0.14429932832717896, 0.04029575362801552, 0.8858634829521179, 0.11432939022779465, 0.07119402289390564, 0.12135152518749237, 0.3925829827785492, 0.21404767036437988, 0.20084165036678314, 0.44459500908851624, 0.14230185747146606, 0.31742748618125916, 0.09571961313486099, 0.010261288844048977, 0.09730532765388489, 0.2768189311027527, 0.31975120306015015, 0.29592615365982056, 0.9933345913887024, 0.00588933564722538, 0.9945157766342163, 0.06898178905248642, 0.12577249109745026, 0.11077974736690521, 0.15681809186935425, 0.5376944541931152, 0.9972289800643921, 0.04620400071144104, 0.10119608044624329, 0.4778851568698883, 0.16024932265281677, 0.214509055018425, 0.9992917776107788, 0.9991309642791748, 0.9974114298820496, 0.05143410339951515, 0.9478570818901062, 0.9982823133468628, 0.01843670941889286, 0.3831004500389099, 0.4006991386413574, 0.19777561724185944, 0.10056363046169281, 0.05774493142962456, 0.16162550449371338, 0.668062150478363, 0.012061604298651218, 0.0007546276901848614, 0.37407970428466797, 0.2798590660095215, 0.3451882600784302, 0.999423623085022, 0.9972229599952698, 0.08675310760736465, 0.07316760718822479, 0.8399718999862671, 0.03703055903315544, 0.9627945423126221, 0.9979656338691711, 0.9977179169654846, 0.04241873696446419, 0.13242922723293304, 0.8245788216590881, 0.9963919520378113, 0.001146135851740837, 0.06469299644231796, 0.2904817461967468, 0.19191406667232513, 0.45183220505714417, 0.9993404746055603, 0.9950615763664246, 0.9978892803192139, 0.9982030987739563, 0.059871211647987366, 0.04082128033041954, 0.8980681896209717, 0.9980008006095886, 0.9981921315193176, 0.02497703954577446, 0.10743628442287445, 0.4775983393192291, 0.1768234223127365, 0.21312183141708374, 0.05879875645041466, 0.1570744514465332, 0.409612238407135, 0.2710784077644348, 0.10337956994771957, 0.9996674656867981, 0.997416079044342, 0.9998403787612915, 0.8357175588607788, 0.03284991905093193, 0.13139967620372772, 0.06712891161441803, 0.9317493438720703, 0.8293768167495728, 0.16749629378318787, 0.009656955488026142, 0.8369361162185669, 0.028970865532755852, 0.123930923640728, 0.9939805865287781, 0.022248469293117523, 0.0690208226442337, 0.7487368583679199, 0.1599108725786209, 0.9974741339683533, 0.9983289837837219, 0.9995887279510498, 0.9991734623908997, 0.9992151856422424, 0.9989101886749268, 0.9999011158943176, 0.050253789871931076, 0.10664396733045578, 0.3389224112033844, 0.004101690836250782, 0.5000510215759277, 0.2598845362663269, 0.7092940211296082, 0.03096812777221203, 0.9982430338859558, 0.9893633127212524, 0.011141479015350342, 0.07345210760831833, 0.9263024926185608, 0.7709641456604004, 0.22884269058704376, 0.9989248514175415, 0.018887517973780632, 0.06826014816761017, 0.31943100690841675, 0.051857832819223404, 0.5416078567504883, 0.9991239905357361, 0.996362030506134, 0.054590195417404175, 0.11279641091823578, 0.37040847539901733, 0.16394555568695068, 0.2982631027698517, 0.979695200920105, 0.018296515569090843, 0.131581649184227, 0.14772528409957886, 0.16055172681808472, 0.5601618885993958, 0.4190274775028229, 0.06926073879003525, 0.2828146815299988, 0.05887163057923317, 0.16968882083892822, 0.762876033782959, 0.022904500365257263, 0.21420912444591522, 0.039035722613334656, 0.4268399775028229, 0.165366530418396, 0.3686981797218323, 0.9934672117233276, 0.03348418325185776, 0.08324539661407471, 0.733396589756012, 0.08812850713729858, 0.061852723360061646, 0.9981959462165833, 0.10571122169494629, 0.8728557825088501, 0.021260356530547142, 0.9943934082984924, 0.20644024014472961, 0.6969090104103088, 0.09663897752761841, 0.9982888102531433, 0.998662531375885, 0.9992526173591614, 0.06196235492825508, 0.8457459211349487, 0.09227294474840164, 0.9990919828414917, 0.9994035959243774, 0.03131452575325966, 0.0011978233233094215, 0.7936435341835022, 0.17368438839912415, 0.999758780002594, 0.13330470025539398, 0.2680366337299347, 0.03311208635568619, 0.5654745101928711, 0.9985363483428955, 0.0009809411130845547, 0.3954594135284424, 0.5795961022377014, 0.023962991312146187, 0.9895932674407959, 0.6754075884819031, 0.21717031300067902, 0.1074034571647644, 0.0482543520629406, 0.100092813372612, 0.6296668648719788, 0.0942358523607254, 0.12771667540073395, 0.9997639656066895, 0.9976372122764587, 0.9970781803131104, 0.003610229818150401, 0.7834198474884033, 0.21300356090068817, 0.9931259751319885, 0.9990736842155457, 0.023480532690882683, 0.056594107300043106, 0.2817663848400116, 0.46258658170700073, 0.1756022721529007, 0.6686252951622009, 0.14375798404216766, 0.1877184957265854, 0.0001491686562076211, 0.4709254503250122, 0.03602423146367073, 0.49285322427749634, 0.9982237219810486, 0.761058509349823, 0.23838776350021362, 0.9983181953430176, 0.007845253683626652, 0.8088265061378479, 0.18311969935894012, 0.6446053385734558, 0.3551006019115448, 0.9986882209777832, 0.054660946130752563, 0.1324605792760849, 0.7330603003501892, 0.07947634905576706, 0.060090046375989914, 0.07363146543502808, 0.1684214025735855, 0.04739496856927872, 0.6508344411849976, 0.9989246726036072, 0.9979679584503174, 0.9969179034233093, 0.9975730180740356, 0.9935178160667419, 0.9966016411781311, 0.06639356166124344, 0.07148119062185287, 0.5876212120056152, 0.2742232084274292, 0.8050674200057983, 0.07680679857730865, 0.11810077726840973, 0.9995701313018799, 0.03847251459956169, 0.0974571630358696, 0.6627675890922546, 0.04789435863494873, 0.15349748730659485, 0.040690552443265915, 0.884260356426239, 0.05101501941680908, 0.023685544729232788, 0.9966411590576172, 0.9973266124725342, 0.05271199718117714, 0.1307157278060913, 0.21347732841968536, 0.5164774060249329, 0.08664299547672272, 0.04933807998895645, 0.048022396862506866, 0.8799720406532288, 0.02280515618622303, 0.9968669414520264, 0.998211145401001, 0.06663217395544052, 0.9328504204750061, 0.043180085718631744, 0.9559177756309509, 0.9020195603370667, 0.09723786264657974, 0.06349903345108032, 0.12936286628246307, 0.48872360587120056, 0.1555507481098175, 0.16282029449939728, 0.05896255001425743, 0.10842403024435043, 0.48829934000968933, 0.029788663610816002, 0.31454145908355713, 0.256801575422287, 0.7427382469177246, 0.12270203232765198, 0.8775054812431335, 0.9989173412322998, 0.9990118145942688, 0.9972051382064819, 0.997448742389679, 0.057312387973070145, 0.18881399929523468, 0.2324182540178299, 0.21843458712100983, 0.3030254542827606, 0.9988575577735901, 0.010353469289839268, 0.9887562990188599, 0.8782396912574768, 0.0860196128487587, 0.03564052656292915, 0.01194697991013527, 0.9872549772262573, 0.9961361885070801, 0.9984509348869324, 0.9989979267120361, 0.13181254267692566, 0.08407466858625412, 0.5635203123092651, 0.2206210047006607, 0.8200580477714539, 0.018464351072907448, 0.16136237978935242, 0.04320405051112175, 0.0856880396604538, 0.6095371842384338, 0.10656999796628952, 0.15505453944206238, 0.9977208971977234, 0.1280127614736557, 0.05287483334541321, 0.11873646825551987, 0.7003596425056458, 0.062129948288202286, 0.12032444030046463, 0.29105618596076965, 0.25555336475372314, 0.2709602415561676, 0.4450734257698059, 0.4050403833389282, 0.14987166225910187, 0.9995318055152893, 0.9958873987197876, 0.9978442192077637, 0.2127947211265564, 0.09735706448554993, 0.3149203062057495, 0.0466916523873806, 0.32823237776756287, 0.014873617328703403, 0.07095213234424591, 0.5658379197120667, 0.16574475169181824, 0.18253985047340393, 0.9995840787887573, 0.9958904981613159], \"Term\": [\"4pm\", \"ale\", \"ale\", \"alinea\", \"also\", \"also\", \"also\", \"also\", \"also\", \"always\", \"always\", \"always\", \"always\", \"amazement\", \"andouille\", \"andrea\", \"annoy\", \"annoy\", \"apologize\", \"apology\", \"arrive\", \"arrive\", \"arrive\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"asparagus\", \"atmosphere\", \"atmosphere\", \"atmosphere\", \"atmosphere\", \"attempt\", \"attitude\", \"back\", \"back\", \"back\", \"back\", \"back\", \"bar\", \"bar\", \"bar\", \"bartender\", \"bartender\", \"bayless\", \"beef\", \"beef\", \"beef\", \"beef\", \"beer\", \"beer\", \"beer\", \"beer\", \"beet\", \"behind\", \"behind\", \"behind\", \"belgian\", \"belly\", \"belly\", \"benedict\", \"best\", \"best\", \"best\", \"best\", \"best\", \"bier\", \"bill\", \"bill\", \"bloody\", \"bone\", \"bongo\", \"bourdain\", \"braise\", \"brazzaz\", \"bread\", \"bread\", \"bread\", \"breakfast\", \"brew\", \"brew\", \"brunch\", \"buddha\", \"bun\", \"bun\", \"burger\", \"burrito\", \"burrito\", \"butter\", \"butter\", \"byob\", \"byob\", \"byob\", \"cafe\", \"cafe\", \"cake\", \"cake\", \"call\", \"call\", \"call\", \"call\", \"call\", \"card\", \"carne\", \"carrot\", \"cash\", \"cash\", \"cash\", \"cauliflower\", \"chair\", \"charge\", \"charge\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"chicago\", \"chicago\", \"chicago\", \"chicago\", \"chicago\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chinese\", \"chinese\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"churros\", \"coffee\", \"coffee\", \"coffee\", \"come\", \"come\", \"come\", \"come\", \"come\", \"contact\", \"cook\", \"cook\", \"cook\", \"cook\", \"cook\", \"corncakes\", \"costa\", \"course\", \"course\", \"cream\", \"cream\", \"cream\", \"creamy\", \"crisp\", \"crisp\", \"crust\", \"crust\", \"cuban\", \"cucumber\", \"cupcake\", \"curtain\", \"customer\", \"customer\", \"dawg\", \"day\", \"day\", \"day\", \"day\", \"day\", \"deep\", \"deep\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delivery\", \"delivery\", \"dessert\", \"dessert\", \"dessert\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"diner\", \"diner\", \"diner\", \"dinner\", \"dinner\", \"dinner\", \"dish\", \"dish\", \"dish\", \"dish\", \"dog\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"doug\", \"dougs\", \"drink\", \"drink\", \"drink\", \"duck\", \"duck\", \"eat\", \"eat\", \"eat\", \"eat\", \"eat\", \"eggplant\", \"empanadas\", \"empty\", \"encased\", \"enchilada\", \"even\", \"even\", \"even\", \"even\", \"even\", \"eventually\", \"excellent\", \"excellent\", \"excellent\", \"excellent\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"factory\", \"falafel\", \"fat\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"favorite\", \"feta\", \"filet\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"foie\", \"foie\", \"fois\", \"food\", \"food\", \"food\", \"food\", \"food\", \"fox\", \"freezing\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"frontera\", \"fry\", \"fry\", \"fry\", \"fry\", \"garcias\", \"gejas\", \"get\", \"get\", \"get\", \"get\", \"get\", \"ginos\", \"giordanos\", \"give\", \"give\", \"give\", \"give\", \"give\", \"glenn\", \"go\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gourmet\", \"gourmet\", \"gourmet\", \"gourmet\", \"gras\", \"gras\", \"great\", \"great\", \"great\", \"great\", \"great\", \"hamcrumbs\", \"happen\", \"happen\", \"happen\", \"hopleaf\", \"hostess\", \"hot\", \"hot\", \"hot\", \"hotdog\", \"hour\", \"hour\", \"hour\", \"ignore\", \"im\", \"im\", \"im\", \"im\", \"im\", \"indian\", \"inform\", \"ive\", \"ive\", \"ive\", \"ive\", \"ive\", \"jazz\", \"jones\", \"kendall\", \"ketchup\", \"kimchi\", \"kimchi\", \"know\", \"know\", \"know\", \"know\", \"know\", \"korean\", \"kumas\", \"lamb\", \"lamb\", \"later\", \"later\", \"later\", \"later\", \"later\", \"latin\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"lemon\", \"lemon\", \"like\", \"like\", \"like\", \"like\", \"like\", \"line\", \"line\", \"line\", \"line\", \"little\", \"little\", \"little\", \"little\", \"little\", \"lobster\", \"lobster\", \"lockdown\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lux\", \"make\", \"make\", \"make\", \"make\", \"make\", \"manager\", \"marrow\", \"mary\", \"mash\", \"mash\", \"mayan\", \"meal\", \"meal\", \"meal\", \"meal\", \"meat\", \"meat\", \"meat\", \"meat\", \"meat\", \"menu\", \"menu\", \"menu\", \"menu\", \"mexican\", \"milanesa\", \"minute\", \"minute\", \"minute\", \"mistake\", \"mistake\", \"mojitos\", \"mole\", \"morning\", \"morning\", \"morning\", \"naan\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"noodle\", \"nuke\", \"oatmeal\", \"octopus\", \"oil\", \"oil\", \"oil\", \"omelet\", \"omelette\", \"one\", \"one\", \"one\", \"one\", \"one\", \"order\", \"order\", \"order\", \"order\", \"order\", \"outdoor\", \"oven\", \"pancake\", \"party\", \"party\", \"party\", \"patio\", \"patio\", \"patty\", \"patty\", \"pay\", \"pay\", \"pay\", \"pay\", \"peking\", \"people\", \"people\", \"people\", \"people\", \"pepperoni\", \"pequods\", \"pho\", \"phone\", \"pig\", \"pita\", \"pizza\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plate\", \"plate\", \"plate\", \"policy\", \"poor\", \"poor\", \"pork\", \"pork\", \"potato\", \"potato\", \"pretentious\", \"price\", \"price\", \"price\", \"price\", \"price\", \"purple\", \"q\", \"really\", \"really\", \"really\", \"really\", \"really\", \"receive\", \"receive\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"regular\", \"regular\", \"regular\", \"regular\", \"regular\", \"reservation\", \"reservation\", \"reservation\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"reuben\", \"review\", \"review\", \"review\", \"review\", \"review\", \"revolution\", \"rib\", \"rib\", \"rib\", \"rican\", \"rice\", \"rice\", \"rice\", \"rick\", \"risotto\", \"roast\", \"roll\", \"roll\", \"roll\", \"ropa\", \"rude\", \"salad\", \"salad\", \"salad\", \"salad\", \"salsa\", \"sandwich\", \"sandwich\", \"sandwich\", \"sandwich\", \"sassy\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"sauerkraut\", \"sausage\", \"sausage\", \"sausage\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scallop\", \"scramble\", \"sea\", \"seat\", \"seat\", \"seat\", \"sel\", \"seoul\", \"serve\", \"serve\", \"serve\", \"serve\", \"serve\", \"server\", \"server\", \"server\", \"service\", \"service\", \"service\", \"service\", \"shaws\", \"shrimp\", \"shrimp\", \"sincere\", \"sit\", \"sit\", \"sit\", \"slice\", \"slice\", \"slider\", \"soup\", \"soup\", \"soup\", \"soup\", \"spot\", \"spot\", \"spot\", \"spot\", \"spot\", \"sprout\", \"squash\", \"struggle\", \"stupid\", \"sultan\", \"superdawg\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"table\", \"table\", \"table\", \"taco\", \"take\", \"take\", \"take\", \"take\", \"take\", \"talk\", \"talk\", \"talk\", \"talk\", \"tank\", \"tart\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"tell\", \"tell\", \"tell\", \"tell\", \"tempura\", \"ten\", \"tender\", \"tender\", \"terrible\", \"terrible\", \"thin\", \"thin\", \"think\", \"think\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"time\", \"time\", \"toast\", \"toast\", \"topping\", \"topping\", \"torta\", \"tortas\", \"tortilla\", \"trout\", \"try\", \"try\", \"try\", \"try\", \"try\", \"tuna\", \"understand\", \"understand\", \"us\", \"us\", \"us\", \"vegan\", \"vegan\", \"vieja\", \"vietnamese\", \"violet\", \"wait\", \"wait\", \"wait\", \"wait\", \"waitress\", \"waitress\", \"waitress\", \"want\", \"want\", \"want\", \"want\", \"want\", \"wear\", \"weekend\", \"weekend\", \"weekend\", \"weekend\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wine\", \"wine\", \"wine\", \"wing\", \"wishbone\", \"woman\", \"worth\", \"worth\", \"worth\", \"worth\", \"worth\", \"would\", \"would\", \"would\", \"would\", \"would\", \"xoco\", \"yucca\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1648818661773835445362739816\", ldavis_el1648818661773835445362739816_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1648818661773835445362739816\", ldavis_el1648818661773835445362739816_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1648818661773835445362739816\", ldavis_el1648818661773835445362739816_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_display = pyLDAvis.gensim.prepare(real_model, real_corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1648818666316444085759733157\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1648818666316444085759733157_data = {\"mdsDat\": {\"x\": [0.19262501512520128, 0.1812697956629397, -0.18779415100724717, 0.11343479943494295, -0.2995354592158369], \"y\": [0.05466229751650265, 0.029759086390815048, 0.09015275905478008, -0.12418505583025802, -0.05038908713183989], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [2.5354104042053223, 0.6149008870124817, 19.92186164855957, 3.7512288093566895, 73.17660522460938]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [2730.0, 3722.0, 1471.0, 471.0, 3146.0, 854.0, 503.0, 325.0, 3468.0, 777.0, 405.0, 835.0, 417.0, 580.0, 1486.0, 1346.0, 813.0, 705.0, 494.0, 228.0, 338.0, 428.0, 1490.0, 942.0, 1866.0, 656.0, 471.0, 1555.0, 687.0, 479.0, 21.789506912231445, 21.262340545654297, 19.041423797607422, 13.968194007873535, 11.763520240783691, 12.14721393585205, 11.322790145874023, 10.674556732177734, 9.7822904586792, 9.53738784790039, 9.604158401489258, 9.398691177368164, 9.429798126220703, 9.335832595825195, 9.175008773803711, 9.041350364685059, 9.164857864379883, 8.633801460266113, 8.570825576782227, 8.569964408874512, 8.567536354064941, 8.40815544128418, 8.407007217407227, 8.27271842956543, 8.27244758605957, 8.333860397338867, 8.2717924118042, 8.037357330322266, 8.037357330322266, 8.037357330322266, 8.497454643249512, 8.037357330322266, 8.037357330322266, 8.26539134979248, 8.037357330322266, 8.097138404846191, 9.466949462890625, 18.270051956176758, 21.484458923339844, 8.981675148010254, 11.069226264953613, 11.173314094543457, 10.700565338134766, 10.014644622802734, 8.966781616210938, 9.117191314697266, 8.880721092224121, 8.92286491394043, 2.890350103378296, 2.9268832206726074, 2.7156436443328857, 2.6382458209991455, 2.6382458209991455, 2.6382458209991455, 2.9320902824401855, 0.8069727420806885, 0.6832049489021301, 0.8959062695503235, 0.5485672354698181, 0.513135552406311, 0.4868886172771454, 0.4773118495941162, 0.4361582100391388, 0.33213546872138977, 0.2965778410434723, 0.29257506132125854, 0.2548733651638031, 0.2878343462944031, 0.25786176323890686, 0.25786176323890686, 0.2744031548500061, 0.2352241724729538, 0.2217605710029602, 0.2192671149969101, 0.1987018585205078, 0.19654037058353424, 0.17762330174446106, 0.17762330174446106, 0.17762330174446106, 0.18058958649635315, 1.458494782447815, 0.21043534576892853, 136.38833618164062, 108.00791931152344, 104.33362579345703, 94.08878326416016, 75.54481506347656, 69.87476348876953, 67.93539428710938, 66.46426391601562, 60.995361328125, 63.329345703125, 58.640323638916016, 52.95732879638672, 53.36874008178711, 61.279510498046875, 51.54701232910156, 49.333675384521484, 47.64512252807617, 47.47429275512695, 44.047847747802734, 43.17851638793945, 41.767669677734375, 42.097774505615234, 42.00103759765625, 41.6364631652832, 40.581722259521484, 39.34126663208008, 38.707275390625, 38.090763092041016, 37.983402252197266, 35.810062408447266, 42.15584182739258, 114.15807342529297, 126.74752807617188, 89.64810180664062, 141.36508178710938, 155.27076721191406, 345.28680419921875, 137.16835021972656, 540.66552734375, 1359.6763916015625, 159.37071228027344, 154.19252014160156, 99.864013671875, 712.0446166992188, 337.8494567871094, 165.07191467285156, 71.59889221191406, 1050.9837646484375, 357.415771484375, 240.53060913085938, 235.6584930419922, 776.8485717773438, 308.8751525878906, 190.933349609375, 205.21026611328125, 395.2692565917969, 285.4117736816406, 398.8389892578125, 615.3240356445312, 225.84666442871094, 289.7274169921875, 243.47032165527344, 354.79736328125, 325.3790283203125, 327.5240173339844, 392.4418029785156, 354.82501220703125, 230.3009490966797, 218.99070739746094, 248.7748260498047, 194.94422912597656, 274.28741455078125, 268.4269714355469, 212.13352966308594, 256.4777526855469, 222.724365234375, 56.56989288330078, 41.78849792480469, 29.343446731567383, 26.068960189819336, 20.93374252319336, 20.666711807250977, 20.309396743774414, 18.528169631958008, 14.9090576171875, 12.172638893127441, 12.219842910766602, 11.915910720825195, 11.439452171325684, 10.593550682067871, 10.453411102294922, 10.340595245361328, 10.402104377746582, 10.359119415283203, 9.975910186767578, 9.942212104797363, 10.039769172668457, 9.791560173034668, 9.80008602142334, 9.739326477050781, 9.55145263671875, 9.613485336303711, 9.309563636779785, 9.506580352783203, 9.199049949645996, 9.198667526245117, 9.37099838256836, 9.320154190063477, 26.929428100585938, 9.425178527832031, 19.11092185974121, 18.28279685974121, 52.34953308105469, 132.9373779296875, 29.256072998046875, 34.44093704223633, 28.414697647094727, 83.08992004394531, 24.651628494262695, 54.1541748046875, 27.459514617919922, 17.594491958618164, 14.111701011657715, 17.260122299194336, 18.42394256591797, 17.718738555908203, 51.619136810302734, 20.321657180786133, 26.526155471801758, 39.28267288208008, 25.984661102294922, 34.43539047241211, 31.975109100341797, 34.95530700683594, 24.011581420898438, 26.112777709960938, 27.60076332092285, 22.19668197631836, 23.696531295776367, 21.413612365722656, 1490.0211181640625, 784.5236206054688, 660.3150024414062, 617.0899658203125, 584.8765258789062, 536.8053588867188, 530.6821899414062, 505.9403076171875, 484.04803466796875, 473.46966552734375, 458.8448486328125, 403.84954833984375, 404.06884765625, 355.937255859375, 353.73394775390625, 353.76123046875, 322.2170104980469, 301.4967041015625, 298.6916809082031, 295.40008544921875, 282.64666748046875, 269.30902099609375, 270.63433837890625, 266.87725830078125, 277.220703125, 259.7371520996094, 257.364501953125, 304.06689453125, 257.702880859375, 247.45407104492188, 337.7953796386719, 309.7474365234375, 1118.883544921875, 1310.1287841796875, 568.602783203125, 1323.6993408203125, 879.533447265625, 792.0966186523438, 1584.806884765625, 726.0161743164062, 1227.8687744140625, 1474.963134765625, 523.1885375976562, 962.9268188476562, 934.9560546875, 3100.71875, 2158.3310546875, 872.0465087890625, 2521.576416015625, 1683.808349609375, 921.35498046875, 1136.62158203125, 2853.1953125, 1767.3582763671875, 1749.478515625, 1234.97509765625, 931.8847045898438, 782.330322265625, 752.5223388671875, 2369.712158203125, 2670.96142578125, 1511.391845703125, 1123.130615234375, 1227.06494140625, 1189.7352294921875, 1087.0067138671875, 944.5618896484375, 1363.2252197265625, 936.552978515625], \"Term\": [\"great\", \"food\", \"love\", \"course\", \"good\", \"always\", \"wine\", \"dessert\", \"place\", \"menu\", \"work\", \"price\", \"fresh\", \"favorite\", \"restaurant\", \"best\", \"delicious\", \"taste\", \"many\", \"cake\", \"flavor\", \"special\", \"us\", \"also\", \"service\", \"server\", \"atmosphere\", \"try\", \"little\", \"everything\", \"ear\", \"concert\", \"screen\", \"lockdown\", \"uncommon\", \"pain\", \"holy\", \"adore\", \"appreciation\", \"washington\", \"interact\", \"royalty\", \"connoisseur\", \"rj\", \"albany\", \"masterpiece\", \"ppl\", \"againi\", \"hoppin\", \"hike\", \"convey\", \"remotely\", \"sustenance\", \"plug\", \"glare\", \"superfriendly\", \"closet\", \"crue\", \"waitressservers\", \"woohooone\", \"dope\", \"wussy\", \"motley\", \"lotta\", \"hoarse\", \"bongo\", \"sweetheart\", \"level\", \"play\", \"bitch\", \"culinary\", \"alinea\", \"hummus\", \"noise\", \"rat\", \"ground\", \"jack\", \"alot\", \"approve\", \"whoopercheesie\", \"cory\", \"reservationgo\", \"unbelieve\", \"uphttpforksandcorkschicagocom20110114schwachicagostinypieceofculinaryheaven\", \"trade\", \"falcon\", \"frank\", \"colombian\", \"humus\", \"laughter\", \"presidentdoug\", \"pasadita\", \"emporium\", \"911\", \"dey\", \"muscle\", \"caption\", \"soundbar\", \"surf\", \"turf\", \"resonable\", \"outfit\", \"yummmmm\", \"detour\", \"greatjust\", \"hottie\", \"choclate\", \"hadwine\", \"autograph\", \"uneducated\", \"blog\", \"monk\", \"margarita\", \"pasta\", \"lamb\", \"pho\", \"vietnamese\", \"chop\", \"greek\", \"homemade\", \"mojitos\", \"salsa\", \"28\", \"tres\", \"thai\", \"bone\", \"relax\", \"pic\", \"tofu\", \"mole\", \"ropa\", \"vibe\", \"vieja\", \"organic\", \"spice\", \"yum\", \"honey\", \"coconut\", \"nana\", \"vietnam\", \"freeze\", \"lech\", \"juicy\", \"byob\", \"burrito\", \"tender\", \"cafe\", \"rib\", \"fresh\", \"spicy\", \"always\", \"great\", \"portion\", \"mexican\", \"shrimp\", \"love\", \"favorite\", \"amazing\", \"cuisine\", \"food\", \"price\", \"everything\", \"atmosphere\", \"good\", \"menu\", \"wonderful\", \"special\", \"best\", \"delicious\", \"restaurant\", \"place\", \"salad\", \"also\", \"little\", \"service\", \"make\", \"try\", \"go\", \"get\", \"ive\", \"dinner\", \"well\", \"friendly\", \"like\", \"one\", \"taste\", \"time\", \"eat\", \"fondue\", \"gejas\", \"anniversary\", \"mastros\", \"cornbread\", \"basket\", \"background\", \"pairing\", \"graham\", \"elliot\", \"preparation\", \"dill\", \"competition\", \"unexpected\", \"restroom\", \"passion\", \"handful\", \"omelette\", \"carte\", \"tooth\", \"fear\", \"ganache\", \"component\", \"flake\", \"gorgonzola\", \"bloody\", \"tremendous\", \"involve\", \"reminiscent\", \"ceasar\", \"mary\", \"stain\", \"pot\", \"addictive\", \"surprised\", \"beginning\", \"chocolate\", \"course\", \"tasting\", \"flavorful\", \"romantic\", \"dessert\", \"present\", \"cake\", \"exceptional\", \"torta\", \"popcorn\", \"pace\", \"pleasantly\", \"texture\", \"wine\", \"melt\", \"instead\", \"work\", \"white\", \"flavor\", \"many\", \"menu\", \"din\", \"special\", \"taste\", \"isnt\", \"delicious\", \"server\", \"us\", \"ask\", \"minute\", \"hour\", \"see\", \"seat\", \"beer\", \"seem\", \"long\", \"waitress\", \"reservation\", \"next\", \"review\", \"line\", \"else\", \"check\", \"pay\", \"call\", \"money\", \"guy\", \"let\", \"dog\", \"show\", \"20\", \"party\", \"bill\", \"put\", \"birthday\", \"10\", \"wont\", \"around\", \"actually\", \"pizza\", \"table\", \"serve\", \"back\", \"people\", \"meal\", \"come\", \"tell\", \"would\", \"wait\", \"find\", \"want\", \"never\", \"go\", \"time\", \"drink\", \"get\", \"order\", \"dont\", \"take\", \"place\", \"one\", \"like\", \"say\", \"even\", \"bar\", \"know\", \"good\", \"food\", \"service\", \"really\", \"try\", \"make\", \"restaurant\", \"eat\", \"great\", \"best\"], \"Total\": [2730.0, 3722.0, 1471.0, 471.0, 3146.0, 854.0, 503.0, 325.0, 3468.0, 777.0, 405.0, 835.0, 417.0, 580.0, 1486.0, 1346.0, 813.0, 705.0, 494.0, 228.0, 338.0, 428.0, 1490.0, 942.0, 1866.0, 656.0, 471.0, 1555.0, 687.0, 479.0, 22.23584747314453, 21.70320701599121, 19.48282241821289, 14.41266918182373, 12.20639419555664, 12.610936164855957, 11.765925407409668, 11.121830940246582, 10.230961799621582, 9.977682113647461, 10.058147430419922, 9.846694946289062, 9.879683494567871, 9.78400707244873, 9.617585182189941, 9.4788236618042, 9.608658790588379, 9.071598052978516, 9.007697105407715, 9.009626388549805, 9.012848854064941, 8.845776557922363, 8.846284866333008, 8.709531784057617, 8.709956169128418, 8.774727821350098, 8.710670471191406, 8.474284172058105, 8.474284172058105, 8.474284172058105, 8.959705352783203, 8.474284172058105, 8.474284172058105, 8.720853805541992, 8.474284172058105, 8.547406196594238, 10.387458801269531, 51.21414566040039, 125.39557647705078, 11.232705116271973, 23.97835350036621, 29.395305633544922, 24.703134536743164, 31.439929962158203, 20.864856719970703, 31.519363403320312, 18.858081817626953, 26.166141510009766, 3.376786470413208, 3.4434874057769775, 3.1985104084014893, 3.122417688369751, 3.122417688369751, 3.122417688369751, 3.5723037719726562, 1.2909736633300781, 1.2030282020568848, 1.5813425779342651, 1.062032699584961, 0.9971882700920105, 0.9703124761581421, 0.9745806455612183, 0.9440275430679321, 0.8176124691963196, 0.780695378780365, 0.8058037757873535, 0.7404833436012268, 0.8395308256149292, 0.7530673742294312, 0.7530673742294312, 0.8023264408111572, 0.7431365847587585, 0.7105080485343933, 0.7035402655601501, 0.6824965476989746, 0.6906473636627197, 0.6627349257469177, 0.6627349257469177, 0.6627349257469177, 0.6785888671875, 14.253132820129395, 1.0232998132705688, 136.75186157226562, 108.37571716308594, 104.72428894042969, 94.45252227783203, 75.90931701660156, 70.24205017089844, 68.30034637451172, 66.83307647705078, 61.3577766418457, 63.71976089477539, 59.003971099853516, 53.319149017333984, 53.734622955322266, 61.71091079711914, 51.91307830810547, 49.695125579833984, 48.007835388183594, 47.838802337646484, 44.410667419433594, 43.54583740234375, 42.13008117675781, 42.46422576904297, 42.36790084838867, 42.00401306152344, 40.950904846191406, 39.705474853515625, 39.074562072753906, 38.45238494873047, 38.35347366333008, 36.171600341796875, 42.6092529296875, 116.9615707397461, 130.2393035888672, 92.59199523925781, 151.2716827392578, 171.11158752441406, 417.14703369140625, 168.98153686523438, 854.7533569335938, 2730.5771484375, 209.780517578125, 202.67282104492188, 121.37052154541016, 1471.062744140625, 580.9634399414062, 251.17022705078125, 82.01628112792969, 3722.3876953125, 835.3466796875, 479.10504150390625, 471.9110412597656, 3146.9375, 777.4635009765625, 368.34918212890625, 428.2895812988281, 1346.4139404296875, 813.1744384765625, 1486.4237060546875, 3468.6904296875, 552.301513671875, 942.2035522460938, 687.89453125, 1866.372314453125, 1524.462158203125, 1555.265380859375, 3493.35107421875, 2876.5751953125, 767.340087890625, 657.4852905273438, 1099.86083984375, 468.61846923828125, 2023.944091796875, 2039.8907470703125, 705.6429443359375, 2414.97900390625, 1167.4564208984375, 57.00820541381836, 42.22447967529297, 29.78453826904297, 26.50901222229004, 21.373958587646484, 21.108840942382812, 20.751163482666016, 18.974061965942383, 15.34746265411377, 12.607982635498047, 12.662345886230469, 12.36594009399414, 11.879584312438965, 11.03671646118164, 10.900232315063477, 10.783247947692871, 10.851962089538574, 10.810741424560547, 10.413484573364258, 10.380824089050293, 10.48338508605957, 10.227582931518555, 10.239328384399414, 10.18033504486084, 9.990568161010742, 10.059810638427734, 9.746197700500488, 9.954534530639648, 9.634954452514648, 9.635237693786621, 9.817127227783203, 9.764801979064941, 33.79974365234375, 9.894702911376953, 24.162702560424805, 23.19294548034668, 108.09043884277344, 471.3675842285156, 52.725341796875, 69.39073944091797, 55.27158737182617, 325.8759460449219, 46.42112731933594, 228.61996459960938, 68.4134750366211, 30.116191864013672, 19.776700973510742, 29.857805252075195, 35.3489875793457, 33.814537048339844, 503.1587219238281, 50.41596984863281, 118.53939819335938, 405.7757568359375, 123.5722427368164, 338.431640625, 494.4876708984375, 777.4635009765625, 187.906005859375, 428.2895812988281, 705.6429443359375, 204.75021362304688, 813.1744384765625, 656.604248046875, 1490.3936767578125, 784.8407592773438, 660.632080078125, 617.4091186523438, 585.1959228515625, 537.1220703125, 530.9989624023438, 506.258056640625, 484.3669738769531, 473.7877502441406, 459.16204833984375, 404.16748046875, 404.3882141113281, 356.25592041015625, 354.052490234375, 354.0813293457031, 322.5334777832031, 301.81292724609375, 299.0105285644531, 295.71820068359375, 282.96337890625, 269.6249694824219, 270.9527893066406, 267.193115234375, 277.54974365234375, 260.05255126953125, 257.6812744140625, 304.4435729980469, 258.02313232421875, 247.773681640625, 338.345703125, 310.1761779785156, 1139.796630859375, 1346.016845703125, 576.0723266601562, 1372.260009765625, 909.722900390625, 816.849365234375, 1674.0467529296875, 748.90087890625, 1297.83837890625, 1571.2181396484375, 534.0776977539062, 1018.224853515625, 987.9620971679688, 3493.35107421875, 2414.97900390625, 924.1239013671875, 2876.5751953125, 1864.71826171875, 984.7918701171875, 1243.3079833984375, 3468.6904296875, 2039.8907470703125, 2023.944091796875, 1375.3218994140625, 1012.4342041015625, 828.6456909179688, 792.91064453125, 3146.9375, 3722.3876953125, 1866.372314453125, 1296.788818359375, 1555.265380859375, 1524.462158203125, 1486.4237060546875, 1167.4564208984375, 2730.5771484375, 1346.4139404296875], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.6545000076293945, 3.6542999744415283, 3.651900053024292, 3.6435000896453857, 3.6379001140594482, 3.637399911880493, 3.636399984359741, 3.6338000297546387, 3.630000114440918, 3.629699945449829, 3.6285998821258545, 3.628200054168701, 3.628200054168701, 3.6278998851776123, 3.627700090408325, 3.6275999546051025, 3.627500057220459, 3.6254000663757324, 3.6250998973846436, 3.624799966812134, 3.6240999698638916, 3.6240999698638916, 3.6238999366760254, 3.6233999729156494, 3.623300075531006, 3.623300075531006, 3.6231000423431396, 3.6219000816345215, 3.6219000816345215, 3.6219000816345215, 3.621799945831299, 3.6219000816345215, 3.6219000816345215, 3.6212000846862793, 3.6219000816345215, 3.620699882507324, 3.5820000171661377, 2.6440999507904053, 1.9106999635696411, 3.451200008392334, 2.9017999172210693, 2.7074999809265137, 2.838200092315674, 2.5308001041412354, 2.8303000926971436, 2.4344000816345215, 2.921799898147583, 2.5989999771118164, 4.9359002113342285, 4.928899765014648, 4.927800178527832, 4.922999858856201, 4.922999858856201, 4.922999858856201, 4.894000053405762, 4.621600151062012, 4.525700092315674, 4.5233001708984375, 4.430799961090088, 4.42710018157959, 4.401899814605713, 4.377600193023682, 4.319300174713135, 4.1905999183654785, 4.123600006103516, 4.0782999992370605, 4.024899959564209, 4.020999908447266, 4.019700050354004, 4.019700050354004, 4.018499851226807, 3.9410998821258545, 3.9270999431610107, 3.925600051879883, 3.8575000762939453, 3.834700107574463, 3.7748000621795654, 3.7748000621795654, 3.7748000621795654, 3.767699956893921, 2.8118999004364014, 3.5099000930786133, 1.610700011253357, 1.6100000143051147, 1.6095999479293823, 1.6095000505447388, 1.6085000038146973, 1.6081000566482544, 1.6080000400543213, 1.607800006866455, 1.6073999404907227, 1.607200026512146, 1.607200026512146, 1.6065000295639038, 1.6065000295639038, 1.6062999963760376, 1.6062999963760376, 1.6060999631881714, 1.6058000326156616, 1.6057000160217285, 1.6051000356674194, 1.6049000024795532, 1.604699969291687, 1.604699969291687, 1.604699969291687, 1.604599952697754, 1.6043000221252441, 1.604099988937378, 1.6038999557495117, 1.6038999557495117, 1.603700041770935, 1.6032999753952026, 1.6026999950408936, 1.5891000032424927, 1.5861999988555908, 1.5809999704360962, 1.5456000566482544, 1.5161999464035034, 1.424299955368042, 1.4048000574111938, 1.1553000211715698, 0.916100025177002, 1.3385000228881836, 1.340000033378601, 1.4183000326156616, 0.8877999782562256, 1.0713000297546387, 1.193600058555603, 1.4774999618530273, 0.34869998693466187, 0.7644000053405762, 0.9243000149726868, 0.9189000129699707, 0.21439999341964722, 0.6902999877929688, 0.9562000036239624, 0.8776000142097473, 0.38769999146461487, 0.5662999749183655, 0.2978000044822693, -0.11599999666213989, 0.7190999984741211, 0.4341000020503998, 0.5746999979019165, -0.04690000042319298, 0.06889999657869339, 0.05550000071525574, -0.5728999972343445, -0.47940000891685486, 0.4097999930381775, 0.5139999985694885, 0.12700000405311584, 0.736299991607666, -0.38530001044273376, -0.4147000014781952, 0.4115000069141388, -0.6291000247001648, -0.043299999088048935, 3.275399923324585, 3.272700071334839, 3.268199920654297, 3.2662999629974365, 3.2623000144958496, 3.261899948120117, 3.2616000175476074, 3.2592999935150146, 3.2541000843048096, 3.2479000091552734, 3.247499942779541, 3.246000051498413, 3.245300054550171, 3.2421000003814697, 3.2411999702453613, 3.2411999702453613, 3.2407000064849854, 3.2404000759124756, 3.2402000427246094, 3.2399001121520996, 3.239799976348877, 3.239500045776367, 3.2392001152038574, 3.238800048828125, 3.238100051879883, 3.2376999855041504, 3.237299919128418, 3.236999988555908, 3.236799955368042, 3.2367000579833984, 3.236599922180176, 3.2365000247955322, 3.0559000968933105, 3.234499931335449, 3.0485000610351562, 3.0452001094818115, 2.5580999851226807, 2.0172998905181885, 2.6940999031066895, 2.5826001167297363, 2.6177000999450684, 1.9164999723434448, 2.6501998901367188, 1.842900037765503, 2.3701999187469482, 2.7455999851226807, 2.9456000328063965, 2.734999895095825, 2.631500005722046, 2.6368000507354736, 1.006100058555603, 2.374500036239624, 1.7860000133514404, 0.9480999708175659, 1.7237999439239502, 0.9977999925613403, 0.5444999933242798, 0.181099995970726, 1.2257000207901, 0.48570001125335693, 0.04179999977350235, 1.0612000226974487, -0.2524999976158142, -0.14000000059604645, 0.31200000643730164, 0.31189998984336853, 0.3118000030517578, 0.3118000030517578, 0.3116999864578247, 0.3116999864578247, 0.3116999864578247, 0.3116999864578247, 0.311599999666214, 0.311599999666214, 0.311599999666214, 0.31150001287460327, 0.31150001287460327, 0.31139999628067017, 0.31139999628067017, 0.31139999628067017, 0.31130000948905945, 0.31119999289512634, 0.31119999289512634, 0.31119999289512634, 0.31119999289512634, 0.3111000061035156, 0.3111000061035156, 0.3111000061035156, 0.3111000061035156, 0.3111000061035156, 0.3111000061035156, 0.3111000061035156, 0.3111000061035156, 0.3109999895095825, 0.310699999332428, 0.3109000027179718, 0.2937999963760376, 0.28529998660087585, 0.29919999837875366, 0.27630001306533813, 0.2784999907016754, 0.2815000116825104, 0.2574999928474426, 0.28130000829696655, 0.25690001249313354, 0.249099999666214, 0.29170000553131104, 0.2565000057220459, 0.257099986076355, 0.1931000053882599, 0.19990000128746033, 0.25429999828338623, 0.18060000240802765, 0.2101999968290329, 0.24570000171661377, 0.22259999811649323, 0.11699999868869781, 0.1688999980688095, 0.16660000383853912, 0.20469999313354492, 0.22939999401569366, 0.2547999918460846, 0.25999999046325684, 0.028599999845027924, -0.019600000232458115, 0.10130000114440918, 0.16850000619888306, 0.07530000060796738, 0.06440000236034393, -0.000699999975040555, 0.10040000081062317, -0.3824000060558319, -0.050700001418590546], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.877500057220459, -5.901899814605713, -6.01230001449585, -6.3221001625061035, -6.493899822235107, -6.4618000984191895, -6.532100200653076, -6.591000080108643, -6.678299903869629, -6.703700065612793, -6.696700096130371, -6.718299865722656, -6.715000152587891, -6.724999904632568, -6.742400169372559, -6.7571001052856445, -6.743500232696533, -6.803199768066406, -6.810500144958496, -6.8105998039245605, -6.8109002113342285, -6.829699993133545, -6.829800128936768, -6.845900058746338, -6.8460001945495605, -6.838600158691406, -6.8460001945495605, -6.874800205230713, -6.874800205230713, -6.874800205230713, -6.8190999031066895, -6.874800205230713, -6.874800205230713, -6.846799850463867, -6.874800205230713, -6.867400169372559, -6.711100101470947, -6.053599834442139, -5.891600131988525, -6.763700008392334, -6.554699897766113, -6.545400142669678, -6.588600158691406, -6.654799938201904, -6.765399932861328, -6.748700141906738, -6.775000095367432, -6.770299911499023, -6.480899810791016, -6.468299865722656, -6.5432000160217285, -6.5721001625061035, -6.5721001625061035, -6.5721001625061035, -6.4664998054504395, -7.756700038909912, -7.9232001304626465, -7.652200222015381, -8.1427001953125, -8.209400177001953, -8.26200008392334, -8.281800270080566, -8.371999740600586, -8.644399642944336, -8.757699966430664, -8.771300315856934, -8.909199714660645, -8.787599563598633, -8.897600173950195, -8.897600173950195, -8.835399627685547, -8.989500045776367, -9.048399925231934, -9.059700012207031, -9.15820026397705, -9.169099807739258, -9.270299911499023, -9.270299911499023, -9.270299911499023, -9.253800392150879, -7.16480016708374, -9.100799560546875, -6.104800224304199, -6.338099956512451, -6.372799873352051, -6.476099967956543, -6.6956000328063965, -6.773600101470947, -6.801799774169922, -6.823699951171875, -6.9095001220703125, -6.872000217437744, -6.94890022277832, -7.050899982452393, -7.043099880218506, -6.904900074005127, -7.077899932861328, -7.121699810028076, -7.156599998474121, -7.160200119018555, -7.235099792480469, -7.255000114440918, -7.2881999015808105, -7.280399799346924, -7.282700061798096, -7.291399955749512, -7.316999912261963, -7.348100185394287, -7.364299774169922, -7.38040018081665, -7.383200168609619, -7.4421000480651855, -7.2789998054504395, -6.282800197601318, -6.178100109100342, -6.524499893188477, -6.068999767303467, -5.975200176239014, -5.176000118255615, -6.099100112915039, -4.727499961853027, -3.805299997329712, -5.949100017547607, -5.982100009918213, -6.416500091552734, -4.452199935913086, -5.197700023651123, -5.914000034332275, -6.749300003051758, -4.062900066375732, -5.14139986038208, -5.537499904632568, -5.558000087738037, -4.365099906921387, -5.287399768829346, -5.768400192260742, -5.696300029754639, -5.040800094604492, -5.366399765014648, -5.031799793243408, -4.598199844360352, -5.600500106811523, -5.351399898529053, -5.525400161743164, -5.148799896240234, -5.235400199890137, -5.228799819946289, -5.047999858856201, -5.14870023727417, -5.580999851226807, -5.63129997253418, -5.503799915313721, -5.747600078582764, -5.406199932098389, -5.427800178527832, -5.663099765777588, -5.473299980163574, -5.6143999099731445, -5.315100193023682, -5.618000030517578, -5.971499919891357, -6.089900016784668, -6.309199810028076, -6.3221001625061035, -6.3394999504089355, -6.431300163269043, -6.648600101470947, -6.851399898529053, -6.847599983215332, -6.872700214385986, -6.91349983215332, -6.9903998374938965, -7.003699779510498, -7.014500141143799, -7.008600234985352, -7.012700080871582, -7.0503997802734375, -7.053800106048584, -7.044099807739258, -7.0690999031066895, -7.06820011138916, -7.074399948120117, -7.093900203704834, -7.087399959564209, -7.11959981918335, -7.098599910736084, -7.131499767303467, -7.1315999031066895, -7.11299991607666, -7.1184000968933105, -6.057400226593018, -7.1072001457214355, -6.400400161743164, -6.444699764251709, -5.3927001953125, -4.460700035095215, -5.9745001792907715, -5.811399936676025, -6.003699779510498, -4.930699825286865, -6.1458001136779785, -5.358799934387207, -6.037899971008301, -6.482999801635742, -6.70359992980957, -6.502200126647949, -6.436999797821045, -6.47599983215332, -5.406700134277344, -6.338900089263916, -6.072500228881836, -5.679800033569336, -6.093100070953369, -5.811500072479248, -5.885700225830078, -5.796500205993652, -6.172100067138672, -6.088200092315674, -6.032800197601318, -6.250699996948242, -6.185299873352051, -6.286600112915039, -5.014900207519531, -5.656300067901611, -5.828700065612793, -5.896399974822998, -5.949999809265137, -6.035799980163574, -6.0472002029418945, -6.09499979019165, -6.139200210571289, -6.161300182342529, -6.192699909210205, -6.320400238037109, -6.319799900054932, -6.446599960327148, -6.452899932861328, -6.4527997970581055, -6.546199798583984, -6.612599849700928, -6.622000217437744, -6.6331000328063965, -6.677199840545654, -6.725500106811523, -6.720600128173828, -6.734600067138672, -6.696599960327148, -6.76170015335083, -6.770899772644043, -6.6041998863220215, -6.769599914550781, -6.810200214385986, -6.499000072479248, -6.585599899291992, -5.301300048828125, -5.143499851226807, -5.9781999588012695, -5.133200168609619, -5.541999816894531, -5.646699905395508, -4.953199863433838, -5.733799934387207, -5.208399772644043, -5.025000095367432, -6.061500072479248, -5.451399803161621, -5.480899810791016, -4.2820000648498535, -4.6442999839782715, -5.550600051879883, -4.488800048828125, -4.892600059509277, -5.49560022354126, -5.285600185394287, -4.365200042724609, -4.844200134277344, -4.854300022125244, -5.202600002288818, -5.4842000007629395, -5.65910005569458, -5.697999954223633, -4.550899982452393, -4.43120002746582, -5.0005998611450195, -5.297500133514404, -5.209000110626221, -5.2399001121521, -5.3302001953125, -5.470699787139893, -5.103799819946289, -5.4791998863220215]}, \"token.table\": {\"Topic\": [5, 5, 3, 5, 4, 1, 1, 1, 1, 3, 4, 1, 5, 3, 5, 3, 5, 3, 5, 4, 1, 2, 5, 5, 3, 5, 3, 4, 5, 4, 3, 5, 4, 5, 4, 5, 3, 4, 5, 5, 5, 1, 5, 2, 5, 4, 3, 1, 3, 5, 3, 5, 3, 5, 3, 4, 5, 5, 4, 4, 5, 3, 4, 5, 3, 1, 3, 2, 3, 5, 4, 4, 1, 1, 1, 4, 2, 3, 4, 5, 1, 3, 5, 1, 4, 3, 4, 5, 3, 4, 5, 4, 3, 4, 5, 3, 5, 5, 3, 5, 1, 3, 5, 1, 3, 5, 4, 5, 3, 4, 5, 3, 4, 5, 3, 4, 2, 3, 5, 4, 3, 5, 4, 3, 4, 5, 3, 4, 5, 4, 3, 5, 2, 3, 3, 5, 3, 5, 4, 4, 3, 5, 1, 3, 5, 3, 5, 4, 4, 3, 4, 5, 3, 1, 4, 5, 5, 4, 1, 1, 1, 3, 3, 1, 5, 1, 4, 5, 2, 4, 5, 1, 4, 3, 4, 5, 3, 5, 1, 5, 3, 3, 5, 3, 2, 3, 5, 1, 5, 3, 5, 5, 3, 5, 1, 5, 1, 3, 4, 5, 3, 4, 5, 3, 4, 5, 3, 4, 1, 4, 3, 4, 5, 3, 4, 5, 3, 4, 5, 3, 5, 5, 3, 3, 5, 1, 3, 3, 5, 5, 1, 5, 4, 3, 4, 5, 3, 5, 3, 3, 4, 5, 1, 4, 5, 4, 3, 5, 3, 5, 3, 3, 3, 5, 3, 5, 1, 4, 5, 4, 5, 1, 4, 5, 3, 5, 3, 4, 1, 4, 4, 5, 3, 5, 5, 1, 3, 5, 3, 4, 5, 3, 4, 1, 5, 2, 3, 5, 4, 5, 3, 5, 1, 3, 4, 3, 1, 3, 4, 5, 3, 3, 5, 1, 5, 5, 5, 3, 5, 3, 4, 5, 3, 5, 5, 3, 5, 3, 4, 5, 3, 3, 5, 4, 1, 4, 5, 1, 1, 4, 3, 5, 3, 5, 3, 4, 5, 4, 5, 3, 5, 3, 5, 4, 5, 3, 3, 5, 3, 4, 4, 5, 2, 4, 3, 3, 4, 5, 2, 1, 4, 2, 5, 3, 3, 3, 3, 3, 5, 5, 1, 3, 5, 1, 3, 4, 5, 3, 4, 5, 2, 3, 4, 5, 3, 5, 5, 1, 3, 4, 5, 3, 5, 1, 3], \"Freq\": [0.9999103546142578, 0.9992772340774536, 0.9999327063560486, 0.9994320273399353, 0.9095776081085205, 0.9890457987785339, 0.9921074509620667, 0.9357858300209045, 0.3742094039916992, 0.5102855563163757, 0.10205711424350739, 0.343955934047699, 0.649694561958313, 0.3077891170978546, 0.691994845867157, 0.632931113243103, 0.36735743284225464, 0.6569250226020813, 0.3423972725868225, 0.9736595749855042, 0.977425217628479, 0.8884186148643494, 0.9989782571792603, 1.0002028942108154, 0.5000942349433899, 0.5000942349433899, 0.029148994013667107, 0.005829798988997936, 0.9648317098617554, 0.963801383972168, 0.055512264370918274, 0.9437085390090942, 0.9948438405990601, 1.0000019073486328, 0.7760980725288391, 0.21558278799057007, 0.29337188601493835, 0.01039799116551876, 0.6959226727485657, 0.9997979402542114, 0.9985430240631104, 0.8012317419052124, 0.17805150151252747, 0.07016001641750336, 0.9120801687240601, 0.9940544962882996, 0.9884799718856812, 0.9359564781188965, 0.9751280546188354, 0.02303452044725418, 0.9746791124343872, 0.025649450719356537, 0.9320977926254272, 0.06610622256994247, 0.2755664885044098, 0.23619984090328217, 0.4898959696292877, 0.9973065257072449, 0.9602933526039124, 0.93407142162323, 0.9997702836990356, 0.1850302368402481, 0.4810786247253418, 0.3238029181957245, 0.9965540766716003, 0.9184138178825378, 0.9822323322296143, 0.6323740482330322, 0.05316458269953728, 0.9468075037002563, 0.9259583353996277, 0.9766265749931335, 0.9675989151000977, 0.9109603762626648, 0.9985743761062622, 0.9825040102005005, 0.9379366040229797, 0.2503354251384735, 0.2821577191352844, 0.46672704815864563, 0.9440325498580933, 0.877874493598938, 0.12192700803279877, 0.45874708890914917, 0.5421556830406189, 0.35047829151153564, 0.02951396256685257, 0.6197932362556458, 0.2485608458518982, 0.25469815731048584, 0.49405303597450256, 0.9704074263572693, 0.11707980930805206, 0.12772342562675476, 0.7556969523429871, 0.333087295293808, 0.666174590587616, 0.9976820945739746, 0.06397290527820587, 0.9352229833602905, 0.8928865194320679, 0.056269511580467224, 0.9435964226722717, 0.9893933534622192, 0.19101355969905853, 0.8094520568847656, 0.9517779350280762, 0.9998517632484436, 0.07704204320907593, 0.002963155508041382, 0.9205536246299744, 0.503021240234375, 0.0125233493745327, 0.48632341623306274, 0.5992971658706665, 0.3946591019630432, 0.7746091485023499, 0.5817921757698059, 0.4182707369327545, 0.9538903832435608, 0.020596254616975784, 0.9792582392692566, 0.9822859168052673, 0.20979125797748566, 0.10046342015266418, 0.6884698867797852, 0.34586748480796814, 0.48997893929481506, 0.1585225909948349, 0.9998560547828674, 0.28234565258026123, 0.7175502181053162, 0.8312357068061829, 0.9907838106155396, 0.8270465135574341, 0.17260101437568665, 0.41611677408218384, 0.584697425365448, 0.9777480959892273, 0.9946836829185486, 0.12341064214706421, 0.8767370581626892, 0.9184890985488892, 0.11221317201852798, 0.8876863121986389, 0.24690671265125275, 0.7531131505966187, 1.0009440183639526, 0.9773602485656738, 0.49806320667266846, 0.002929783659055829, 0.49916186928749084, 0.995602548122406, 0.28553876280784607, 0.3172653019428253, 0.3807183504104614, 0.9975713491439819, 0.921492338180542, 0.9989315271377563, 0.9440325498580933, 0.934903085231781, 0.9875349402427673, 1.0011988878250122, 0.9991455078125, 0.999337375164032, 0.4452876150608063, 0.4452876150608063, 0.12144207954406738, 0.9415906071662903, 0.22777236998081207, 0.7761132717132568, 0.9942188858985901, 1.004567265510559, 0.1953599900007248, 0.10744799673557281, 0.6935279965400696, 0.29973670840263367, 0.6998201012611389, 0.4772489666938782, 0.5302765965461731, 0.9857013821601868, 0.050447046756744385, 0.9496656656265259, 0.9930838346481323, 1.0028196573257446, 0.9952559471130371, 1.0001294612884521, 0.3514654040336609, 0.6443532109260559, 0.13537923991680145, 0.8641542792320251, 0.999281644821167, 0.3532518148422241, 0.6454477906227112, 0.971367597579956, 0.99924236536026, 0.9173413515090942, 0.48400384187698364, 0.0027191226836293936, 0.5132343769073486, 0.21318994462490082, 0.005903721321374178, 0.7806031703948975, 0.21638557314872742, 0.06471344083547592, 0.7179147601127625, 0.9945020079612732, 0.9167651534080505, 0.9494848847389221, 0.9807985424995422, 0.022035887464880943, 0.008569511584937572, 0.9695790410041809, 0.13884489238262177, 0.3966996967792511, 0.4562046527862549, 0.39744630455970764, 0.045018188655376434, 0.5582255721092224, 0.7598453760147095, 0.23683491349220276, 0.9990432262420654, 0.9941689968109131, 0.9824660420417786, 0.9999647736549377, 0.9440325498580933, 0.9980918169021606, 0.0536457821726799, 0.9463925957679749, 0.9995856285095215, 0.31806686520576477, 0.6679404377937317, 0.9250059127807617, 0.13137958943843842, 0.0019608894363045692, 0.8662228584289551, 0.09706560522317886, 0.903085470199585, 0.9890678524971008, 0.1674603968858719, 0.569365382194519, 0.23444455862045288, 0.951555073261261, 1.0013669729232788, 0.998019278049469, 0.9273643493652344, 0.996533215045929, 0.9983459711074829, 0.03297707438468933, 0.9673275351524353, 0.9952089786529541, 0.9860122203826904, 0.018424339592456818, 0.9817540645599365, 0.1773003488779068, 0.8225005865097046, 0.1674700230360031, 0.03189905360341072, 0.7974762916564941, 0.5092083811759949, 0.4809190034866333, 0.9185338616371155, 0.7079036831855774, 0.25282275676727295, 0.7579349875450134, 0.23834434151649475, 0.20710216462612152, 0.7988226413726807, 0.9366551637649536, 0.9476916790008545, 0.5385478734970093, 0.47392213344573975, 0.4273674786090851, 0.5722175240516663, 0.997356116771698, 0.4313473105430603, 0.14378243684768677, 0.4313473105430603, 0.1303219199180603, 0.0038556780200451612, 0.8659852743148804, 1.0016744136810303, 0.9340988397598267, 0.9043864011764526, 0.9996470808982849, 0.9607939124107361, 0.2684295177459717, 0.7312854528427124, 0.9174116253852844, 0.9990400075912476, 0.9058416485786438, 0.09350623190402985, 0.919868528842926, 0.48849692940711975, 0.506589412689209, 0.9907529354095459, 0.9140122532844543, 0.40919676423072815, 0.0036212103441357613, 0.5866360664367676, 0.988704264163971, 0.10179434716701508, 0.8979715704917908, 0.9752180576324463, 0.9997727274894714, 0.9996652007102966, 0.9994902610778809, 0.012151251547038555, 0.987723171710968, 0.04721260815858841, 0.03198273479938507, 0.9198843836784363, 0.1902085691690445, 0.8095919489860535, 1.0001742839813232, 0.8239232897758484, 0.17302389442920685, 0.4786481261253357, 0.06070658937096596, 0.459969162940979, 0.9913164973258972, 0.8107394576072693, 0.189369797706604, 0.9216776490211487, 0.911709189414978, 0.7863358855247498, 0.2069304883480072, 0.9043344259262085, 0.8664294481277466, 0.09626993536949158, 0.02674557827413082, 0.973241925239563, 0.08606073260307312, 0.9144958853721619, 0.30043521523475647, 0.0396801233291626, 0.6603906750679016, 0.550020158290863, 0.4362228810787201, 0.030711675062775612, 0.9694206714630127, 0.9720062613487244, 0.032400209456682205, 0.5323154330253601, 0.4731692671775818, 0.986328661441803, 0.10600506514310837, 0.8935895562171936, 0.999836802482605, 0.9633146524429321, 0.5976850986480713, 0.39845675230026245, 0.8397942185401917, 0.9234370589256287, 0.9940143823623657, 0.21089647710323334, 0.0006429770728573203, 0.7889328598976135, 0.9607939124107361, 0.9830912947654724, 0.9966732263565063, 0.9607939124107361, 0.9997358322143555, 0.9874652028083801, 0.99691241979599, 0.9882351756095886, 1.0011945962905884, 0.0610990896821022, 0.9387620687484741, 0.9983373284339905, 0.9440325498580933, 0.05401557311415672, 0.9457635879516602, 1.0022367238998413, 0.22639228403568268, 0.0009092059335671365, 0.7728250622749329, 0.3641594648361206, 0.2104032337665558, 0.4288989007472992, 0.8712098002433777, 0.07552288472652435, 0.10334710776805878, 0.8228020071983337, 0.5185297131538391, 0.4805223047733307, 0.9968774914741516, 0.9440325498580933, 0.014786492101848125, 0.0961121991276741, 0.887189507484436, 0.053935837000608444, 0.9461886882781982, 0.9440325498580933, 0.999904453754425], \"Term\": [\"10\", \"20\", \"28\", \"actually\", \"addictive\", \"adore\", \"againi\", \"albany\", \"alinea\", \"alinea\", \"alinea\", \"alot\", \"alot\", \"also\", \"also\", \"always\", \"always\", \"amazing\", \"amazing\", \"anniversary\", \"appreciation\", \"approve\", \"around\", \"ask\", \"atmosphere\", \"atmosphere\", \"back\", \"back\", \"back\", \"background\", \"bar\", \"bar\", \"basket\", \"beer\", \"beginning\", \"beginning\", \"best\", \"best\", \"best\", \"bill\", \"birthday\", \"bitch\", \"bitch\", \"blog\", \"blog\", \"bloody\", \"bone\", \"bongo\", \"burrito\", \"burrito\", \"byob\", \"byob\", \"cafe\", \"cafe\", \"cake\", \"cake\", \"cake\", \"call\", \"carte\", \"ceasar\", \"check\", \"chocolate\", \"chocolate\", \"chocolate\", \"chop\", \"closet\", \"coconut\", \"colombian\", \"come\", \"come\", \"competition\", \"component\", \"concert\", \"connoisseur\", \"convey\", \"cornbread\", \"cory\", \"course\", \"course\", \"course\", \"crue\", \"cuisine\", \"cuisine\", \"culinary\", \"culinary\", \"delicious\", \"delicious\", \"delicious\", \"dessert\", \"dessert\", \"dessert\", \"dill\", \"din\", \"din\", \"din\", \"dinner\", \"dinner\", \"dog\", \"dont\", \"dont\", \"dope\", \"drink\", \"drink\", \"ear\", \"eat\", \"eat\", \"elliot\", \"else\", \"even\", \"even\", \"even\", \"everything\", \"everything\", \"everything\", \"exceptional\", \"exceptional\", \"falcon\", \"favorite\", \"favorite\", \"fear\", \"find\", \"find\", \"flake\", \"flavor\", \"flavor\", \"flavor\", \"flavorful\", \"flavorful\", \"flavorful\", \"fondue\", \"food\", \"food\", \"frank\", \"freeze\", \"fresh\", \"fresh\", \"friendly\", \"friendly\", \"ganache\", \"gejas\", \"get\", \"get\", \"glare\", \"go\", \"go\", \"good\", \"good\", \"gorgonzola\", \"graham\", \"great\", \"great\", \"great\", \"greek\", \"ground\", \"ground\", \"ground\", \"guy\", \"handful\", \"hike\", \"hoarse\", \"holy\", \"homemade\", \"honey\", \"hoppin\", \"hour\", \"hummus\", \"hummus\", \"hummus\", \"humus\", \"instead\", \"instead\", \"interact\", \"involve\", \"isnt\", \"isnt\", \"isnt\", \"ive\", \"ive\", \"jack\", \"jack\", \"juicy\", \"know\", \"know\", \"lamb\", \"laughter\", \"lech\", \"let\", \"level\", \"level\", \"like\", \"like\", \"line\", \"little\", \"little\", \"lockdown\", \"long\", \"lotta\", \"love\", \"love\", \"love\", \"make\", \"make\", \"make\", \"many\", \"many\", \"many\", \"margarita\", \"mary\", \"masterpiece\", \"mastros\", \"meal\", \"meal\", \"meal\", \"melt\", \"melt\", \"melt\", \"menu\", \"menu\", \"menu\", \"mexican\", \"mexican\", \"minute\", \"mojitos\", \"mole\", \"money\", \"motley\", \"nana\", \"never\", \"never\", \"next\", \"noise\", \"noise\", \"omelette\", \"one\", \"one\", \"one\", \"order\", \"order\", \"organic\", \"pace\", \"pace\", \"pace\", \"pain\", \"pairing\", \"party\", \"passion\", \"pasta\", \"pay\", \"people\", \"people\", \"pho\", \"pic\", \"pizza\", \"pizza\", \"place\", \"place\", \"play\", \"play\", \"play\", \"pleasantly\", \"pleasantly\", \"plug\", \"popcorn\", \"popcorn\", \"portion\", \"portion\", \"pot\", \"pot\", \"ppl\", \"preparation\", \"present\", \"present\", \"price\", \"price\", \"put\", \"rat\", \"rat\", \"rat\", \"really\", \"really\", \"really\", \"relax\", \"reminiscent\", \"remotely\", \"reservation\", \"reservationgo\", \"restaurant\", \"restaurant\", \"restroom\", \"review\", \"rib\", \"rib\", \"rj\", \"romantic\", \"romantic\", \"ropa\", \"royalty\", \"salad\", \"salad\", \"salad\", \"salsa\", \"say\", \"say\", \"screen\", \"seat\", \"see\", \"seem\", \"serve\", \"serve\", \"server\", \"server\", \"server\", \"service\", \"service\", \"show\", \"shrimp\", \"shrimp\", \"special\", \"special\", \"special\", \"spice\", \"spicy\", \"spicy\", \"stain\", \"superfriendly\", \"surprised\", \"surprised\", \"sustenance\", \"sweetheart\", \"sweetheart\", \"table\", \"table\", \"take\", \"take\", \"taste\", \"taste\", \"taste\", \"tasting\", \"tasting\", \"tell\", \"tell\", \"tender\", \"tender\", \"texture\", \"texture\", \"thai\", \"time\", \"time\", \"tofu\", \"tooth\", \"torta\", \"torta\", \"trade\", \"tremendous\", \"tres\", \"try\", \"try\", \"try\", \"unbelieve\", \"uncommon\", \"unexpected\", \"uphttpforksandcorkschicagocom20110114schwachicagostinypieceofculinaryheaven\", \"us\", \"vibe\", \"vieja\", \"vietnam\", \"vietnamese\", \"wait\", \"wait\", \"waitress\", \"waitressservers\", \"want\", \"want\", \"washington\", \"well\", \"well\", \"well\", \"white\", \"white\", \"white\", \"whoopercheesie\", \"wine\", \"wine\", \"wine\", \"wonderful\", \"wonderful\", \"wont\", \"woohooone\", \"work\", \"work\", \"work\", \"would\", \"would\", \"wussy\", \"yum\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1648818666316444085759733157\", ldavis_el1648818666316444085759733157_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1648818666316444085759733157\", ldavis_el1648818666316444085759733157_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1648818666316444085759733157\", ldavis_el1648818666316444085759733157_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_display = pyLDAvis.gensim.prepare(fake_model, fake_corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced87cdacf5f470e8fedbc93d66b9523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15386), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set = []\n",
    "pbar = tqdm_notebook(total=X_test.shape[0])\n",
    "for text in X_test:\n",
    "    tokens = preprocess_text(str(text))\n",
    "    test_set.append(tokens)\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "X_test = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 1),\n",
       " (66, 1),\n",
       " (70, 1),\n",
       " (106, 1),\n",
       " (130, 1),\n",
       " (158, 1),\n",
       " (176, 1),\n",
       " (225, 1),\n",
       " (240, 1),\n",
       " (289, 1),\n",
       " (545, 1),\n",
       " (810, 1),\n",
       " (1862, 1),\n",
       " (4436, 1),\n",
       " (4827, 1),\n",
       " (5030, 1),\n",
       " (5908, 1),\n",
       " (7882, 1),\n",
       " (8753, 1)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2bow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions based on topics\n",
    "y_pred = []\n",
    "\n",
    "for test_text in X_test:\n",
    "    test_doc_bow = dictionary.doc2bow(test_text)\n",
    "    real_scores = []\n",
    "    fake_scores = []\n",
    "    for i in real_model.get_document_topics(test_doc_bow):\n",
    "        #real_model.get_document_topics(new_doc_bow)[0][1] -> Fit value of doc on topic 0\n",
    "        real_scores.append(i[1])\n",
    "    for i in fake_model.get_document_topics(test_doc_bow):\n",
    "        fake_scores.append(i[1])\n",
    "        \n",
    "    #Best Fit on real model\n",
    "    real_fit = max(real_scores)\n",
    "    #Best Fit on fake model\n",
    "    fake_fit = max(fake_scores)\n",
    "    \n",
    "    if real_fit >= fake_fit:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 29.234368906798387 %\n",
      "Real correct: 3020\n",
      "Fake correct: 1478\n"
     ]
    }
   ],
   "source": [
    "#Evaluating\n",
    "real_correct = 0\n",
    "fake_correct = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        if y_test[i] == 0:\n",
    "            real_correct = real_correct + 1\n",
    "        else:\n",
    "            fake_correct = fake_correct + 1\n",
    "        \n",
    "acc = ((real_correct+fake_correct)/len(y_test))*100\n",
    "print(\"Overall Accuracy:\", acc,\"%\")\n",
    "print(\"Real correct:\", real_correct)\n",
    "print(\"Fake correct:\", fake_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.to_csv(r\"E:\\Yelp\\YelpChi\\res_lda.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46155, 9) (15386, 2) (46155, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(r\"E:\\Yelp\\YelpChi\\X_train\")\n",
    "X_test = pd.read_csv(r\"E:\\Yelp\\YelpChi\\X_test\")\n",
    "y_train = pd.read_csv(r\"E:\\Yelp\\YelpChi\\y_train\", header=None)\n",
    "y_test = pd.read_csv(r\"E:\\Yelp\\YelpChi\\y_test\", header=None)\n",
    "print(X_train.shape, y_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words= 2000)\n",
    "tokenizer.fit_on_texts(X_train['0'])\n",
    "sequences = tokenizer.texts_to_sequences(X_train['0'])\n",
    "data1 = pad_sequences(sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 100, 32)           64000     \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 924,673\n",
      "Trainable params: 924,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(2000, 32, input_length=100))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "46155/46155 [==============================] - ETA: 28s - loss: 0.6909 - acc: 0.60 - ETA: 15s - loss: 0.6351 - acc: 0.73 - ETA: 10s - loss: 0.5898 - acc: 0.78 - ETA: 8s - loss: 0.5481 - acc: 0.8045 - ETA: 7s - loss: 0.5302 - acc: 0.816 - ETA: 6s - loss: 0.5129 - acc: 0.824 - ETA: 5s - loss: 0.4865 - acc: 0.834 - ETA: 5s - loss: 0.4716 - acc: 0.839 - ETA: 4s - loss: 0.4595 - acc: 0.844 - ETA: 4s - loss: 0.4515 - acc: 0.846 - ETA: 3s - loss: 0.4403 - acc: 0.850 - ETA: 3s - loss: 0.4355 - acc: 0.852 - ETA: 3s - loss: 0.4297 - acc: 0.854 - ETA: 3s - loss: 0.4254 - acc: 0.855 - ETA: 3s - loss: 0.4217 - acc: 0.856 - ETA: 2s - loss: 0.4188 - acc: 0.857 - ETA: 2s - loss: 0.4163 - acc: 0.858 - ETA: 2s - loss: 0.4153 - acc: 0.858 - ETA: 2s - loss: 0.4150 - acc: 0.857 - ETA: 2s - loss: 0.4129 - acc: 0.858 - ETA: 2s - loss: 0.4132 - acc: 0.857 - ETA: 2s - loss: 0.4120 - acc: 0.858 - ETA: 1s - loss: 0.4103 - acc: 0.858 - ETA: 1s - loss: 0.4089 - acc: 0.858 - ETA: 1s - loss: 0.4071 - acc: 0.858 - ETA: 1s - loss: 0.4048 - acc: 0.859 - ETA: 1s - loss: 0.4024 - acc: 0.860 - ETA: 1s - loss: 0.4012 - acc: 0.860 - ETA: 1s - loss: 0.4004 - acc: 0.860 - ETA: 1s - loss: 0.3997 - acc: 0.860 - ETA: 1s - loss: 0.3979 - acc: 0.861 - ETA: 1s - loss: 0.3978 - acc: 0.861 - ETA: 1s - loss: 0.3978 - acc: 0.861 - ETA: 0s - loss: 0.3982 - acc: 0.860 - ETA: 0s - loss: 0.3983 - acc: 0.860 - ETA: 0s - loss: 0.3979 - acc: 0.860 - ETA: 0s - loss: 0.3977 - acc: 0.860 - ETA: 0s - loss: 0.3971 - acc: 0.860 - ETA: 0s - loss: 0.3965 - acc: 0.860 - ETA: 0s - loss: 0.3953 - acc: 0.860 - ETA: 0s - loss: 0.3941 - acc: 0.861 - ETA: 0s - loss: 0.3930 - acc: 0.861 - ETA: 0s - loss: 0.3932 - acc: 0.861 - ETA: 0s - loss: 0.3924 - acc: 0.862 - ETA: 0s - loss: 0.3920 - acc: 0.862 - ETA: 0s - loss: 0.3914 - acc: 0.862 - 3s 71us/step - loss: 0.3913 - acc: 0.8624\n",
      "Epoch 2/3\n",
      "46155/46155 [==============================] - ETA: 3s - loss: 0.3576 - acc: 0.869 - ETA: 2s - loss: 0.3500 - acc: 0.871 - ETA: 2s - loss: 0.3319 - acc: 0.880 - ETA: 2s - loss: 0.3415 - acc: 0.875 - ETA: 2s - loss: 0.3408 - acc: 0.878 - ETA: 2s - loss: 0.3423 - acc: 0.877 - ETA: 2s - loss: 0.3410 - acc: 0.877 - ETA: 2s - loss: 0.3423 - acc: 0.876 - ETA: 2s - loss: 0.3429 - acc: 0.875 - ETA: 2s - loss: 0.3429 - acc: 0.874 - ETA: 2s - loss: 0.3430 - acc: 0.873 - ETA: 2s - loss: 0.3432 - acc: 0.872 - ETA: 1s - loss: 0.3427 - acc: 0.872 - ETA: 1s - loss: 0.3420 - acc: 0.872 - ETA: 1s - loss: 0.3422 - acc: 0.872 - ETA: 1s - loss: 0.3426 - acc: 0.872 - ETA: 1s - loss: 0.3449 - acc: 0.871 - ETA: 1s - loss: 0.3446 - acc: 0.871 - ETA: 1s - loss: 0.3473 - acc: 0.871 - ETA: 1s - loss: 0.3492 - acc: 0.870 - ETA: 1s - loss: 0.3483 - acc: 0.870 - ETA: 1s - loss: 0.3486 - acc: 0.870 - ETA: 1s - loss: 0.3474 - acc: 0.870 - ETA: 1s - loss: 0.3489 - acc: 0.869 - ETA: 1s - loss: 0.3481 - acc: 0.869 - ETA: 1s - loss: 0.3482 - acc: 0.869 - ETA: 1s - loss: 0.3484 - acc: 0.869 - ETA: 1s - loss: 0.3489 - acc: 0.869 - ETA: 1s - loss: 0.3480 - acc: 0.869 - ETA: 0s - loss: 0.3483 - acc: 0.869 - ETA: 0s - loss: 0.3485 - acc: 0.869 - ETA: 0s - loss: 0.3489 - acc: 0.868 - ETA: 0s - loss: 0.3499 - acc: 0.868 - ETA: 0s - loss: 0.3495 - acc: 0.868 - ETA: 0s - loss: 0.3489 - acc: 0.868 - ETA: 0s - loss: 0.3492 - acc: 0.868 - ETA: 0s - loss: 0.3492 - acc: 0.868 - ETA: 0s - loss: 0.3491 - acc: 0.868 - ETA: 0s - loss: 0.3486 - acc: 0.868 - ETA: 0s - loss: 0.3478 - acc: 0.868 - ETA: 0s - loss: 0.3478 - acc: 0.868 - ETA: 0s - loss: 0.3483 - acc: 0.868 - ETA: 0s - loss: 0.3486 - acc: 0.868 - ETA: 0s - loss: 0.3482 - acc: 0.868 - ETA: 0s - loss: 0.3484 - acc: 0.868 - ETA: 0s - loss: 0.3486 - acc: 0.867 - 3s 58us/step - loss: 0.3486 - acc: 0.8680\n",
      "Epoch 3/3\n",
      "46155/46155 [==============================] - ETA: 3s - loss: 0.2918 - acc: 0.878 - ETA: 2s - loss: 0.2984 - acc: 0.872 - ETA: 2s - loss: 0.3024 - acc: 0.871 - ETA: 2s - loss: 0.3086 - acc: 0.868 - ETA: 2s - loss: 0.3058 - acc: 0.869 - ETA: 2s - loss: 0.3041 - acc: 0.870 - ETA: 2s - loss: 0.3044 - acc: 0.871 - ETA: 2s - loss: 0.3079 - acc: 0.870 - ETA: 2s - loss: 0.3108 - acc: 0.873 - ETA: 2s - loss: 0.3132 - acc: 0.872 - ETA: 2s - loss: 0.3153 - acc: 0.871 - ETA: 1s - loss: 0.3139 - acc: 0.872 - ETA: 1s - loss: 0.3114 - acc: 0.873 - ETA: 1s - loss: 0.3098 - acc: 0.874 - ETA: 1s - loss: 0.3088 - acc: 0.874 - ETA: 1s - loss: 0.3090 - acc: 0.874 - ETA: 1s - loss: 0.3086 - acc: 0.874 - ETA: 1s - loss: 0.3083 - acc: 0.874 - ETA: 1s - loss: 0.3074 - acc: 0.874 - ETA: 1s - loss: 0.3078 - acc: 0.874 - ETA: 1s - loss: 0.3081 - acc: 0.873 - ETA: 1s - loss: 0.3087 - acc: 0.874 - ETA: 1s - loss: 0.3103 - acc: 0.873 - ETA: 1s - loss: 0.3099 - acc: 0.874 - ETA: 1s - loss: 0.3091 - acc: 0.874 - ETA: 1s - loss: 0.3087 - acc: 0.874 - ETA: 1s - loss: 0.3081 - acc: 0.874 - ETA: 1s - loss: 0.3078 - acc: 0.875 - ETA: 0s - loss: 0.3078 - acc: 0.875 - ETA: 0s - loss: 0.3073 - acc: 0.875 - ETA: 0s - loss: 0.3060 - acc: 0.875 - ETA: 0s - loss: 0.3063 - acc: 0.875 - ETA: 0s - loss: 0.3065 - acc: 0.875 - ETA: 0s - loss: 0.3071 - acc: 0.875 - ETA: 0s - loss: 0.3074 - acc: 0.875 - ETA: 0s - loss: 0.3076 - acc: 0.875 - ETA: 0s - loss: 0.3075 - acc: 0.875 - ETA: 0s - loss: 0.3075 - acc: 0.875 - ETA: 0s - loss: 0.3071 - acc: 0.876 - ETA: 0s - loss: 0.3073 - acc: 0.876 - ETA: 0s - loss: 0.3075 - acc: 0.876 - ETA: 0s - loss: 0.3080 - acc: 0.875 - ETA: 0s - loss: 0.3081 - acc: 0.875 - ETA: 0s - loss: 0.3074 - acc: 0.875 - ETA: 0s - loss: 0.3072 - acc: 0.876 - ETA: 0s - loss: 0.3073 - acc: 0.876 - 3s 57us/step - loss: 0.3072 - acc: 0.8761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b2b6a27b00>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data1, y_train[1], batch_size=1000, epochs=3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(X_test['0'])\n",
    "test_sequences_matrix = pad_sequences(test_sequences,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_sequences_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93     13340\n",
      "           1       0.31      0.03      0.05      2046\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     15386\n",
      "   macro avg       0.59      0.51      0.49     15386\n",
      "weighted avg       0.79      0.86      0.81     15386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tst = []\n",
    "for i in y_pred:\n",
    "    if i >= 0.50:\n",
    "        tst.append(1)\n",
    "    else:\n",
    "        tst.append(0)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test[1], tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15386/15386 [==============================] - ETA: 1: - ETA: 2s - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 55us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_sequences_matrix, y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.2667359906614 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", results[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(len(tst)):\n",
    "    if tst[i] == y_test[1][i]:\n",
    "        a = a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.26673599376056"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a/15386)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(tst)\n",
    "y_pred.to_csv(r\"E:\\Yelp\\YelpChi\\res_nn.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = pd.read_csv(r\"E:\\Yelp\\YelpChi\\res_lda.csv\", header=None)\n",
    "res2 = pd.read_csv(r\"E:\\Yelp\\YelpChi\\res_nn.csv\", header=None)\n",
    "res3 = pd.read_csv(r\"E:\\Yelp\\YelpChi\\res_features.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15386, 2) (15386, 2) (15386, 2)\n"
     ]
    }
   ],
   "source": [
    "print(res1.shape, res2.shape, res3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(r\"E:\\Yelp\\YelpChi\\y_test\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape\n",
    "X = pd.DataFrame({'a':res1[1], 'b':res2[1], 'c':res3[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15386, 3)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, activation='sigmoid', input_dim=3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_test[1], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10308/10308 [==============================] - ETA: 3:51 - loss: 0.7198 - acc: 0.187 - ETA: 5s - loss: 0.7036 - acc: 0.3430  - ETA: 2s - loss: 0.6818 - acc: 0.611 - ETA: 1s - loss: 0.6589 - acc: 0.705 - ETA: 0s - loss: 0.6425 - acc: 0.741 - ETA: 0s - loss: 0.6254 - acc: 0.766 - ETA: 0s - loss: 0.6095 - acc: 0.782 - ETA: 0s - loss: 0.5936 - acc: 0.796 - 1s 109us/step - loss: 0.5830 - acc: 0.8036\n",
      "Epoch 2/5\n",
      "10308/10308 [==============================] - ETA: 0s - loss: 0.4505 - acc: 0.906 - ETA: 0s - loss: 0.4765 - acc: 0.860 - ETA: 0s - loss: 0.4617 - acc: 0.869 - ETA: 0s - loss: 0.4529 - acc: 0.870 - ETA: 0s - loss: 0.4447 - acc: 0.871 - ETA: 0s - loss: 0.4451 - acc: 0.866 - ETA: 0s - loss: 0.4399 - acc: 0.866 - 0s 34us/step - loss: 0.4356 - acc: 0.8673\n",
      "Epoch 3/5\n",
      "10308/10308 [==============================] - ETA: 0s - loss: 0.5665 - acc: 0.750 - ETA: 0s - loss: 0.3931 - acc: 0.876 - ETA: 0s - loss: 0.3875 - acc: 0.878 - ETA: 0s - loss: 0.3936 - acc: 0.873 - ETA: 0s - loss: 0.3955 - acc: 0.871 - ETA: 0s - loss: 0.4004 - acc: 0.867 - ETA: 0s - loss: 0.4005 - acc: 0.866 - ETA: 0s - loss: 0.3990 - acc: 0.867 - 0s 35us/step - loss: 0.3987 - acc: 0.8673\n",
      "Epoch 4/5\n",
      "10308/10308 [==============================] - ETA: 0s - loss: 0.4294 - acc: 0.843 - ETA: 0s - loss: 0.4105 - acc: 0.856 - ETA: 0s - loss: 0.3982 - acc: 0.863 - ETA: 0s - loss: 0.3956 - acc: 0.865 - ETA: 0s - loss: 0.3825 - acc: 0.872 - ETA: 0s - loss: 0.3854 - acc: 0.870 - ETA: 0s - loss: 0.3922 - acc: 0.867 - ETA: 0s - loss: 0.3908 - acc: 0.867 - 0s 36us/step - loss: 0.3916 - acc: 0.8673\n",
      "Epoch 5/5\n",
      "10308/10308 [==============================] - ETA: 0s - loss: 0.4306 - acc: 0.843 - ETA: 0s - loss: 0.3773 - acc: 0.875 - ETA: 0s - loss: 0.4007 - acc: 0.862 - ETA: 0s - loss: 0.3932 - acc: 0.866 - ETA: 0s - loss: 0.3980 - acc: 0.863 - ETA: 0s - loss: 0.3907 - acc: 0.867 - ETA: 0s - loss: 0.3909 - acc: 0.867 - 0s 34us/step - loss: 0.3905 - acc: 0.8673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b2b81f6f98>"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5078/5078 [==============================] - ETA: 40 - ETA: 0 - 0s 68us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.64828671766765 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",scores[1]*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.81      4400\n",
      "           1       0.16      0.31      0.21       678\n",
      "\n",
      "   micro avg       0.70      0.70      0.70      5078\n",
      "   macro avg       0.52      0.53      0.51      5078\n",
      "weighted avg       0.78      0.70      0.73      5078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "tst = []\n",
    "for i in y_pred:\n",
    "    if i >= 0.15:\n",
    "        tst.append(1)\n",
    "    else:\n",
    "        tst.append(0)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, tst))\n",
    "\n",
    "a = 0\n",
    "for i in range(len(tst)):\n",
    "    if tst[i] == y_test.tolist()[i]:\n",
    "        a = a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
