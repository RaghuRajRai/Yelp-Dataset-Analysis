{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YelpChi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:923: DeprecationWarning: builtin type EagerTensor has no __module__ attribute\n",
      "  EagerTensor = c_api.TFE_Py_InitEagerTensor(_EagerTensorBase)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_inspect.py:75: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  return _inspect.getargspec(target)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "from textblob import TextBlob\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import string\n",
    "from matplotlib import pyplot\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import random\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models.callbacks import PerplexityMetric\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, TimeDistributed, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import optimizers\n",
    "from keras.layers import Input\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "meta = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\metadata\", sep=\"\\\\t\", header=None)\n",
    "data = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\reviewContent\", sep=\"\\\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0  1    2  3           4\n",
      "0  923  0  3.0 -1  2014-12-08\n",
      "1  924  0  3.0 -1  2013-05-16\n",
      "2  925  0  4.0 -1  2013-07-01\n",
      "3  926  0  4.0 -1  2011-07-28\n",
      "4  927  0  4.0 -1  2010-11-01\n",
      "     0  1           2                                                  3\n",
      "0  923  0  2014-12-08  The food at snack is a selection of popular Gr...\n",
      "1  924  0  2013-05-16  This little place in Soho is wonderful. I had ...\n",
      "2  925  0  2013-07-01  ordered lunch for 15 from Snack last Friday. Â...\n",
      "3  926  0  2011-07-28  This is a beautiful quaint little restaurant o...\n",
      "4  927  0  2010-11-01  Snack is great place for a Â casual sit down l...\n",
      "(359052, 5) (359052, 4)\n"
     ]
    }
   ],
   "source": [
    "print(meta.head())\n",
    "print(data.head())\n",
    "print(meta.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame()\n",
    "data1[0] = data[3]\n",
    "data1[1] = meta[3]\n",
    "data1[2] = meta[2]\n",
    "data = data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0  1    2\n",
      "0  The food at snack is a selection of popular Gr... -1  3.0\n",
      "1  This little place in Soho is wonderful. I had ... -1  3.0\n",
      "2  ordered lunch for 15 from Snack last Friday. Â... -1  4.0\n",
      "3  This is a beautiful quaint little restaurant o... -1  4.0\n",
      "4  Snack is great place for a Â casual sit down l... -1  4.0 \n",
      " (359052, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.head(),\"\\n\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ordered lunch for 15 from Snack last Friday. Â...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snack is great place for a Â casual sit down l...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2\n",
       "0  The food at snack is a selection of popular Gr...  1  3\n",
       "1  This little place in Soho is wonderful. I had ...  1  3\n",
       "2  ordered lunch for 15 from Snack last Friday. Â...  1  4\n",
       "3  This is a beautiful quaint little restaurant o...  1  4\n",
       "4  Snack is great place for a Â casual sit down l...  1  4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binarize(charac):\n",
    "    if charac==-1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data[1] = data[1].apply(lambda c: binarize(c))\n",
    "data[2] = data[2].apply(lambda x: int(x))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Real, 1: Fake\n",
      "\n",
      " 0    322167\n",
      "1     36885\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"0: Real, 1: Fake\\n\\n\", data[1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d7679db104441ca107d80107b104e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=359052), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ordered lunch for 15 from Snack last Friday. Â...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snack is great place for a Â casual sit down l...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count\n",
       "0  The food at snack is a selection of popular Gr...  1  3          40\n",
       "1  This little place in Soho is wonderful. I had ...  1  3          52\n",
       "2  ordered lunch for 15 from Snack last Friday. Â...  1  4          34\n",
       "3  This is a beautiful quaint little restaurant o...  1  4          92\n",
       "4  Snack is great place for a Â casual sit down l...  1  4         107"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word Count\n",
    "data['word_count'] = data[0].progress_apply(lambda st: len(str(st).split()))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031ef7eb00c9448ca84651a67b68323f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=359052), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ordered lunch for 15 from Snack last Friday. Â...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snack is great place for a Â casual sit down l...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  The food at snack is a selection of popular Gr...  1  3          40   \n",
       "1  This little place in Soho is wonderful. I had ...  1  3          52   \n",
       "2  ordered lunch for 15 from Snack last Friday. Â...  1  4          34   \n",
       "3  This is a beautiful quaint little restaurant o...  1  4          92   \n",
       "4  Snack is great place for a Â casual sit down l...  1  4         107   \n",
       "\n",
       "   deviation  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          2  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentimental Deviation\n",
    "pos_words = pd.read_table(r\"C:\\Users\\elonm\\Desktop\\Yelp-Dataset-Analysis-master\\poswords.txt\", header=None)\n",
    "neg_words = pd.read_table(r\"C:\\Users\\elonm\\Desktop\\Yelp-Dataset-Analysis-master\\negwords.txt\", header=None)\n",
    "\n",
    "def sentimental_deviation(txt):\n",
    "    dev = 0\n",
    "    flag = 0\n",
    "    for word in txt.split():\n",
    "        for pos in pos_words[0]:\n",
    "            if pos == word.lower():\n",
    "                if flag == -1:\n",
    "                    dev = dev+1\n",
    "                flag = 1\n",
    "                #print(word, dev, flag)\n",
    "        for neg in neg_words[0]:\n",
    "            if neg == word.lower():\n",
    "                if flag == 1:\n",
    "                    dev = dev+1\n",
    "                flag = -1\n",
    "                #print(word, dev, flag)\n",
    "    return dev\n",
    "\n",
    "data['deviation'] = data[0].progress_apply(lambda txt: sentimental_deviation(str((txt))))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r\"E:\\Yelp\\YelpNYC\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6431fd0e668a4d3d83a22d4e69c947a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=359052), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ordered lunch for 15 from Snack last Friday. Â...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snack is great place for a Â casual sit down l...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>0.138715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  The food at snack is a selection of popular Gr...  1  3          40   \n",
       "1  This little place in Soho is wonderful. I had ...  1  3          52   \n",
       "2  ordered lunch for 15 from Snack last Friday. Â...  1  4          34   \n",
       "3  This is a beautiful quaint little restaurant o...  1  4          92   \n",
       "4  Snack is great place for a Â casual sit down l...  1  4         107   \n",
       "\n",
       "   deviation  polarity  \n",
       "0          1  0.195833  \n",
       "1          0  0.025000  \n",
       "2          0  0.220000  \n",
       "3          0  0.555134  \n",
       "4          2  0.138715  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentiment Polarity\n",
    "data['polarity'] = data[0].progress_apply(lambda txt: TextBlob(str(txt)).sentiment.polarity)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255eb87003d142d090243feb2fefa942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=359052), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf52476c866f43429531996d1e52d372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=359052), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pos_word_count</th>\n",
       "      <th>neg_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ordered lunch for 15 from Snack last Friday. Â...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555134</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snack is great place for a Â casual sit down l...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>0.138715</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  The food at snack is a selection of popular Gr...  1  3          40   \n",
       "1  This little place in Soho is wonderful. I had ...  1  3          52   \n",
       "2  ordered lunch for 15 from Snack last Friday. Â...  1  4          34   \n",
       "3  This is a beautiful quaint little restaurant o...  1  4          92   \n",
       "4  Snack is great place for a Â casual sit down l...  1  4         107   \n",
       "\n",
       "   deviation  polarity  pos_word_count  neg_word_count  \n",
       "0          1  0.195833               2               1  \n",
       "1          0  0.025000               6               4  \n",
       "2          0  0.220000               4               3  \n",
       "3          0  0.555134              11               6  \n",
       "4          2  0.138715              13               8  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Positive Negative word count\n",
    "def count_sentiment_pos(sentence):\n",
    "    count = 0\n",
    "    for word in sentence.split():\n",
    "        for sent_word in pos_words[0]:\n",
    "            if sent_word in word:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def count_sentiment_neg(sentence):\n",
    "    count = 0\n",
    "    for word in sentence.split():\n",
    "        for sent_word in neg_words[0]:\n",
    "            if sent_word in word:\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "data['pos_word_count'] = data[0].progress_apply(lambda txt: count_sentiment_pos(str(txt)))\n",
    "data['neg_word_count'] = data[0].progress_apply(lambda txt: count_sentiment_neg(str(txt)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pos_word_count</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>count_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ordered lunch for 15 from Snack last Friday. Â...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555134</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snack is great place for a Â casual sit down l...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>0.138715</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  The food at snack is a selection of popular Gr...  1  3          40   \n",
       "1  This little place in Soho is wonderful. I had ...  1  3          52   \n",
       "2  ordered lunch for 15 from Snack last Friday. Â...  1  4          34   \n",
       "3  This is a beautiful quaint little restaurant o...  1  4          92   \n",
       "4  Snack is great place for a Â casual sit down l...  1  4         107   \n",
       "\n",
       "   deviation  polarity  pos_word_count  neg_word_count  count_sentiment  \n",
       "0          1  0.195833               2               1                3  \n",
       "1          0  0.025000               6               4               10  \n",
       "2          0  0.220000               4               3                7  \n",
       "3          0  0.555134              11               6               17  \n",
       "4          2  0.138715              13               8               21  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['count_sentiment'] = data['pos_word_count'] + data['neg_word_count']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a checkpoint\n",
    "data.to_csv(r\"E:\\Yelp\\YelpChi\\data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pos_word_count</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>count_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The food at snack is a selection of popular Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This little place in Soho is wonderful. I had ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ordered lunch for 15 from Snack last Friday. Â...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a beautiful quaint little restaurant o...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555134</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Snack is great place for a Â casual sit down l...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>0.138715</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  The food at snack is a selection of popular Gr...  1  3          40   \n",
       "1  This little place in Soho is wonderful. I had ...  1  3          52   \n",
       "2  ordered lunch for 15 from Snack last Friday. Â...  1  4          34   \n",
       "3  This is a beautiful quaint little restaurant o...  1  4          92   \n",
       "4  Snack is great place for a Â casual sit down l...  1  4         107   \n",
       "\n",
       "   deviation  polarity  pos_word_count  neg_word_count  count_sentiment  \n",
       "0          1  0.195833               2               1                3  \n",
       "1          0  0.025000               6               4               10  \n",
       "2          0  0.220000               4               3                7  \n",
       "3          0  0.555134              11               6               17  \n",
       "4          2  0.138715              13               8               21  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaec2311c80d4797895c02862fb14597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=359052), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pos_word_count</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>count_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the food at snack is a selection of popular gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this little place in soho is wonderful i had a...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ordered lunch for 15 from snack last friday â ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a beautiful quaint little restaurant o...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555134</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>snack is great place for a â casual sit down l...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>0.138715</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  the food at snack is a selection of popular gr...  1  3          40   \n",
       "1  this little place in soho is wonderful i had a...  1  3          52   \n",
       "2  ordered lunch for 15 from snack last friday â ...  1  4          34   \n",
       "3  this is a beautiful quaint little restaurant o...  1  4          92   \n",
       "4  snack is great place for a â casual sit down l...  1  4         107   \n",
       "\n",
       "   deviation  polarity  pos_word_count  neg_word_count  count_sentiment  \n",
       "0          1  0.195833               2               1                3  \n",
       "1          0  0.025000               6               4               10  \n",
       "2          0  0.220000               4               3                7  \n",
       "3          0  0.555134              11               6               17  \n",
       "4          2  0.138715              13               8               21  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    trans = str.maketrans('', '', string.punctuation)\n",
    "    words = text.split()\n",
    "    stripped = [word.translate(trans) for word in words]\n",
    "    a = [x for x in stripped if x!=\"\"]\n",
    "    b = [word.lower() for word in a]\n",
    "    b = ' '.join(b)\n",
    "    return b\n",
    "\n",
    "data[0] = data[0].progress_apply(lambda text: clean_text(text))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c314fe3eaeef464b93a2d42f198c7d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=359052), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Stemming/Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "#print(lemmatizer.lemmatize(\"going\"))\n",
    "\n",
    "def nltk2wn_tag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    wn_tagged = map(lambda x: (x[0], nltk2wn_tag(x[1])), nltk_tagged)\n",
    "\n",
    "    res_words = []\n",
    "    for word, tag in wn_tagged:\n",
    "        if tag is None:            \n",
    "            res_words.append(word)\n",
    "        else:\n",
    "            res_words.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(res_words)\n",
    "\n",
    "# test =  \"You better lose yourself in the music, the moment You own it, you better never let it go You only get one shot, do not miss your chance to blow This opportunity comes once in a lifetime\"\n",
    "# print(lemmatize_sentence(test))\n",
    "\n",
    "data[0] = data[0].progress_apply(lambda text: lemmatize_sentence(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>word_count</th>\n",
       "      <th>deviation</th>\n",
       "      <th>polarity</th>\n",
       "      <th>pos_word_count</th>\n",
       "      <th>neg_word_count</th>\n",
       "      <th>count_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the food at snack be a selection of popular gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0.195833</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this little place in soho be wonderful i have ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>order lunch for 15 from snack last friday â on...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this be a beautiful quaint little restaurant o...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.555134</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>snack be great place for a â casual sit down l...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>0.138715</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1  2  word_count  \\\n",
       "0  the food at snack be a selection of popular gr...  1  3          40   \n",
       "1  this little place in soho be wonderful i have ...  1  3          52   \n",
       "2  order lunch for 15 from snack last friday â on...  1  4          34   \n",
       "3  this be a beautiful quaint little restaurant o...  1  4          92   \n",
       "4  snack be great place for a â casual sit down l...  1  4         107   \n",
       "\n",
       "   deviation  polarity  pos_word_count  neg_word_count  count_sentiment  \n",
       "0          1  0.195833               2               1                3  \n",
       "1          0  0.025000               6               4               10  \n",
       "2          0  0.220000               4               3                7  \n",
       "3          0  0.555134              11               6               17  \n",
       "4          2  0.138715              13               8               21  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to_csv(r\"E:\\Yelp\\YelpNYC\\data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269289, 8) (89763, 8)\n",
      "0    80456\n",
      "1     9307\n",
      "Name: 1, dtype: int64 0    241711\n",
      "1     27578\n",
      "Name: 1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Creating a train test split for the final processing\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[[0, 2, 'word_count', 'deviation', 'polarity', 'count_sentiment', 'pos_word_count', 'neg_word_count']], data[1], test_size=0.25, random_state=42)\n",
    "X_train.to_csv(r\"E:\\Yelp\\YelpNYC\\X_train\")\n",
    "X_test.to_csv(r\"E:\\Yelp\\YelpNYC\\X_test\")\n",
    "y_train.to_csv(r\"E:\\Yelp\\YelpNYC\\y_train\")\n",
    "y_test.to_csv(r\"E:\\Yelp\\YelpNYC\\y_test\")\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_test.value_counts(), y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[[2, 'word_count', 'deviation', 'polarity', 'count_sentiment', 'pos_word_count', 'neg_word_count']]\n",
    "X_test = X_test[[2, 'word_count', 'deviation', 'polarity', 'count_sentiment', 'pos_word_count', 'neg_word_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "svm_clf = svm.SVC(kernel='sigmoid', gamma='auto', verbose=True)\n",
    "svm_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elonm\\AppData\\Roaming\\Python\\Python36\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     80456\n",
      "           1       0.00      0.00      0.00      9307\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     89763\n",
      "   macro avg       0.45      0.50      0.47     89763\n",
      "weighted avg       0.80      0.90      0.85     89763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGB\n",
    "xgb_model = XGBClassifier(learning_rate = 0.2, objective= 'binary:logistic')\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     80456\n",
      "           1       1.00      0.00      0.00      9307\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     89763\n",
      "   macro avg       0.95      0.50      0.47     89763\n",
      "weighted avg       0.91      0.90      0.85     89763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "y_pred = [round(value) for value in y_pred]\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15601783 0.2154532  0.06835067 0.25854382 0.10698365 0.09658246\n",
      " 0.09806835]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(xgb_model.feature_importances_)\n",
    "# plot\n",
    "pyplot.bar(range(len(xgb_model.feature_importances_)), xgb_model.feature_importances_)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.to_csv(r\"E:\\Yelp\\YelpNYC\\res_features.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based on LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269289, 9) (89763, 2) (269289, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\X_train\")\n",
    "X_test = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\X_test\")\n",
    "y_train = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\y_train\", header=None)\n",
    "y_test = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\y_test\", header=None)\n",
    "print(X_train.shape, y_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['0']\n",
    "X_test = X_test['0']\n",
    "y_train = y_train[1]\n",
    "y_test = y_test[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', '0', '1', '2', 'word_count', 'deviation', 'polarity',\n",
       "       'pos_word_count', 'neg_word_count', 'count_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\data.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: (322167, 10) Fake: (36885, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    #Getting tokens from text\n",
    "    tokens = []\n",
    "    text_split = text.split()\n",
    "    for token in text_split:\n",
    "        tokens.append(token)\n",
    "    #Removing stop words from the list of tokens\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    return tokens\n",
    "\n",
    "real = data[data['1'] == 0]\n",
    "fake = data[data['1'] == 1]\n",
    "print(\"Real:\",real.shape,\"Fake:\",fake.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c006f8a5c46a4002adf8d2bda413b371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=359052), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Converting all our text to a list of preprocessed tokens\n",
    "review_data = []\n",
    "pbar = tqdm_notebook(total=data.shape[0])\n",
    "for text in data['1']:\n",
    "    tokens = preprocess_text(str(text))\n",
    "    review_data.append(tokens)\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322167 36885\n"
     ]
    }
   ],
   "source": [
    "#Separating real and fake reviews in different lists\n",
    "real = []\n",
    "fake = []\n",
    "\n",
    "for i in range(len(review_data)):\n",
    "    if data['1'][i] == 0:\n",
    "        real.append(review_data[i])\n",
    "    else:\n",
    "        fake.append(review_data[i])\n",
    "\n",
    "print(len(real), len(fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269289\n"
     ]
    }
   ],
   "source": [
    "rangex = X_train.shape[0]\n",
    "print(rangex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_indexes = []\n",
    "fake_indexes = []\n",
    "real_train = []\n",
    "fake_train = []\n",
    "\n",
    "for i in range(rangex):\n",
    "    if y_train[i] == 0:\n",
    "        real_train.append(X_train[i])\n",
    "    else:\n",
    "        fake_train.append(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7403adadda42b0a34d3c4d25fefaae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=359052), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e1d215620143b98d72342855a9b41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=359052), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "real_t = []\n",
    "fake_t = []\n",
    "pbar = tqdm_notebook(total=data.shape[0])\n",
    "for text in real_train:\n",
    "    tokens = preprocess_text(str(text))\n",
    "    real_t.append(tokens)\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "real_train = real_t\n",
    "\n",
    "pbar = tqdm_notebook(total=data.shape[0])\n",
    "for text in fake_train:\n",
    "    tokens = preprocess_text(str(text))\n",
    "    fake_t.append(tokens)\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "fake_train = fake_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of token: ['consistently', 'superior', 'food', 'awful', 'sound', 'level', 'pass', 'dessert', 'noise', 'bad', 'tell', 'loud', 'music', 'enhance', 'food'] || ['amaze', 'taste', 'presentation', 'great', 'spot', 'take', 'friend', 'town', 'anyone', 'want', 'impress', 'spaghetti', 'dish', 'definitely', 'one', 'best', 'ive', 'ever', 'taste', 'even', 'include', 'spaghetti', 'italy', 'come', 'birthday', 'group', '4', 'girl', 'seat', 'promptly', 'serve', 'amazing', 'cocktail', 'mine', 'good', 'remember', 'tiny', 'strawberry', 'along', 'champagne', 'waitress', 'sweet', 'overhear', 'us', 'talk', 'birthday', 'us', 'complimentary', 'dessert', 'platter', 'say', 'happy', 'birthday', 'go', 'regret']\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample of token:\",real_train[2], \"||\",fake_train[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = []\n",
    "for i in real_train:\n",
    "    review_data.append(i)\n",
    "for i in fake_train:\n",
    "    review_data.append(i)\n",
    "#Creating dictionary of our data using Gensim and saving \n",
    "dictionary = corpora.Dictionary(review_data)\n",
    "dictionary.save('dictionary.gensim')\n",
    "\n",
    "#For saving corpus, use:\n",
    "#pickle.dump(corpus, open('corpus.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.021*\"pork\" + 0.015*\"good\" + 0.012*\"ramen\" + 0.011*\"rice\" + 0.011*\"noodle\" + 0.010*\"place\" + 0.010*\"get\"')\n",
      "(1, '0.029*\"food\" + 0.028*\"great\" + 0.027*\"place\" + 0.020*\"good\" + 0.013*\"service\" + 0.013*\"go\" + 0.010*\"love\"')\n",
      "(2, '0.191*\"â\" + 0.012*\"dish\" + 0.009*\"restaurant\" + 0.007*\"wine\" + 0.007*\"dessert\" + 0.006*\"pasta\" + 0.006*\"menu\"')\n",
      "(3, '0.015*\"get\" + 0.012*\"go\" + 0.011*\"wait\" + 0.011*\"place\" + 0.010*\"food\" + 0.010*\"time\" + 0.009*\"order\"')\n",
      "(4, '0.014*\"good\" + 0.012*\"cheese\" + 0.011*\"fry\" + 0.011*\"chicken\" + 0.010*\"sauce\" + 0.010*\"get\" + 0.009*\"like\"')\n",
      "(0, '0.003*\"e\" + 0.003*\"de\" + 0.002*\"hood\" + 0.002*\"la\" + 0.002*\"que\" + 0.001*\"un\" + 0.001*\"die\"')\n",
      "(1, '0.056*\"pizza\" + 0.012*\"ramen\" + 0.010*\"dumpling\" + 0.010*\"noodle\" + 0.009*\"slice\" + 0.008*\"pie\" + 0.007*\"crust\"')\n",
      "(2, '0.029*\"â\" + 0.011*\"get\" + 0.010*\"food\" + 0.010*\"go\" + 0.009*\"order\" + 0.008*\"wait\" + 0.008*\"us\"')\n",
      "(3, '0.035*\"â\" + 0.020*\"food\" + 0.019*\"great\" + 0.019*\"place\" + 0.016*\"good\" + 0.011*\"go\" + 0.010*\"love\"')\n",
      "(4, '0.002*\"disk\" + 0.002*\"totto\" + 0.001*\"format\" + 0.001*\"weeknight\" + 0.001*\"toros\" + 0.001*\"hagi\" + 0.001*\"addiction\"')\n"
     ]
    }
   ],
   "source": [
    "NUM_TOPICS = 5\n",
    "\n",
    "#Getting 5 topics from real_train\n",
    "real_corpus = [dictionary.doc2bow(text) for text in real_train]\n",
    "perplexity1 = PerplexityMetric(corpus=real_corpus)\n",
    "real_model = gensim.models.ldamodel.LdaModel(real_corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=20, eval_every=1000)\n",
    "real_topics = real_model.print_topics(num_words=7)\n",
    "for topic in real_topics:\n",
    "    print(topic)\n",
    "\n",
    "#Getting 5 topics from fake_train\n",
    "fake_corpus = [dictionary.doc2bow(text) for text in fake_train]\n",
    "perplexity2 = PerplexityMetric(corpus=fake_corpus)\n",
    "fake_model = gensim.models.ldamodel.LdaModel(fake_corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=20, eval_every=1000)\n",
    "fake_topics = fake_model.print_topics(num_words=7)\n",
    "for topic in fake_topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2721622150076821362493232618\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2721622150076821362493232618_data = {\"mdsDat\": {\"x\": [0.005226893531219219, -0.11044632308228645, 0.17278256420423377, -0.16943708097529003, 0.10187394632212383], \"y\": [-0.14143341517335645, 0.08684891265867363, 0.15974385535958202, 0.024166191376393992, -0.1293255442212935], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [12.592244148254395, 19.668500900268555, 15.723615646362305, 34.73320770263672, 17.282426834106445]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [474563.0, 42297.0, 115481.0, 163794.0, 169827.0, 37042.0, 51274.0, 37540.0, 22982.0, 44866.0, 22427.0, 22137.0, 55170.0, 40808.0, 72436.0, 54811.0, 184002.0, 27307.0, 28257.0, 49772.0, 16454.0, 22470.0, 21055.0, 28664.0, 31137.0, 24103.0, 149201.0, 16113.0, 65800.0, 26828.0, 42296.4453125, 22981.341796875, 22136.5, 22426.208984375, 16453.53515625, 11153.7568359375, 10454.4970703125, 9735.138671875, 7535.13037109375, 6737.92138671875, 6463.8759765625, 6494.796875, 4753.34765625, 4396.4736328125, 4243.38037109375, 4075.1259765625, 3973.061767578125, 3890.043212890625, 3738.747802734375, 3274.2880859375, 3275.042724609375, 3159.73291015625, 3165.62109375, 3002.8369140625, 2404.193359375, 2199.072998046875, 2106.740966796875, 2102.5625, 2092.57763671875, 2093.694580078125, 7162.9853515625, 17426.8203125, 8257.1123046875, 15749.1357421875, 8493.994140625, 8951.212890625, 12286.40625, 5734.8017578125, 16766.705078125, 30283.146484375, 14621.5029296875, 14340.8798828125, 17560.078125, 19714.0546875, 20577.396484375, 11113.4560546875, 13311.345703125, 15058.05078125, 12389.599609375, 13049.0908203125, 12297.345703125, 9362.3369140625, 12583.58203125, 10099.3623046875, 10684.8251953125, 9739.3095703125, 9125.14453125, 6865.8828125, 6197.5, 1560.76611328125, 1113.5537109375, 978.0101318359375, 961.1748046875, 934.724365234375, 662.6368408203125, 657.1826782226562, 636.7178344726562, 573.718994140625, 505.81781005859375, 505.6388854980469, 479.7661437988281, 478.32086181640625, 446.90484619140625, 436.0588073730469, 396.0004577636719, 369.5104064941406, 346.19989013671875, 348.0231018066406, 338.8653564453125, 328.0000915527344, 319.25445556640625, 313.50250244140625, 310.0001220703125, 306.3660583496094, 299.36492919921875, 309.8064270019531, 293.0359802246094, 18956.681640625, 1803.1173095703125, 3079.874755859375, 6168.025390625, 18501.779296875, 23647.853515625, 1856.606201171875, 11441.7958984375, 2850.57177734375, 7830.97119140625, 9458.8173828125, 87084.5078125, 1152.7459716796875, 3648.261474609375, 1185.0423583984375, 19737.2109375, 1711.558349609375, 8253.9462890625, 9940.46875, 29214.341796875, 10040.951171875, 6534.654296875, 9175.5927734375, 17980.36328125, 2552.61376953125, 5402.7900390625, 89215.453125, 7229.01171875, 23256.05078125, 41458.70703125, 2992.942626953125, 82686.890625, 6880.50146484375, 22393.5390625, 27265.080078125, 7974.06982421875, 32429.71875, 15523.3916015625, 16243.7236328125, 10646.1337890625, 60569.98828125, 18471.642578125, 21389.625, 26529.548828125, 27730.01953125, 39693.09375, 27021.15234375, 19650.34375, 11314.2431640625, 21261.26171875, 22679.41796875, 17893.18359375, 23330.005859375, 18889.1015625, 22902.94140625, 18187.591796875, 474562.84375, 16112.330078125, 4913.26025390625, 3757.986083984375, 3674.249267578125, 2962.083984375, 2637.285888671875, 2612.951171875, 2506.101318359375, 2260.7412109375, 2170.837646484375, 1811.4627685546875, 1607.1229248046875, 1455.1822509765625, 1370.95556640625, 1297.2144775390625, 1252.8277587890625, 1064.4073486328125, 971.560791015625, 963.479736328125, 932.9222412109375, 916.8641967773438, 914.9747314453125, 900.2861938476562, 890.7664794921875, 848.2850341796875, 826.594482421875, 831.5431518554688, 813.341796875, 824.4426879882812, 4222.95703125, 3191.17919921875, 3277.857666015625, 16139.2802734375, 6685.8564453125, 29367.705078125, 16892.65625, 9627.4130859375, 8739.1953125, 11185.892578125, 7306.0712890625, 4764.271484375, 5340.634765625, 4197.0546875, 3203.525634765625, 3362.579833984375, 7479.81103515625, 21227.275390625, 6287.07421875, 13669.9091796875, 15359.6865234375, 12047.9462890625, 8157.14990234375, 9777.6181640625, 8390.7763671875, 5599.615234375, 7310.0615234375, 8271.685546875, 7305.50830078125, 6247.13330078125, 14362.8115234375, 8391.58203125, 9745.7080078125, 10438.6787109375, 7759.09912109375, 10034.935546875, 8717.921875, 9492.6767578125, 11942.1787109375, 9279.8779296875, 8431.4833984375, 7869.1357421875, 8447.501953125, 8053.99853515625, 44865.73828125, 23897.341796875, 19867.787109375, 5015.91357421875, 4692.4072265625, 4118.71875, 3732.69140625, 3517.7861328125, 3343.9033203125, 2818.930908203125, 2639.36328125, 2666.199951171875, 2621.102294921875, 2161.26123046875, 2084.824462890625, 1906.6654052734375, 1863.2344970703125, 1838.8721923828125, 1794.2269287109375, 1711.674560546875, 1578.4490966796875, 1556.41455078125, 1425.1822509765625, 1361.8883056640625, 1286.4290771484375, 1266.0526123046875, 1255.370849609375, 1230.1461181640625, 1226.785888671875, 1180.7796630859375, 6306.208984375, 10856.7138671875, 3914.892822265625, 3724.386474609375, 2903.498291015625, 20002.84765625, 5291.267578125, 5022.6474609375, 3189.0703125, 21161.265625, 11399.720703125, 9226.525390625, 7192.5517578125, 6978.4560546875, 60798.16796875, 40025.8359375, 16587.072265625, 19024.796875, 37516.484375, 29289.576171875, 40071.9375, 8264.4541015625, 29824.57421875, 37285.19921875, 38733.95703125, 20024.330078125, 16172.74609375, 28104.5859375, 23012.529296875, 53429.01171875, 21948.705078125, 80419.9375, 15414.1240234375, 27384.892578125, 18717.767578125, 28076.1015625, 64808.0703125, 24827.689453125, 32711.1171875, 44289.4609375, 48277.2578125, 28006.181640625, 37251.71875, 58719.546875, 45428.89453125, 54392.86328125, 43160.06640625, 32125.951171875, 44275.765625, 26784.98828125, 26779.865234375, 11409.1826171875, 9667.8994140625, 7030.76025390625, 6913.94482421875, 6308.0087890625, 5089.7783203125, 3903.574462890625, 3801.046875, 3721.43505859375, 3494.24462890625, 3105.74462890625, 3100.902587890625, 2920.552001953125, 2531.810302734375, 2409.708740234375, 2196.991455078125, 2171.649169921875, 2124.091552734375, 2060.94677734375, 2033.071533203125, 1928.4010009765625, 1891.0992431640625, 1869.5078125, 1853.4945068359375, 1609.103515625, 1586.4630126953125, 1582.0888671875, 1527.5074462890625, 1421.8345947265625, 1413.503173828125, 32367.484375, 7500.21142578125, 12884.14453125, 31205.9921875, 22821.12890625, 23483.767578125, 19677.537109375, 6941.78076171875, 10040.455078125, 9875.970703125, 6688.14306640625, 16251.171875, 8970.4140625, 31008.037109375, 3204.212646484375, 15566.60546875, 8508.0927734375, 28388.337890625, 17230.708984375, 8282.7861328125, 6021.57666015625, 15986.7177734375, 15260.6142578125, 14935.4111328125, 7713.3271484375, 36931.890625, 20043.205078125, 25775.91796875, 19678.642578125, 16195.8759765625, 23731.791015625, 20251.689453125, 23854.2421875, 26136.353515625, 18716.306640625, 15269.734375, 12588.720703125, 12256.884765625, 11041.1142578125, 12283.6982421875, 11516.716796875, 12036.7607421875], \"Term\": [\"\\u00e2\", \"pork\", \"great\", \"food\", \"place\", \"cheese\", \"chicken\", \"fry\", \"ramen\", \"pizza\", \"rice\", \"noodle\", \"dish\", \"drink\", \"service\", \"sauce\", \"good\", \"burger\", \"sandwich\", \"us\", \"dumpling\", \"spicy\", \"soup\", \"wine\", \"brunch\", \"egg\", \"get\", \"pasta\", \"delicious\", \"friendly\", \"pork\", \"ramen\", \"noodle\", \"rice\", \"dumpling\", \"broth\", \"thai\", \"bun\", \"curry\", \"japanese\", \"sushi\", \"bbq\", \"ippudo\", \"chinese\", \"brisket\", \"mi\", \"korean\", \"tofu\", \"sesame\", \"banh\", \"chinatown\", \"pad\", \"sake\", \"miso\", \"totto\", \"soy\", \"soba\", \"pho\", \"kimchi\", \"vietnamese\", \"belly\", \"soup\", \"bowl\", \"spicy\", \"roll\", \"beef\", \"meat\", \"tea\", \"chicken\", \"good\", \"sauce\", \"dish\", \"like\", \"get\", \"place\", \"taste\", \"try\", \"order\", \"also\", \"come\", \"really\", \"flavor\", \"food\", \"delicious\", \"go\", \"one\", \"best\", \"music\", \"vibe\", \"pio\", \"pub\", \"latin\", \"mojitos\", \"backyard\", \"enchilada\", \"jazz\", \"lic\", \"mole\", \"ropa\", \"vieja\", \"brazilian\", \"playing\", \"sunset\", \"dj\", \"calle\", \"ocho\", \"wifi\", \"penelope\", \"hangout\", \"bogota\", \"laid\", \"gastropub\", \"joya\", \"guinness\", \"verlaine\", \"outdoors\", \"cigar\", \"atmosphere\", \"patio\", \"outdoor\", \"sangria\", \"beer\", \"friendly\", \"martini\", \"selection\", \"reasonably\", \"cozy\", \"neighborhood\", \"great\", \"relaxed\", \"gem\", \"draft\", \"staff\", \"relax\", \"ambiance\", \"decor\", \"drink\", \"date\", \"bartender\", \"cocktail\", \"spot\", \"quiet\", \"reasonable\", \"food\", \"fun\", \"bar\", \"service\", \"ambience\", \"place\", \"cute\", \"price\", \"nice\", \"attentive\", \"love\", \"recommend\", \"always\", \"happy\", \"good\", \"dinner\", \"definitely\", \"delicious\", \"back\", \"go\", \"really\", \"menu\", \"awesome\", \"restaurant\", \"time\", \"friend\", \"come\", \"also\", \"get\", \"try\", \"\\u00e2\", \"pasta\", \"scallop\", \"clam\", \"gnocchi\", \"ravioli\", \"gras\", \"spaghetti\", \"foie\", \"marrow\", \"veal\", \"bass\", \"gelato\", \"tartare\", \"filet\", \"tiramisu\", \"sorbet\", \"ragu\", \"cotta\", \"panna\", \"bolognese\", \"ink\", \"penne\", \"escargot\", \"shank\", \"anniversary\", \"bouley\", \"burrata\", \"gramercy\", \"yasuda\", \"octopus\", \"risotto\", \"sea\", \"dessert\", \"chef\", \"dish\", \"wine\", \"entree\", \"course\", \"appetizer\", \"italian\", \"oyster\", \"main\", \"olive\", \"sprout\", \"calamari\", \"fish\", \"restaurant\", \"duck\", \"meal\", \"menu\", \"dinner\", \"cook\", \"salad\", \"bread\", \"lamb\", \"start\", \"special\", \"plate\", \"perfectly\", \"order\", \"flavor\", \"us\", \"well\", \"experience\", \"service\", \"taste\", \"delicious\", \"good\", \"great\", \"would\", \"night\", \"one\", \"also\", \"pizza\", \"minute\", \"tell\", \"min\", \"cart\", \"understand\", \"behind\", \"tourist\", \"rude\", \"halal\", \"grimaldis\", \"terrible\", \"phone\", \"lombardis\", \"forever\", \"poor\", \"woman\", \"horrible\", \"drunk\", \"waste\", \"pepperoni\", \"story\", \"ruin\", \"margherita\", \"awful\", \"sicilian\", \"apologize\", \"bridge\", \"shit\", \"attempt\", \"later\", \"guy\", \"charge\", \"realize\", \"sorry\", \"line\", \"30\", \"ready\", \"card\", \"ask\", \"call\", \"pay\", \"customer\", \"20\", \"wait\", \"us\", \"walk\", \"review\", \"take\", \"know\", \"say\", \"door\", \"people\", \"dont\", \"table\", \"long\", \"bad\", \"give\", \"seat\", \"time\", \"star\", \"get\", \"leave\", \"want\", \"hour\", \"even\", \"go\", \"didnt\", \"eat\", \"one\", \"order\", \"im\", \"make\", \"place\", \"like\", \"food\", \"come\", \"would\", \"good\", \"think\", \"back\", \"bacon\", \"toast\", \"waffle\", \"mac\", \"falafel\", \"biscuit\", \"benedict\", \"crepe\", \"pita\", \"grit\", \"hummus\", \"banana\", \"strawberry\", \"ham\", \"syrup\", \"maple\", \"blueberry\", \"frites\", \"scramble\", \"hash\", \"cheesy\", \"ketchup\", \"yogurt\", \"chipotle\", \"macarons\", \"lemonade\", \"omelette\", \"cheddar\", \"patty\", \"turkey\", \"cheese\", \"onion\", \"potato\", \"fry\", \"burger\", \"sandwich\", \"egg\", \"corn\", \"french\", \"cream\", \"butter\", \"sweet\", \"tomato\", \"chicken\", \"cheesecake\", \"bread\", \"pancake\", \"sauce\", \"brunch\", \"crispy\", \"breakfast\", \"side\", \"salad\", \"flavor\", \"green\", \"good\", \"also\", \"like\", \"delicious\", \"taste\", \"order\", \"try\", \"come\", \"get\", \"really\", \"love\", \"little\", \"well\", \"fresh\", \"one\", \"best\", \"go\"], \"Total\": [474563.0, 42297.0, 115481.0, 163794.0, 169827.0, 37042.0, 51274.0, 37540.0, 22982.0, 44866.0, 22427.0, 22137.0, 55170.0, 40808.0, 72436.0, 54811.0, 184002.0, 27307.0, 28257.0, 49772.0, 16454.0, 22470.0, 21055.0, 28664.0, 31137.0, 24103.0, 149201.0, 16113.0, 65800.0, 26828.0, 42297.25, 22982.134765625, 22137.294921875, 22427.013671875, 16454.330078125, 11154.5576171875, 10455.29296875, 9735.9443359375, 7535.9287109375, 6738.7177734375, 6464.67431640625, 6495.6025390625, 4754.140625, 4397.271484375, 4244.18701171875, 4075.91943359375, 3973.857666015625, 3890.838134765625, 3739.544677734375, 3275.08056640625, 3275.83837890625, 3160.527587890625, 3166.422119140625, 3003.630126953125, 2404.9853515625, 2199.87158203125, 2107.533447265625, 2103.35546875, 2093.373046875, 2094.491455078125, 7844.51708984375, 21055.345703125, 9611.8310546875, 22470.861328125, 10990.041015625, 14230.6318359375, 25726.578125, 8308.9833984375, 51274.6328125, 184002.96875, 54811.0859375, 55170.5703125, 110380.671875, 149201.890625, 169827.5, 46883.7265625, 74940.0, 104457.6171875, 66398.3359375, 107717.9921875, 85114.0859375, 32689.73046875, 163794.640625, 65800.4296875, 131155.96875, 89224.8828125, 54221.3828125, 6866.69287109375, 6198.31201171875, 1561.575927734375, 1114.3624267578125, 978.81787109375, 961.9782104492188, 935.534912109375, 663.4474487304688, 657.995361328125, 637.5355834960938, 574.5301513671875, 506.62298583984375, 506.444091796875, 480.57861328125, 479.1330871582031, 447.729248046875, 436.86944580078125, 396.8061218261719, 370.3155212402344, 347.00787353515625, 348.83917236328125, 339.6836853027344, 328.80438232421875, 320.06494140625, 314.3152770996094, 310.8182678222656, 307.1770935058594, 300.1663513183594, 310.6400146484375, 293.84661865234375, 20090.56640625, 1841.9818115234375, 3197.808349609375, 6500.79638671875, 20284.35546875, 26828.830078125, 1947.0693359375, 13060.4580078125, 3100.53173828125, 8920.779296875, 10964.046875, 115481.2265625, 1219.8138427734375, 4112.224609375, 1255.909912109375, 25736.90234375, 1868.102783203125, 10294.9609375, 12607.1875, 40808.82421875, 12943.455078125, 8074.1630859375, 11758.0185546875, 24785.267578125, 2907.310302734375, 6698.87744140625, 163794.640625, 9483.359375, 36220.86328125, 72436.515625, 3498.2255859375, 169827.5, 9215.05859375, 37667.98046875, 47914.9765625, 10985.654296875, 63329.35546875, 26674.669921875, 28700.525390625, 16557.443359375, 184002.96875, 36015.55078125, 45982.640625, 65800.4296875, 70974.015625, 131155.96875, 85114.0859375, 49792.79296875, 18481.865234375, 66835.1875, 88096.921875, 51967.72265625, 107717.9921875, 66398.3359375, 149201.890625, 74940.0, 474563.625, 16113.1328125, 4914.06494140625, 3758.7939453125, 3675.05029296875, 2962.8818359375, 2638.087646484375, 2613.756103515625, 2506.9013671875, 2261.546142578125, 2171.640869140625, 1812.2626953125, 1607.9324951171875, 1455.988037109375, 1371.762939453125, 1298.0162353515625, 1253.6307373046875, 1065.2060546875, 972.3582763671875, 964.2774047851562, 933.7229614257812, 917.6627197265625, 915.7777099609375, 901.0901489257812, 891.575439453125, 849.0929565429688, 827.3901977539062, 832.345947265625, 814.1385498046875, 825.2628784179688, 4585.28125, 3474.705322265625, 3601.810791015625, 23824.67578125, 9192.67578125, 55170.5703125, 28664.189453125, 15089.1630859375, 13447.4599609375, 18177.896484375, 11205.4892578125, 6839.69775390625, 7961.13232421875, 5925.6298828125, 4302.57861328125, 4602.1298828125, 14533.98828125, 66835.1875, 11619.2021484375, 38145.6015625, 49792.79296875, 36015.55078125, 19839.154296875, 30441.814453125, 23957.990234375, 11210.892578125, 18742.861328125, 24793.779296875, 19665.576171875, 14708.919921875, 104457.6171875, 32689.73046875, 49772.15234375, 60635.90625, 28858.2265625, 72436.515625, 46883.7265625, 65800.4296875, 184002.96875, 115481.2265625, 66084.1015625, 37874.3671875, 89224.8828125, 66398.3359375, 44866.546875, 23898.150390625, 19868.59765625, 5016.72216796875, 4693.2119140625, 4119.53076171875, 3733.50537109375, 3518.59619140625, 3344.704345703125, 2819.73095703125, 2640.159423828125, 2667.0087890625, 2621.90869140625, 2162.05859375, 2085.6357421875, 1907.4747314453125, 1864.042724609375, 1839.677490234375, 1795.03515625, 1712.4835205078125, 1579.249755859375, 1557.224853515625, 1425.9976806640625, 1362.697998046875, 1287.2376708984375, 1266.8544921875, 1256.1766357421875, 1230.9508056640625, 1227.59619140625, 1181.5887451171875, 6405.439453125, 11190.244140625, 3975.240234375, 3788.60595703125, 2948.607666015625, 21162.505859375, 5465.599609375, 5213.92578125, 3266.0771484375, 23469.44921875, 12577.7158203125, 10118.2666015625, 7770.53125, 7593.70654296875, 77613.6484375, 49772.15234375, 19491.830078125, 22709.828125, 47572.8984375, 36755.54296875, 52069.92578125, 9236.5908203125, 38088.27734375, 52363.6484375, 55083.0625, 26219.36328125, 20473.0859375, 39547.79296875, 31705.251953125, 88096.921875, 30232.6875, 149201.890625, 20004.517578125, 41336.38671875, 25967.794921875, 43937.1640625, 131155.96875, 37851.41796875, 56209.2265625, 89224.8828125, 104457.6171875, 47652.80859375, 78513.421875, 169827.5, 110380.671875, 163794.640625, 107717.9921875, 66084.1015625, 184002.96875, 50390.13671875, 70974.015625, 11409.9892578125, 9668.703125, 7031.560546875, 6914.75, 6308.8115234375, 5090.57666015625, 3904.374755859375, 3801.855224609375, 3722.239501953125, 3495.047119140625, 3106.54931640625, 3101.709716796875, 2921.359619140625, 2532.620849609375, 2410.510009765625, 2197.791748046875, 2172.44921875, 2124.8994140625, 2061.751220703125, 2033.8724365234375, 1929.211669921875, 1891.901123046875, 1870.316162109375, 1854.3001708984375, 1609.903564453125, 1587.2681884765625, 1582.895751953125, 1528.307373046875, 1422.6419677734375, 1414.310546875, 37042.890625, 8143.3466796875, 14402.5859375, 37540.01171875, 27307.296875, 28257.560546875, 24103.20703125, 7848.97705078125, 12184.3642578125, 12624.6796875, 8068.705078125, 23612.142578125, 11695.3056640625, 51274.6328125, 3470.16943359375, 23957.990234375, 11743.80078125, 54811.0859375, 31137.32421875, 12003.3984375, 7759.82958984375, 30537.7265625, 30441.814453125, 32689.73046875, 12100.984375, 184002.96875, 66398.3359375, 110380.671875, 65800.4296875, 46883.7265625, 104457.6171875, 74940.0, 107717.9921875, 149201.890625, 85114.0859375, 63329.35546875, 47909.1328125, 60635.90625, 31723.36328125, 89224.8828125, 54221.3828125, 131155.96875], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.0720999240875244, 2.0720999240875244, 2.0720999240875244, 2.0720999240875244, 2.072000026702881, 2.072000026702881, 2.072000026702881, 2.072000026702881, 2.072000026702881, 2.072000026702881, 2.072000026702881, 2.072000026702881, 2.071899890899658, 2.071899890899658, 2.071899890899658, 2.071899890899658, 2.071899890899658, 2.071899890899658, 2.071899890899658, 2.0717999935150146, 2.0717999935150146, 2.0717999935150146, 2.0717999935150146, 2.0717999935150146, 2.0717999935150146, 2.071700096130371, 2.071700096130371, 2.071700096130371, 2.071700096130371, 2.071700096130371, 1.9811999797821045, 1.8828999996185303, 1.920199990272522, 1.7166999578475952, 1.8144999742507935, 1.6085000038146973, 1.3330999612808228, 1.701300024986267, 0.9542999863624573, 0.2676999866962433, 0.7506999969482422, 0.7247999906539917, 0.2337999939918518, 0.04809999838471413, -0.03849999979138374, 0.6326000094413757, 0.3440000116825104, 0.13519999384880066, 0.39329999685287476, -0.03869999945163727, 0.13750000298023224, 0.8216999769210815, -0.49410000443458557, 0.19789999723434448, -0.43549999594688416, -0.1429000049829483, 0.28999999165534973, 1.6260000467300415, 1.6260000467300415, 1.625599980354309, 1.6253999471664429, 1.6253000497817993, 1.6253000497817993, 1.6253000497817993, 1.624899983406067, 1.624899983406067, 1.624899983406067, 1.6246999502182007, 1.6246000528335571, 1.6246000528335571, 1.624500036239624, 1.624500036239624, 1.6243000030517578, 1.6243000030517578, 1.6240999698638916, 1.6239999532699585, 1.6238000392913818, 1.6238000392913818, 1.6237000226974487, 1.6237000226974487, 1.6236000061035156, 1.6236000061035156, 1.6234999895095825, 1.6234999895095825, 1.6234999895095825, 1.6234999895095825, 1.6233999729156494, 1.5680999755859375, 1.6047999858856201, 1.5886000394821167, 1.5736000537872314, 1.5341999530792236, 1.499899983406067, 1.5786000490188599, 1.4938000440597534, 1.542099952697754, 1.49590003490448, 1.4785000085830688, 1.3438999652862549, 1.569599986076355, 1.5063999891281128, 1.5680999755859375, 1.360700011253357, 1.538599967956543, 1.4052000045776367, 1.3884999752044678, 1.2919000387191772, 1.3722000122070312, 1.4146000146865845, 1.3782000541687012, 1.3051999807357788, 1.496000051498413, 1.4111000299453735, 1.0185999870300293, 1.354699969291687, 1.1830999851226807, 1.0680999755859375, 1.4701999425888062, 0.9064000248908997, 1.3339999914169312, 1.1060999631881714, 1.0622999668121338, 1.305799961090088, 0.9569000005722046, 1.0848000049591064, 1.0569000244140625, 1.184499979019165, 0.5149999856948853, 0.9584000110626221, 0.86080002784729, 0.7178000211715698, 0.6863999962806702, 0.4309000074863434, 0.4787999987602234, 0.696399986743927, 1.1354000568389893, 0.48080000281333923, 0.26919999718666077, 0.5598999857902527, 0.09640000015497208, 0.36910000443458557, -0.24789999425411224, 0.2101999968290329, 1.850000023841858, 1.850000023841858, 1.8497999906539917, 1.8497999906539917, 1.8497999906539917, 1.8496999740600586, 1.8496999740600586, 1.8496999740600586, 1.8496999740600586, 1.8496999740600586, 1.8495999574661255, 1.8495999574661255, 1.8494999408721924, 1.8494999408721924, 1.8494000434875488, 1.8494000434875488, 1.8494000434875488, 1.8493000268936157, 1.8492000102996826, 1.8492000102996826, 1.8490999937057495, 1.8490999937057495, 1.8490999937057495, 1.8490999937057495, 1.8490999937057495, 1.8490999937057495, 1.8489999771118164, 1.8489999771118164, 1.8489999771118164, 1.8489999771118164, 1.767699956893921, 1.7648999691009521, 1.7558000087738037, 1.4605000019073486, 1.531599998474121, 1.219499945640564, 1.3212000131607056, 1.4005999565124512, 1.4190000295639038, 1.3645000457763672, 1.4222999811172485, 1.4883999824523926, 1.4507999420166016, 1.5051000118255615, 1.5549999475479126, 1.5362000465393066, 1.1857000589370728, 0.7031000256538391, 1.23580002784729, 0.8238000273704529, 0.6739000082015991, 0.7548999786376953, 0.9611999988555908, 0.7142999768257141, 0.8008000254631042, 1.1557999849319458, 0.9083999991416931, 0.7523000240325928, 0.8597999811172485, 0.9937000274658203, -0.13410000503063202, 0.490200012922287, 0.21940000355243683, 0.09059999883174896, 0.5364999771118164, -0.1265999972820282, 0.16769999265670776, -0.08609999716281891, -0.8848999738693237, -0.6712999939918518, -0.20890000462532043, 0.27869999408721924, -0.5073000192642212, -0.25949999690055847, 1.0575000047683716, 1.0573999881744385, 1.0573999881744385, 1.0572999715805054, 1.0572999715805054, 1.0572999715805054, 1.0572999715805054, 1.0571999549865723, 1.0571999549865723, 1.0571999549865723, 1.0571999549865723, 1.0571999549865723, 1.0571999549865723, 1.0571000576019287, 1.0571000576019287, 1.0570000410079956, 1.0570000410079956, 1.0570000410079956, 1.0570000410079956, 1.0570000410079956, 1.0570000410079956, 1.0570000410079956, 1.0569000244140625, 1.0569000244140625, 1.0568000078201294, 1.0568000078201294, 1.0568000078201294, 1.0568000078201294, 1.0568000078201294, 1.0568000078201294, 1.0419000387191772, 1.0271999835968018, 1.042199969291687, 1.0404000282287598, 1.042099952697754, 1.001099944114685, 1.0250999927520752, 1.0200999975204468, 1.0335999727249146, 0.9538999795913696, 0.9591000080108643, 0.9652000069618225, 0.9801999926567078, 0.9729999899864197, 0.8133000135421753, 0.8395000100135803, 0.8960999846458435, 0.8804000020027161, 0.8199999928474426, 0.8303999900817871, 0.7955999970436096, 0.9463000297546387, 0.8129000067710876, 0.7178999781608582, 0.705299973487854, 0.7878999710083008, 0.8216999769210815, 0.7159000039100647, 0.7369999885559082, 0.5573999881744385, 0.7372999787330627, 0.43939998745918274, 0.7968000173568726, 0.6456999778747559, 0.7300999760627747, 0.6096000075340271, 0.35249999165534973, 0.6358000040054321, 0.5160999894142151, 0.3571000099182129, 0.2856999933719635, 0.5260000228881836, 0.31189998984336853, -0.0044999998062849045, 0.1696999967098236, -0.04490000009536743, 0.1429000049829483, 0.3361999988555908, -0.367000013589859, 0.4255000054836273, 0.0828000009059906, 1.7553999423980713, 1.7553999423980713, 1.7553999423980713, 1.7553999423980713, 1.7553999423980713, 1.7553000450134277, 1.7553000450134277, 1.7553000450134277, 1.7553000450134277, 1.7553000450134277, 1.7552000284194946, 1.7552000284194946, 1.7552000284194946, 1.7552000284194946, 1.7551000118255615, 1.7551000118255615, 1.7551000118255615, 1.7551000118255615, 1.7551000118255615, 1.7551000118255615, 1.7551000118255615, 1.7551000118255615, 1.7549999952316284, 1.7549999952316284, 1.7549999952316284, 1.7549999952316284, 1.7549999952316284, 1.7549999952316284, 1.7548999786376953, 1.7548999786376953, 1.6205999851226807, 1.673200011253357, 1.6440999507904053, 1.5707000494003296, 1.5759999752044678, 1.5703999996185303, 1.5526000261306763, 1.632699966430664, 1.561900019645691, 1.5098999738693237, 1.5678000450134277, 1.3818999528884888, 1.4902000427246094, 1.252500057220459, 1.6756999492645264, 1.3243000507354736, 1.4332000017166138, 1.097599983215332, 1.1638000011444092, 1.3845000267028809, 1.5018999576568604, 1.108299970626831, 1.0649000406265259, 0.9721999764442444, 1.3050999641418457, 0.14959999918937683, 0.557699978351593, 0.3009999990463257, 0.5483999848365784, 0.6926000118255615, 0.273499995470047, 0.44699999690055847, 0.24789999425411224, 0.013500000350177288, 0.24089999496936798, 0.3330000042915344, 0.4189999997615814, 0.156700000166893, 0.7001000046730042, -0.227400004863739, 0.2062000036239624, -0.6328999996185303], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.849299907684326, -4.4593000411987305, -4.496799945831299, -4.483799934387207, -4.793499946594238, -5.182300090789795, -5.247000217437744, -5.318299770355225, -5.57450008392334, -5.686299800872803, -5.727799892425537, -5.7230000495910645, -6.035200119018555, -6.1132001876831055, -6.14870023727417, -6.1890997886657715, -6.2144999504089355, -6.235599994659424, -6.275300025939941, -6.407899856567383, -6.407700061798096, -6.44350004196167, -6.441699981689453, -6.494500160217285, -6.716800212860107, -6.806000232696533, -6.848899841308594, -6.850900173187256, -6.855599880218506, -6.855100154876709, -5.625100135803223, -4.736000061035156, -5.482999801635742, -4.837200164794922, -5.454699993133545, -5.402200222015381, -5.0854997634887695, -5.847499847412109, -4.774600028991699, -4.1834001541137695, -4.911499977111816, -4.9309000968933105, -4.728400230407715, -4.61269998550415, -4.569799900054932, -5.1859002113342285, -5.00540018081665, -4.8821001052856445, -5.077199935913086, -5.025300025939941, -5.08459997177124, -5.3572998046875, -5.061600208282471, -5.281599998474121, -5.225200176239014, -5.31790018081665, -5.382999897003174, -6.113399982452393, -6.215799808502197, -7.594799995422363, -7.932400226593018, -8.062199592590332, -8.07960033416748, -8.107500076293945, -8.451499938964844, -8.459799766540527, -8.491399765014648, -8.595600128173828, -8.721500396728516, -8.72189998626709, -8.774399757385254, -8.777400016784668, -8.845399856567383, -8.86989974975586, -8.966300010681152, -9.035499572753906, -9.100700378417969, -9.095499992370605, -9.122099876403809, -9.15470027923584, -9.181699752807617, -9.199899673461914, -9.211199760437012, -9.222900390625, -9.246100425720215, -9.211799621582031, -9.267399787902832, -5.097799777984619, -7.450500011444092, -6.91510009765625, -6.220600128173828, -5.122099876403809, -4.876699924468994, -7.421199798583984, -5.602700233459473, -6.992400169372559, -5.981900215148926, -5.793000221252441, -3.5731000900268555, -7.897799968719482, -6.745699882507324, -7.870200157165527, -5.057499885559082, -7.502600193023682, -5.929299831390381, -5.7434000968933105, -4.665299892425537, -5.73330020904541, -6.162799835205078, -5.823400020599365, -5.150700092315674, -7.102799892425537, -6.353099822998047, -3.5488998889923096, -6.0619001388549805, -4.893400192260742, -4.315299987792969, -6.943699836730957, -3.6249001026153564, -6.111299991607666, -4.93120002746582, -4.734399795532227, -5.963799953460693, -4.5609002113342285, -5.297599792480469, -5.252299785614014, -5.674799919128418, -3.936199903488159, -5.123700141906738, -4.977099895477295, -4.76170015335083, -4.71750020980835, -4.358799934387207, -4.743299961090088, -5.0619001388549805, -5.613900184631348, -4.983099937438965, -4.918499946594238, -5.1554999351501465, -4.890200138092041, -5.101399898529053, -4.908699989318848, -5.139200210571289, -1.6536999940872192, -5.036499977111816, -6.2241997718811035, -6.492199897766113, -6.514800071716309, -6.730199813842773, -6.846399784088135, -6.855599880218506, -6.89739990234375, -7.000400066375732, -7.040999889373779, -7.2220001220703125, -7.341700077056885, -7.440999984741211, -7.5005998611450195, -7.5559000968933105, -7.590700149536133, -7.753699779510498, -7.84499979019165, -7.853300094604492, -7.885499954223633, -7.902900218963623, -7.90500020980835, -7.921199798583984, -7.93179988861084, -7.9807000160217285, -8.006600379943848, -8.00059986114502, -8.022700309753418, -8.009200096130371, -6.3755998611450195, -6.655700206756592, -6.628900051116943, -5.034900188446045, -5.916100025177002, -4.436200141906738, -4.989200115203857, -5.551499843597412, -5.6483001708984375, -5.401500225067139, -5.827400207519531, -6.255000114440918, -6.1407999992370605, -6.381700038909912, -6.651899814605713, -6.603400230407715, -5.803899765014648, -4.760799884796143, -5.97760009765625, -5.200900077819824, -5.084400177001953, -5.327199935913086, -5.717199802398682, -5.535999774932861, -5.689000129699707, -6.093400001525879, -5.826900005340576, -5.7032999992370605, -5.827499866485596, -5.984000205993652, -5.151500225067139, -5.688899993896484, -5.539299964904785, -5.470600128173828, -5.767199993133545, -5.510000228881836, -5.650700092315674, -5.5655999183654785, -5.335999965667725, -5.5883002281188965, -5.684100151062012, -5.753200054168701, -5.682199954986572, -5.729899883270264, -4.804999828338623, -5.434899806976318, -5.619500160217285, -6.995999813079834, -7.062699794769287, -7.1930999755859375, -7.291500091552734, -7.350800037384033, -7.401500225067139, -7.572299957275391, -7.6381001472473145, -7.627999782562256, -7.645100116729736, -7.8379998207092285, -7.874000072479248, -7.9633002281188965, -7.986299991607666, -7.999499797821045, -8.024100303649902, -8.071200370788574, -8.152199745178223, -8.166299819946289, -8.254300117492676, -8.299799919128418, -8.356800079345703, -8.372699737548828, -8.381199836730957, -8.40149974822998, -8.404199600219727, -8.442500114440918, -6.767099857330322, -6.223899841308594, -7.243899822235107, -7.293700218200684, -7.542699813842773, -5.612800121307373, -6.942599773406982, -6.994699954986572, -7.44890022277832, -5.55649995803833, -6.175099849700928, -6.386600017547607, -6.6356000900268555, -6.665800094604492, -4.501100063323975, -4.919099807739258, -5.800000190734863, -5.662899971008301, -4.98390007019043, -5.231400012969971, -4.918000221252441, -6.496699810028076, -5.2133002281188965, -4.989999771118164, -4.951900005340576, -5.611700057983398, -5.825300216674805, -5.27269983291626, -5.472599983215332, -4.630300045013428, -5.519899845123291, -4.221399784088135, -5.8734002113342285, -5.298699855804443, -5.679200172424316, -5.27370023727417, -4.43720006942749, -5.396699905395508, -5.1209001541137695, -4.81790018081665, -4.7316999435424805, -5.276199817657471, -4.990900039672852, -4.535900115966797, -4.792500019073486, -4.612400054931641, -4.843699932098389, -5.138999938964844, -4.81820011138916, -5.320799827575684, -5.321000099182129, -5.476200103759766, -5.6417999267578125, -5.960299968719482, -5.977099895477295, -6.06879997253418, -6.283400058746338, -6.548699855804443, -6.575399875640869, -6.596499919891357, -6.6595001220703125, -6.777400016784668, -6.778900146484375, -6.838900089263916, -6.9816999435424805, -7.031099796295166, -7.123600006103516, -7.135200023651123, -7.157299995422363, -7.1875, -7.201099872589111, -7.253900051116943, -7.273499965667725, -7.284999847412109, -7.293600082397461, -7.434999942779541, -7.449100017547607, -7.451900005340576, -7.486999988555908, -7.558700084686279, -7.564599990844727, -4.433499813079834, -5.895699977874756, -5.354599952697754, -4.46999979019165, -4.7829999923706055, -4.754300117492676, -4.93120002746582, -5.973100185394287, -5.604000091552734, -5.620500087738037, -6.010300159454346, -5.122499942779541, -5.716700077056885, -4.476399898529053, -6.746200084686279, -5.165500164031982, -5.769599914550781, -4.564700126647949, -5.063899993896484, -5.796500205993652, -6.115300178527832, -5.138899803161621, -5.185400009155273, -5.206900119781494, -5.867700099945068, -4.301599979400635, -4.912700176239014, -4.661200046539307, -4.931099891662598, -5.125899791717529, -4.743800163269043, -4.902400016784668, -4.738699913024902, -4.647299766540527, -4.981200218200684, -5.184800148010254, -5.377799987792969, -5.404600143432617, -5.508999824523926, -5.402400016784668, -5.466800212860107, -5.422699928283691]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 3, 4, 1, 2, 3, 4, 5, 1, 2, 4, 5, 2, 3, 2, 3, 3, 4, 1, 2, 3, 5, 1, 3, 4, 5, 2, 3, 4, 2, 3, 1, 2, 4, 5, 4, 1, 2, 3, 4, 5, 2, 5, 1, 2, 4, 5, 5, 1, 2, 3, 4, 2, 4, 3, 1, 1, 3, 5, 1, 2, 4, 4, 1, 3, 5, 1, 2, 3, 4, 5, 5, 5, 2, 3, 3, 1, 3, 5, 2, 3, 5, 2, 5, 4, 1, 1, 2, 5, 1, 2, 5, 3, 3, 5, 1, 2, 3, 1, 3, 4, 5, 2, 1, 4, 4, 1, 4, 5, 3, 5, 3, 5, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 1, 5, 2, 3, 2, 3, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 5, 3, 1, 2, 3, 4, 5, 2, 3, 1, 3, 5, 5, 1, 3, 5, 1, 2, 4, 2, 5, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 1, 2, 3, 4, 5, 2, 4, 1, 2, 2, 3, 4, 4, 1, 3, 5, 1, 1, 2, 3, 4, 5, 1, 5, 2, 1, 2, 3, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 1, 3, 5, 3, 1, 2, 3, 4, 4, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 5, 1, 5, 1, 2, 3, 4, 2, 3, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 3, 1, 2, 3, 4, 5, 1, 3, 5, 4, 5, 2, 2, 4, 4, 5, 2, 1, 2, 3, 4, 5, 5, 4, 1, 2, 4, 5, 1, 2, 4, 5, 3, 1, 2, 3, 4, 1, 2, 2, 5, 1, 1, 2, 3, 4, 5, 1, 2, 1, 3, 4, 5, 3, 4, 2, 1, 2, 3, 4, 5, 5, 2, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 4, 3, 2, 3, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 4, 1, 2, 2, 2, 2, 4, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 1, 3, 3, 5, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 2, 5, 2, 1, 2, 3, 1, 1, 5, 3, 3, 2, 5, 5, 1, 4, 2, 3, 1, 2, 4, 4, 1, 3, 5, 1, 4, 2, 5, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 2, 4, 1, 3, 5, 1, 2, 3, 4, 2, 2, 3, 3, 1, 3, 1, 4, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 2, 3, 1, 2, 3, 4, 5, 2, 3, 2, 3, 1, 2, 3, 4, 1, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 2, 4, 4, 1, 1, 2, 3, 5, 1, 2, 5, 2, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 1, 3, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 1, 3, 4, 4, 1, 2, 3, 4, 5, 1, 3, 1, 4, 1, 3, 5, 1, 3, 1, 2, 3, 4, 5, 1, 5, 1, 2, 4, 5, 1, 3, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 5, 2, 1, 1, 2, 3, 5, 5, 2, 3, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 5, 4, 4, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 1, 3, 5, 1, 4, 1, 2, 3, 4, 5, 5, 4, 3, 4, 3, 2, 2, 2, 1, 5, 1, 2, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 2, 2, 3, 4, 1, 2, 3, 4, 5, 3, 5, 3], \"Freq\": [0.057942718267440796, 0.018041254952549934, 0.005004143808037043, 0.9189188480377197, 0.03183548152446747, 0.9680548310279846, 0.18660105764865875, 0.2844800353050232, 0.12129822373390198, 0.10575566440820694, 0.301859974861145, 0.1256422996520996, 0.5659826993942261, 0.2543507516384125, 0.054005980491638184, 0.801751434803009, 0.19815519452095032, 0.8555766344070435, 0.14435890316963196, 0.9987127780914307, 0.9990633130073547, 0.14055532217025757, 0.2251085489988327, 0.6153627038002014, 0.018979093059897423, 0.01913125440478325, 0.04512248933315277, 0.9016402363777161, 0.03408686816692352, 0.9435771703720093, 0.05639462545514107, 0.9995017051696777, 0.7258557081222534, 0.2740847170352936, 0.11281328648328781, 0.6121676564216614, 0.06839136779308319, 0.206634983420372, 0.9990385174751282, 0.05657000094652176, 0.3907063603401184, 0.0523853674530983, 0.37732118368148804, 0.1230168491601944, 0.9994282126426697, 0.9999132752418518, 0.0828404650092125, 0.06423066556453705, 0.789963960647583, 0.06300955265760422, 0.9997711777687073, 0.9996700882911682, 0.6420608758926392, 0.0780765488743782, 0.2798387110233307, 0.809371829032898, 0.19060799479484558, 0.9993032217025757, 0.9999072551727295, 0.6289952397346497, 0.07814129441976547, 0.2928190529346466, 9.859815327217802e-05, 0.9121315479278564, 0.08775235712528229, 0.9998646378517151, 0.9131218791007996, 0.08681222796440125, 0.9999040365219116, 0.16829153895378113, 0.25982367992401123, 0.07047035545110703, 0.28901880979537964, 0.2124069780111313, 0.999886691570282, 0.9997932314872742, 0.9975535869598389, 0.9992257356643677, 0.9995284080505371, 0.8590455055236816, 0.05545249208807945, 0.0854155644774437, 0.9987959861755371, 0.35023805499076843, 0.6497623324394226, 0.22397398948669434, 0.776047945022583, 0.9992275834083557, 0.9997203350067139, 0.9999499917030334, 0.4466022849082947, 0.5533872842788696, 0.9999030232429504, 0.16427843272686005, 0.8357107043266296, 0.9995843768119812, 0.1710311621427536, 0.8288814425468445, 0.0091262087225914, 0.2600969672203064, 0.7307485938072205, 0.039593834429979324, 0.028542542830109596, 0.906364917755127, 0.025521326810121536, 0.9979684948921204, 0.02326950617134571, 0.9764006733894348, 0.999741792678833, 0.015093427151441574, 0.9848461151123047, 0.9997988939285278, 0.12620505690574646, 0.8737708926200867, 0.0763651505112648, 0.9232978820800781, 0.9993719458580017, 0.056457988917827606, 0.7273181676864624, 0.21625912189483643, 0.3270038068294525, 0.04044885188341141, 0.01870320551097393, 0.009107817895710468, 0.604743480682373, 0.9997440576553345, 0.9997108578681946, 0.9992988109588623, 0.9971188306808472, 0.999788761138916, 0.7804036140441895, 0.18591567873954773, 0.03367914259433746, 0.12114039063453674, 0.21658405661582947, 0.04015113785862923, 0.40067586302757263, 0.221448615193367, 0.18917137384414673, 0.41115662455558777, 0.07918684184551239, 0.32042697072029114, 0.025608433410525322, 0.08994802832603455, 0.8844464421272278, 0.9996315240859985, 0.0427590049803257, 0.02714267186820507, 0.64986252784729, 0.20457394421100616, 0.07570202648639679, 0.877838134765625, 0.12207453697919846, 0.028594784438610077, 0.1890740990638733, 0.7822772860527039, 0.9997750520706177, 0.2069413959980011, 0.10305415093898773, 0.6900545954704285, 0.9998767375946045, 0.07425490021705627, 0.9256767630577087, 0.7467125654220581, 0.2532810866832733, 0.7757588624954224, 0.22420597076416016, 0.06591477990150452, 0.788439154624939, 0.1455518901348114, 0.16560597717761993, 0.4651755392551422, 0.06469833105802536, 0.08853340893983841, 0.21599455177783966, 0.15347924828529358, 0.4031888544559479, 0.14426957070827484, 0.29907098412513733, 0.01234014704823494, 0.09943471848964691, 0.677406907081604, 0.21083183586597443, 0.07209769636392593, 0.000713315443135798, 0.0826653316617012, 0.655933141708374, 0.1886058747768402, 0.014188315719366074, 0.512889564037323, 0.33452215790748596, 0.10312212258577347, 0.03529031202197075, 0.2599393129348755, 0.07861074805259705, 0.53231281042099, 0.12914493680000305, 0.9980098009109497, 0.11891837418079376, 0.07149998098611832, 0.00011458330845925957, 0.7120397686958313, 0.09743400663137436, 0.10523363202810287, 0.8947023749351501, 0.0557364821434021, 0.943539023399353, 0.7158745527267456, 0.0025484685320407152, 0.28155675530433655, 0.9994233250617981, 0.38789239525794983, 0.5410870909690857, 0.07100315392017365, 0.9999799132347107, 0.14200516045093536, 0.08747674524784088, 0.0421283133327961, 0.5819507241249084, 0.14645282924175262, 0.183585524559021, 0.8164058923721313, 0.9993255734443665, 0.03565472736954689, 0.19311873614788055, 0.6380075812339783, 0.13320818543434143, 0.9987902045249939, 0.06211142614483833, 0.143341064453125, 0.06695926189422607, 0.6390034556388855, 0.08858104795217514, 0.027998948469758034, 0.21820467710494995, 0.2688661515712738, 0.4849223792552948, 0.9998713731765747, 0.9994438290596008, 0.29090431332588196, 0.19437196850776672, 0.5146557092666626, 0.28638964891433716, 0.25671669840812683, 0.45687130093574524, 0.9996404647827148, 0.07682791352272034, 0.5446759462356567, 0.046417880803346634, 0.3320804536342621, 0.9996951818466187, 0.17588114738464355, 0.8240068554878235, 0.12482913583517075, 0.20133426785469055, 0.24045369029045105, 0.08529990911483765, 0.34804001450538635, 0.054148994386196136, 0.34430986642837524, 0.04851087927818298, 0.39195483922958374, 0.1610807478427887, 0.015393887646496296, 0.8814398646354675, 0.057363662868738174, 0.045808929949998856, 0.99957674741745, 0.16869999468326569, 0.8312730193138123, 0.1120910793542862, 0.7622826099395752, 0.0695955902338028, 0.055992815643548965, 0.998996913433075, 0.9994200468063354, 0.04790594428777695, 0.8871110677719116, 0.06468518078327179, 0.1321296989917755, 0.15350341796875, 0.00019436751608736813, 0.5390012264251709, 0.17517204582691193, 0.07502315193414688, 0.048700567334890366, 0.08288705348968506, 0.7106591463088989, 0.0827353373169899, 0.999714195728302, 0.0814678892493248, 0.3026396632194519, 0.029987197369337082, 0.4941292405128479, 0.09177622944116592, 0.1645788699388504, 0.32917946577072144, 0.06490112841129303, 0.24062655866146088, 0.20071415603160858, 0.9986015558242798, 0.9995877146720886, 0.06004439294338226, 0.754105269908905, 0.08035938441753387, 0.024774590507149696, 0.08072307705879211, 0.2864229679107666, 0.07619214802980423, 0.63738614320755, 0.9995608329772949, 0.9997004270553589, 0.9961680173873901, 0.029758064076304436, 0.970220148563385, 0.9997407793998718, 0.9997548460960388, 0.9979872703552246, 0.026996921747922897, 0.6429736614227295, 0.07187099754810333, 0.21639814972877502, 0.04173349589109421, 0.9995710253715515, 0.9996317625045776, 0.021757720038294792, 0.25743424892425537, 0.720815896987915, 0.9998231530189514, 0.1152922585606575, 0.12217538058757782, 0.5877093076705933, 0.17480607330799103, 0.9992778301239014, 0.999760091304779, 0.24505846202373505, 0.6520018577575684, 0.10289599746465683, 0.9998934864997864, 0.9984872937202454, 0.9973673820495605, 0.9995236992835999, 0.9998217821121216, 0.06303811073303223, 0.0447007417678833, 0.02837667241692543, 0.7968866229057312, 0.067010298371315, 0.9997841715812683, 0.9966727495193481, 0.07019958645105362, 0.4995141923427582, 0.1142638698220253, 0.31603193283081055, 0.01545561384409666, 0.9844757914543152, 0.9991644024848938, 0.0341922752559185, 0.05338793992996216, 0.09767793864011765, 0.7705259323120117, 0.044190019369125366, 0.9992009997367859, 0.9991599321365356, 0.15908582508563995, 0.13551285862922668, 0.06031852960586548, 0.4115666151046753, 0.23351913690567017, 0.05476666986942291, 0.9452094435691833, 0.14934521913528442, 0.294578492641449, 0.10296575725078583, 0.19033949077129364, 0.2627682685852051, 0.9995103478431702, 0.11213087290525436, 0.1086982935667038, 0.7637103796005249, 0.015446599572896957, 0.12450782209634781, 0.5120847821235657, 0.06988859921693802, 0.05239276587963104, 0.24112041294574738, 0.9998915195465088, 0.9994387626647949, 0.06355879455804825, 0.10212115198373795, 0.6708844900131226, 0.07662226259708405, 0.08679670095443726, 0.08718254417181015, 0.20300987362861633, 0.09021387249231339, 0.4744666516780853, 0.14513441920280457, 0.9996397495269775, 0.9994877576828003, 0.9997584819793701, 0.9537410736083984, 0.046223316341638565, 0.09319554269313812, 0.15443457663059235, 0.35836371779441833, 0.23161254823207855, 0.16240404546260834, 0.4775606095790863, 0.14832909405231476, 0.05713935196399689, 0.31694847345352173, 0.06179609149694443, 0.3946354389190674, 0.30847838521003723, 0.11917387694120407, 0.11594047397375107, 0.9997743964195251, 0.9998560547828674, 0.9999518394470215, 0.9997901916503906, 0.9989831447601318, 0.9990772604942322, 0.9998990893363953, 0.8627288937568665, 0.1372668296098709, 0.07120946794748306, 0.5690287947654724, 0.11674846708774567, 0.06643016636371613, 0.17658361792564392, 0.4008515775203705, 0.2077658474445343, 0.3913728892803192, 0.9999415278434753, 0.9991479516029358, 0.07894826680421829, 0.9209904074668884, 0.7082791328430176, 0.2916145622730255, 0.9994341135025024, 0.10915116965770721, 0.16211844980716705, 0.09468210488557816, 0.4963749945163727, 0.13767459988594055, 0.07896016538143158, 0.9209972620010376, 0.1441541612148285, 0.028987834230065346, 0.13750074803829193, 0.46216830611228943, 0.22719262540340424, 0.9631596803665161, 0.036587558686733246, 0.9979397058486938, 0.020614946261048317, 0.2827610373497009, 0.6965219974517822, 0.9998330473899841, 0.2754644751548767, 0.7244673371315002, 0.9986752867698669, 0.9999297261238098, 0.9788370132446289, 0.02062995359301567, 0.9995487332344055, 0.08805856108665466, 0.9119150638580322, 0.9975943565368652, 0.9991507530212402, 0.047862496227025986, 0.16910715401172638, 0.7830493450164795, 0.9992086291313171, 0.1171398013830185, 0.4247082769870758, 0.4580893814563751, 0.9998310208320618, 0.9996533989906311, 0.9996311664581299, 0.9996669888496399, 0.9999878406524658, 0.12116412073373795, 0.48688817024230957, 0.34576261043548584, 0.04618215560913086, 0.029493160545825958, 0.08685227483510971, 0.37151211500167847, 0.2789137661457062, 0.2332502156496048, 0.9976351261138916, 0.999751091003418, 0.9999704360961914, 0.10539773851633072, 0.8945615887641907, 0.16066695749759674, 0.5945102572441101, 0.05705110728740692, 0.1877722144126892, 0.9996747970581055, 0.8781312108039856, 0.12176202982664108, 0.9988677501678467, 0.999950647354126, 0.9997023940086365, 0.03663266450166702, 0.9633815884590149, 0.016892757266759872, 0.9829472899436951, 0.14447666704654694, 0.3174680173397064, 0.04719547927379608, 0.2709539830684662, 0.21989309787750244, 0.0756843239068985, 0.806553065776825, 0.11763165146112442, 0.9195197224617004, 0.08030880242586136, 0.1291862279176712, 0.581937849521637, 0.1488303393125534, 0.031340595334768295, 0.1086798831820488, 0.9164378046989441, 0.08350718021392822, 0.9452261924743652, 0.054106615483760834, 0.08314482867717743, 0.3181108832359314, 0.31760215759277344, 0.28112438321113586, 0.03971848636865616, 0.0870988517999649, 0.8377430438995361, 0.03540317341685295, 0.9999548196792603, 0.9183512330055237, 0.08144575357437134, 0.7728815674781799, 0.053775958716869354, 0.029117271304130554, 0.08571396768093109, 0.05841652303934097, 0.9987702965736389, 0.9997894167900085, 0.9993003606796265, 0.9998666644096375, 0.07542257755994797, 0.10206355899572372, 0.32120293378829956, 0.501317024230957, 0.13737916946411133, 0.03153138607740402, 0.8310695886611938, 0.9488068222999573, 0.05107066407799721, 0.2667708396911621, 0.08916079252958298, 0.12614236772060394, 0.517924427986145, 0.04826202243566513, 0.056577764451503754, 0.04747462272644043, 0.7695804834365845, 0.07812570780515671, 0.9997832775115967, 0.999635636806488, 0.0677437037229538, 0.9100977778434753, 0.022211050614714622, 0.0330229215323925, 0.19769595563411713, 0.0365554578602314, 0.7258418798446655, 0.006907372735440731, 0.8760795593261719, 0.1238853931427002, 0.02105291746556759, 0.5723494291305542, 0.13853509724140167, 0.26806920766830444, 0.999854326248169, 0.9993546009063721, 0.9995143413543701, 0.9993255138397217, 0.16494351625442505, 0.12024470418691635, 0.0924757793545723, 0.09882857650518417, 0.5235163569450378, 0.9997468590736389, 0.9994968771934509, 0.01526144053786993, 0.9845324754714966, 0.8276758193969727, 0.09247057884931564, 0.07983721047639847, 0.999603807926178, 0.999710738658905, 0.13604219257831573, 0.2794249355792999, 0.33363208174705505, 0.09712113440036774, 0.15374824404716492, 0.7008631825447083, 0.2990984618663788, 0.08751166611909866, 0.725430965423584, 0.07706190645694733, 0.10998468846082687, 0.09505927562713623, 0.7446697354316711, 0.16013652086257935, 0.7668755054473877, 0.07390166819095612, 0.15918776392936707, 0.07061892747879028, 0.027784496545791626, 0.12092871218919754, 0.7260022759437561, 0.05464284494519234, 0.04294968396425247, 0.059596024453639984, 0.3900151550769806, 0.3265243172645569, 0.18092221021652222, 0.999213457107544, 0.9998769164085388, 0.9983712434768677, 0.9998956918716431, 0.15589436888694763, 0.06488186866044998, 0.09101249277591705, 0.688247561454773, 0.9997884035110474, 0.1701430380344391, 0.12666325271129608, 0.7031925916671753, 0.03485177457332611, 0.10804470628499985, 0.042797476053237915, 0.7886002659797668, 0.025686893612146378, 0.9993214011192322, 0.2370332032442093, 0.016146328300237656, 0.1859493851661682, 0.21540522575378418, 0.34545034170150757, 0.6902167797088623, 0.039595697075128555, 0.270189493894577, 0.9999698996543884, 0.9996217489242554, 0.9998763203620911, 0.13377617299556732, 0.04635827988386154, 0.09684435278177261, 0.5315524339675903, 0.1914660483598709, 0.06689223647117615, 0.25743237137794495, 0.028570804744958878, 0.6064797639846802, 0.04061435908079147, 0.9992170929908752, 0.999927282333374, 0.9997845888137817, 0.23291397094726562, 0.7669743895530701, 0.999590277671814, 0.9998305439949036, 0.17762209475040436, 0.24270083010196686, 0.055751267820596695, 0.253682941198349, 0.2702428698539734, 0.9997804164886475, 0.9998711347579956, 0.19581231474876404, 0.80418461561203, 0.999704897403717, 0.9961143136024475, 0.9999496340751648, 0.9991230964660645, 0.9997653365135193, 0.9999203085899353, 0.06122634559869766, 0.13600701093673706, 0.7833415865898132, 0.01941668801009655, 0.142880380153656, 0.006105122156441212, 0.8509719371795654, 0.07376068085432053, 0.13177251815795898, 0.025740034878253937, 0.6624913811683655, 0.10622602701187134, 0.999717652797699, 0.14011499285697937, 0.24975301325321198, 0.17215871810913086, 0.23585034906864166, 0.2021409571170807, 0.99709552526474, 0.4106517732143402, 0.5893416404724121, 0.999440610408783, 0.08875054121017456, 0.1763661652803421, 0.12757985293865204, 0.48613810539245605, 0.12116378545761108, 0.9984697103500366, 0.999830961227417, 0.9999986886978149], \"Term\": [\"20\", \"20\", \"20\", \"20\", \"30\", \"30\", \"also\", \"also\", \"also\", \"also\", \"also\", \"always\", \"always\", \"always\", \"always\", \"ambiance\", \"ambiance\", \"ambience\", \"ambience\", \"anniversary\", \"apologize\", \"appetizer\", \"appetizer\", \"appetizer\", \"appetizer\", \"ask\", \"ask\", \"ask\", \"ask\", \"atmosphere\", \"atmosphere\", \"attempt\", \"attentive\", \"attentive\", \"awesome\", \"awesome\", \"awesome\", \"awesome\", \"awful\", \"back\", \"back\", \"back\", \"back\", \"back\", \"backyard\", \"bacon\", \"bad\", \"bad\", \"bad\", \"bad\", \"banana\", \"banh\", \"bar\", \"bar\", \"bar\", \"bartender\", \"bartender\", \"bass\", \"bbq\", \"beef\", \"beef\", \"beef\", \"beer\", \"beer\", \"beer\", \"behind\", \"belly\", \"belly\", \"benedict\", \"best\", \"best\", \"best\", \"best\", \"best\", \"biscuit\", \"blueberry\", \"bogota\", \"bolognese\", \"bouley\", \"bowl\", \"bowl\", \"bowl\", \"brazilian\", \"bread\", \"bread\", \"breakfast\", \"breakfast\", \"bridge\", \"brisket\", \"broth\", \"brunch\", \"brunch\", \"bun\", \"burger\", \"burger\", \"burrata\", \"butter\", \"butter\", \"calamari\", \"calamari\", \"calamari\", \"call\", \"call\", \"call\", \"call\", \"calle\", \"card\", \"card\", \"cart\", \"charge\", \"charge\", \"cheddar\", \"cheese\", \"cheese\", \"cheesecake\", \"cheesecake\", \"cheesy\", \"chef\", \"chef\", \"chef\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chinatown\", \"chinese\", \"chipotle\", \"cigar\", \"clam\", \"cocktail\", \"cocktail\", \"cocktail\", \"come\", \"come\", \"come\", \"come\", \"come\", \"cook\", \"cook\", \"cook\", \"cook\", \"corn\", \"corn\", \"corn\", \"cotta\", \"course\", \"course\", \"course\", \"course\", \"course\", \"cozy\", \"cozy\", \"cream\", \"cream\", \"cream\", \"crepe\", \"crispy\", \"crispy\", \"crispy\", \"curry\", \"customer\", \"customer\", \"cute\", \"cute\", \"date\", \"date\", \"decor\", \"decor\", \"decor\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"dessert\", \"dessert\", \"dessert\", \"dessert\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"dinner\", \"dinner\", \"dinner\", \"dinner\", \"dinner\", \"dish\", \"dish\", \"dish\", \"dish\", \"dj\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"door\", \"door\", \"draft\", \"draft\", \"drink\", \"drink\", \"drink\", \"drunk\", \"duck\", \"duck\", \"duck\", \"dumpling\", \"eat\", \"eat\", \"eat\", \"eat\", \"eat\", \"egg\", \"egg\", \"enchilada\", \"entree\", \"entree\", \"entree\", \"entree\", \"escargot\", \"even\", \"even\", \"even\", \"even\", \"even\", \"experience\", \"experience\", \"experience\", \"experience\", \"falafel\", \"filet\", \"fish\", \"fish\", \"fish\", \"flavor\", \"flavor\", \"flavor\", \"foie\", \"food\", \"food\", \"food\", \"food\", \"forever\", \"french\", \"french\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"frites\", \"fry\", \"fry\", \"fun\", \"fun\", \"fun\", \"fun\", \"gastropub\", \"gelato\", \"gem\", \"gem\", \"gem\", \"get\", \"get\", \"get\", \"get\", \"get\", \"give\", \"give\", \"give\", \"give\", \"give\", \"gnocchi\", \"go\", \"go\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gramercy\", \"gras\", \"great\", \"great\", \"great\", \"great\", \"great\", \"green\", \"green\", \"green\", \"grimaldis\", \"grit\", \"guinness\", \"guy\", \"guy\", \"halal\", \"ham\", \"hangout\", \"happy\", \"happy\", \"happy\", \"happy\", \"happy\", \"hash\", \"horrible\", \"hour\", \"hour\", \"hour\", \"hummus\", \"im\", \"im\", \"im\", \"im\", \"ink\", \"ippudo\", \"italian\", \"italian\", \"italian\", \"japanese\", \"jazz\", \"joya\", \"ketchup\", \"kimchi\", \"know\", \"know\", \"know\", \"know\", \"know\", \"korean\", \"laid\", \"lamb\", \"lamb\", \"lamb\", \"lamb\", \"later\", \"later\", \"latin\", \"leave\", \"leave\", \"leave\", \"leave\", \"leave\", \"lemonade\", \"lic\", \"like\", \"like\", \"like\", \"like\", \"like\", \"line\", \"line\", \"little\", \"little\", \"little\", \"little\", \"little\", \"lombardis\", \"long\", \"long\", \"long\", \"long\", \"love\", \"love\", \"love\", \"love\", \"love\", \"mac\", \"macarons\", \"main\", \"main\", \"main\", \"main\", \"main\", \"make\", \"make\", \"make\", \"make\", \"make\", \"maple\", \"margherita\", \"marrow\", \"martini\", \"martini\", \"meal\", \"meal\", \"meal\", \"meal\", \"meal\", \"meat\", \"meat\", \"meat\", \"meat\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"mi\", \"min\", \"minute\", \"miso\", \"mojitos\", \"mole\", \"music\", \"neighborhood\", \"neighborhood\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"night\", \"night\", \"night\", \"noodle\", \"ocho\", \"octopus\", \"octopus\", \"olive\", \"olive\", \"omelette\", \"one\", \"one\", \"one\", \"one\", \"one\", \"onion\", \"onion\", \"order\", \"order\", \"order\", \"order\", \"order\", \"outdoor\", \"outdoor\", \"outdoors\", \"oyster\", \"oyster\", \"oyster\", \"pad\", \"pancake\", \"pancake\", \"panna\", \"pasta\", \"patio\", \"patio\", \"patty\", \"pay\", \"pay\", \"penelope\", \"penne\", \"people\", \"people\", \"people\", \"pepperoni\", \"perfectly\", \"perfectly\", \"perfectly\", \"pho\", \"phone\", \"pio\", \"pita\", \"pizza\", \"place\", \"place\", \"place\", \"place\", \"plate\", \"plate\", \"plate\", \"plate\", \"plate\", \"playing\", \"poor\", \"pork\", \"potato\", \"potato\", \"price\", \"price\", \"price\", \"price\", \"pub\", \"quiet\", \"quiet\", \"ragu\", \"ramen\", \"ravioli\", \"ready\", \"ready\", \"realize\", \"realize\", \"really\", \"really\", \"really\", \"really\", \"really\", \"reasonable\", \"reasonable\", \"reasonable\", \"reasonably\", \"reasonably\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"relax\", \"relax\", \"relaxed\", \"relaxed\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"review\", \"review\", \"review\", \"review\", \"rice\", \"risotto\", \"risotto\", \"roll\", \"roll\", \"roll\", \"roll\", \"roll\", \"ropa\", \"rude\", \"ruin\", \"sake\", \"salad\", \"salad\", \"salad\", \"salad\", \"sandwich\", \"sandwich\", \"sandwich\", \"sangria\", \"sangria\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scallop\", \"scramble\", \"sea\", \"sea\", \"sea\", \"seat\", \"seat\", \"seat\", \"seat\", \"seat\", \"selection\", \"selection\", \"service\", \"service\", \"service\", \"service\", \"sesame\", \"shank\", \"shit\", \"sicilian\", \"side\", \"side\", \"side\", \"side\", \"side\", \"soba\", \"sorbet\", \"sorry\", \"sorry\", \"soup\", \"soup\", \"soup\", \"soy\", \"spaghetti\", \"special\", \"special\", \"special\", \"special\", \"special\", \"spicy\", \"spicy\", \"spot\", \"spot\", \"spot\", \"spot\", \"sprout\", \"sprout\", \"sprout\", \"staff\", \"staff\", \"staff\", \"star\", \"star\", \"star\", \"star\", \"star\", \"start\", \"start\", \"start\", \"start\", \"start\", \"story\", \"strawberry\", \"sunset\", \"sushi\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"syrup\", \"table\", \"table\", \"table\", \"take\", \"take\", \"take\", \"take\", \"take\", \"tartare\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"tea\", \"tea\", \"tea\", \"tell\", \"terrible\", \"thai\", \"think\", \"think\", \"think\", \"think\", \"think\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tiramisu\", \"toast\", \"tofu\", \"tomato\", \"tomato\", \"totto\", \"tourist\", \"try\", \"try\", \"try\", \"try\", \"try\", \"turkey\", \"understand\", \"us\", \"us\", \"veal\", \"verlaine\", \"vibe\", \"vieja\", \"vietnamese\", \"waffle\", \"wait\", \"wait\", \"wait\", \"wait\", \"walk\", \"walk\", \"walk\", \"want\", \"want\", \"want\", \"want\", \"want\", \"waste\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wifi\", \"wine\", \"wine\", \"woman\", \"would\", \"would\", \"would\", \"would\", \"would\", \"yasuda\", \"yogurt\", \"\\u00e2\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2721622150076821362493232618\", ldavis_el2721622150076821362493232618_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2721622150076821362493232618\", ldavis_el2721622150076821362493232618_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2721622150076821362493232618\", ldavis_el2721622150076821362493232618_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_display = pyLDAvis.gensim.prepare(real_model, real_corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2721622161769259367869054197\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2721622161769259367869054197_data = {\"mdsDat\": {\"x\": [0.20129875947552026, 0.19796652917531724, -0.28617818865479777, -0.31426505838535296, 0.20117795838931313], \"y\": [0.06588775317007531, -0.12333944643603122, 0.045721700299760484, -0.04244639226587484, 0.054176385232070176], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [0.9157958626747131, 3.682724714279175, 45.085899353027344, 49.67921829223633, 0.6363639831542969]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [2488.0, 11857.0, 5775.0, 4902.0, 1465.0, 5331.0, 4506.0, 36383.0, 602.0, 2423.0, 15159.0, 590.0, 4071.0, 591.0, 594.0, 17377.0, 1010.0, 2190.0, 2652.0, 2398.0, 2230.0, 2438.0, 6429.0, 2161.0, 1867.0, 442.0, 2088.0, 4484.0, 2870.0, 13508.0, 20.9650936126709, 18.349594116210938, 15.148229598999023, 12.08510971069336, 11.436827659606934, 10.84628963470459, 9.312426567077637, 8.474552154541016, 6.721460342407227, 6.075888156890869, 5.507069110870361, 5.40764045715332, 5.05757474899292, 5.137190818786621, 4.625558376312256, 4.543629169464111, 4.638187408447266, 4.508160591125488, 4.4075446128845215, 4.615187168121338, 4.35731315612793, 4.420197010040283, 4.180609703063965, 4.044505596160889, 4.014123916625977, 3.9610092639923096, 3.945087432861328, 4.603988170623779, 3.8145432472229004, 3.7582249641418457, 31.59651756286621, 13.920853614807129, 31.153738021850586, 18.375019073486328, 6.057604789733887, 14.943302154541016, 6.532064914703369, 7.590788841247559, 8.009804725646973, 5.124358177185059, 4.685854911804199, 4.599426746368408, 442.09234619140625, 329.9682312011719, 2485.18603515625, 205.1017608642578, 147.7899627685547, 130.59288024902344, 115.32960510253906, 95.39051818847656, 92.4449691772461, 86.39990997314453, 73.88221740722656, 67.17882537841797, 60.72379684448242, 60.19420623779297, 59.61701202392578, 55.985626220703125, 52.96616744995117, 51.806243896484375, 48.59687423706055, 99.0094223022461, 52.880462646484375, 47.584022521972656, 41.501670837402344, 42.485618591308594, 40.26881790161133, 40.485069274902344, 43.292232513427734, 37.924598693847656, 34.62265396118164, 35.83736038208008, 527.007568359375, 60.08842086791992, 419.6824035644531, 384.53973388671875, 193.51869201660156, 140.5128631591797, 336.46112060546875, 84.17085266113281, 92.74934387207031, 85.01194763183594, 307.69708251953125, 119.71839141845703, 74.71292114257812, 84.13003540039062, 149.08042907714844, 75.87653350830078, 80.91876220703125, 65.29955291748047, 72.18463134765625, 2423.59912109375, 2189.997314453125, 1867.2861328125, 1097.484375, 994.6135864257812, 870.049072265625, 827.1890258789062, 759.4080200195312, 625.1151123046875, 1254.3780517578125, 598.31884765625, 581.99658203125, 576.6103515625, 552.0530395507812, 538.0835571289062, 529.0556030273438, 480.4634704589844, 463.5942687988281, 458.2904052734375, 451.1612243652344, 446.4677734375, 530.0870971679688, 444.0778503417969, 415.78765869140625, 398.73907470703125, 402.52008056640625, 393.9346008300781, 392.6842956542969, 386.87066650390625, 383.46728515625, 384.47308349609375, 4253.2568359375, 1939.66943359375, 3603.492431640625, 1892.189697265625, 1741.1494140625, 2646.246337890625, 1601.384765625, 3640.1875, 1398.3736572265625, 568.5480346679688, 3053.254150390625, 4847.06298828125, 2996.423095703125, 747.0802612304688, 1641.870361328125, 1634.703857421875, 1136.477783203125, 2081.879638671875, 4261.61767578125, 2333.0439453125, 6039.236328125, 3268.525634765625, 1310.3240966796875, 15745.7412109375, 2170.136962890625, 1492.75341796875, 2326.8388671875, 3844.369873046875, 1896.4224853515625, 3948.934326171875, 5217.06884765625, 3502.70703125, 3232.8505859375, 5253.9677734375, 3165.992431640625, 2859.560791015625, 4050.509765625, 4094.90087890625, 2342.8603515625, 2594.349853515625, 2249.009521484375, 5775.36474609375, 4901.64306640625, 2397.955078125, 2230.25830078125, 2161.1943359375, 2087.947509765625, 1775.55029296875, 1598.96728515625, 1467.9439697265625, 1259.0841064453125, 1114.149658203125, 1032.26513671875, 941.6964111328125, 809.5857543945312, 705.6119995117188, 637.3071899414062, 639.4599609375, 604.27880859375, 568.2490234375, 540.9061279296875, 479.7818908691406, 402.8354187011719, 387.9456481933594, 358.268310546875, 343.8365783691406, 337.3575439453125, 324.8480224609375, 317.44854736328125, 308.3611145019531, 292.104736328125, 2425.328125, 2635.128173828125, 11597.8798828125, 708.8931884765625, 444.49945068359375, 979.4813842773438, 1743.9248046875, 5051.3408203125, 2728.353759765625, 892.3840942382812, 2525.039794921875, 2837.370361328125, 1421.1339111328125, 2053.1201171875, 3360.586669921875, 1115.4586181640625, 11063.9873046875, 1832.458740234375, 12123.314453125, 9457.8125, 20637.61328125, 2489.93408203125, 4009.0810546875, 2621.535888671875, 5162.73779296875, 2987.5478515625, 3900.82958984375, 6506.189453125, 2635.32275390625, 2588.566162109375, 3491.779296875, 2916.297119140625, 3729.543212890625, 3742.811767578125, 3211.8603515625, 3126.129638671875, 3463.778076171875, 3137.174560546875, 3051.99072265625, 18.378223419189453, 16.043041229248047, 11.18112564086914, 9.98379898071289, 7.455643177032471, 5.4228363037109375, 4.496068477630615, 4.032299518585205, 4.016317367553711, 3.6589837074279785, 3.4855308532714844, 3.4855308532714844, 3.3041253089904785, 3.177586317062378, 3.0776140689849854, 3.3919148445129395, 2.9101293087005615, 2.8666841983795166, 2.7491376399993896, 2.6910858154296875, 2.6242408752441406, 2.6881093978881836, 2.473316192626953, 2.456369400024414, 2.2668697834014893, 2.3318710327148438, 2.427351474761963, 2.3577442169189453, 1.9982783794403076, 2.1020290851593018, 2.0814061164855957, 4.067654609680176], \"Term\": [\"pizza\", \"great\", \"love\", \"delicious\", \"pork\", \"best\", \"us\", \"\\u00e2\", \"ramen\", \"ask\", \"place\", \"noodle\", \"table\", \"slice\", \"pie\", \"food\", \"soup\", \"tell\", \"friendly\", \"atmosphere\", \"amaze\", \"fresh\", \"order\", \"excellent\", \"minute\", \"dumpling\", \"favorite\", \"say\", \"definitely\", \"good\", \"hood\", \"que\", \"un\", \"et\", \"en\", \"der\", \"das\", \"und\", \"macaroon\", \"zu\", \"nicht\", \"ausl\\u00e3\\u00a4nder\", \"familie\", \"vin\", \"je\", \"una\", \"mahi\", \"ist\", \"tr\\u00e3\\u00a8s\", \"bridal\", \"\\u00e3\", \"les\", \"para\", \"sehr\", \"aber\", \"es\", \"ich\", \"sizzle\", \"est\", \"gericht\", \"e\", \"da\", \"de\", \"la\", \"si\", \"die\", \"se\", \"hat\", \"le\", \"al\", \"el\", \"war\", \"dumpling\", \"crust\", \"pizza\", \"broth\", \"oven\", \"basil\", \"grimaldis\", \"ippudo\", \"crunchy\", \"lombardis\", \"vietnamese\", \"banh\", \"sesame\", \"pizzeria\", \"wonton\", \"ginger\", \"pho\", \"staple\", \"margherita\", \"mi\", \"bouley\", \"cherry\", \"spumoni\", \"flavour\", \"shanghai\", \"kimchi\", \"becco\", \"buns\", \"fara\", \"fennel\", \"ramen\", \"sicilian\", \"noodle\", \"slice\", \"bun\", \"thin\", \"pie\", \"chinatown\", \"topping\", \"di\", \"pork\", \"artichoke\", \"dough\", \"chinese\", \"soup\", \"mozzarella\", \"sauce\", \"crisp\", \"best\", \"ask\", \"tell\", \"minute\", \"call\", \"pay\", \"manager\", \"arrive\", \"rude\", \"hostess\", \"customer\", \"20\", \"person\", \"tip\", \"bill\", \"piece\", \"later\", \"turn\", \"instead\", \"saw\", \"understand\", \"attitude\", \"15\", \"30\", \"wouldnt\", \"charge\", \"dry\", \"min\", \"empty\", \"terrible\", \"horrible\", \"speak\", \"us\", \"bad\", \"table\", \"didnt\", \"review\", \"give\", \"leave\", \"say\", \"2\", \"read\", \"take\", \"order\", \"dont\", \"1\", \"star\", \"seat\", \"waitress\", \"know\", \"wait\", \"people\", \"get\", \"would\", \"line\", \"\\u00e2\", \"want\", \"hour\", \"even\", \"like\", \"never\", \"time\", \"go\", \"come\", \"one\", \"food\", \"restaurant\", \"make\", \"good\", \"place\", \"eat\", \"service\", \"back\", \"love\", \"delicious\", \"atmosphere\", \"amaze\", \"excellent\", \"favorite\", \"perfect\", \"amazing\", \"awesome\", \"wonderful\", \"fantastic\", \"highly\", \"selection\", \"ambiance\", \"cozy\", \"authentic\", \"yummy\", \"beautiful\", \"taco\", \"incredible\", \"chocolate\", \"outstanding\", \"falafel\", \"gem\", \"yum\", \"mexican\", \"greek\", \"variety\", \"ambience\", \"octopus\", \"fresh\", \"friendly\", \"great\", \"perfectly\", \"flavorful\", \"attentive\", \"spot\", \"best\", \"definitely\", \"decor\", \"recommend\", \"always\", \"tasty\", \"everything\", \"nice\", \"italian\", \"place\", \"salad\", \"food\", \"good\", \"\\u00e2\", \"chicken\", \"try\", \"price\", \"service\", \"also\", \"really\", \"go\", \"staff\", \"menu\", \"back\", \"well\", \"restaurant\", \"time\", \"one\", \"make\", \"get\", \"like\", \"come\", \"disk\", \"totto\", \"format\", \"weeknight\", \"toros\", \"hagi\", \"addiction\", \"damage\", \"gt\", \"windsor\", \"ntfs\", \"exfat\", \"cockroach\", \"hourglass\", \"circuit\", \"stake\", \"fat32\", \"data\", \"bronte\", \"ron\", \"ken\", \"criollo\", \"recomend\", \"rai\", \"dos\", \"trans\", \"robert\", \"cluny\", \"kebob\", \"posh\", \"league\", \"los\"], \"Total\": [2488.0, 11857.0, 5775.0, 4902.0, 1465.0, 5331.0, 4506.0, 36383.0, 602.0, 2423.0, 15159.0, 590.0, 4071.0, 591.0, 594.0, 17377.0, 1010.0, 2190.0, 2652.0, 2398.0, 2230.0, 2438.0, 6429.0, 2161.0, 1867.0, 442.0, 2088.0, 4484.0, 2870.0, 13508.0, 21.528491973876953, 18.87006187438965, 15.674500465393066, 12.605520248413086, 11.96609878540039, 11.363057136535645, 9.829248428344727, 8.991311073303223, 7.258090496063232, 6.592688083648682, 6.0238423347473145, 5.924499988555908, 5.574411392211914, 5.712674140930176, 5.143915176391602, 5.0652031898498535, 5.172022819519043, 5.036289691925049, 4.924312591552734, 5.158687591552734, 4.878871440887451, 4.949411392211914, 4.698153495788574, 4.56126594543457, 4.530918121337891, 4.478318691253662, 4.461889743804932, 5.223732948303223, 4.33494234085083, 4.275091648101807, 55.86484909057617, 37.414642333984375, 187.35699462890625, 272.2882385253906, 15.764562606811523, 500.3941955566406, 30.965471267700195, 75.85485076904297, 171.14968872070312, 123.66189575195312, 46.44091033935547, 17.085847854614258, 442.5541076660156, 330.42913818359375, 2488.984375, 205.56781005859375, 148.2524871826172, 131.05821228027344, 115.78839111328125, 95.85044860839844, 92.91665649414062, 86.85830688476562, 74.3443832397461, 67.63838195800781, 61.185523986816406, 60.65333557128906, 60.0761604309082, 56.45828628540039, 53.427879333496094, 52.29092788696289, 49.0559196472168, 99.95771789550781, 53.38821029663086, 48.05499267578125, 41.96165466308594, 42.95957946777344, 40.728702545166016, 40.95362091064453, 43.81033706665039, 38.38758850097656, 35.07908630371094, 36.314884185791016, 602.82470703125, 63.670021057128906, 590.3399047851562, 591.0863647460938, 278.838623046875, 190.57472229003906, 594.2991333007812, 104.91468811035156, 124.2042007446289, 112.7598876953125, 1465.4156494140625, 284.2439270019531, 118.18053436279297, 179.00819396972656, 1010.7492065429688, 164.9390106201172, 2525.576416015625, 168.8984832763672, 5331.7578125, 2423.9814453125, 2190.379150390625, 1867.6666259765625, 1097.8673095703125, 994.9952392578125, 870.4308471679688, 827.5715942382812, 759.7868041992188, 625.4959716796875, 1255.15966796875, 598.701171875, 582.3798828125, 576.9917602539062, 552.4342651367188, 538.4692993164062, 529.4373779296875, 480.8464050292969, 463.9776306152344, 458.67413330078125, 451.54351806640625, 446.8486022949219, 530.5418701171875, 444.4599914550781, 416.1708984375, 399.11944580078125, 402.90643310546875, 394.3146667480469, 393.0654296875, 387.25054931640625, 383.8469543457031, 384.8548583984375, 4506.33349609375, 2056.395263671875, 4071.45068359375, 2069.2685546875, 1905.8590087890625, 2975.995361328125, 1762.873291015625, 4484.435546875, 1577.8050537109375, 583.1362915039062, 3799.74755859375, 6429.72314453125, 3812.57568359375, 794.0171508789062, 1946.539794921875, 1966.2564697265625, 1288.380859375, 2630.94287109375, 6189.197265625, 3044.247314453125, 9503.2080078125, 4843.0908203125, 1573.6614990234375, 36383.55078125, 3017.13232421875, 1854.4107666015625, 3390.6962890625, 6981.7392578125, 2611.743896484375, 7691.93994140625, 11723.4521484375, 6554.89208984375, 6444.9052734375, 17377.474609375, 6895.72998046875, 5985.88525390625, 13508.5166015625, 15159.08203125, 4357.53955078125, 7757.28173828125, 5740.98291015625, 5775.76904296875, 4902.03076171875, 2398.34033203125, 2230.643310546875, 2161.580078125, 2088.333984375, 1775.9359130859375, 1599.3525390625, 1468.3289794921875, 1259.46923828125, 1114.53466796875, 1032.65087890625, 942.0797119140625, 809.9725952148438, 705.9951171875, 637.6925048828125, 639.8469848632812, 604.66357421875, 568.6339721679688, 541.2988891601562, 480.1675109863281, 403.2195129394531, 388.330322265625, 358.6520690917969, 344.2227783203125, 337.741943359375, 325.230712890625, 317.8335266113281, 308.74603271484375, 292.4910583496094, 2438.893310546875, 2652.58203125, 11857.712890625, 710.5276489257812, 445.18756103515625, 995.2339477539062, 1801.1922607421875, 5331.7578125, 2870.1298828125, 909.6620483398438, 2742.910888671875, 3133.835693359375, 1508.661376953125, 2248.729736328125, 3848.690673828125, 1168.542236328125, 15159.08203125, 2046.80615234375, 17377.474609375, 13508.5166015625, 36383.55078125, 3014.98583984375, 5568.67919921875, 3306.952392578125, 7757.28173828125, 3903.260986328125, 5604.88037109375, 11723.4521484375, 3535.825927734375, 3480.4296875, 5740.98291015625, 4287.71337890625, 6895.72998046875, 7691.93994140625, 6444.9052734375, 5985.88525390625, 9503.2080078125, 6981.7392578125, 6554.89208984375, 18.91143226623535, 16.605321884155273, 11.719893455505371, 10.555307388305664, 7.9996843338012695, 5.960971832275391, 5.088590621948242, 4.585122585296631, 4.611181259155273, 4.222807884216309, 4.024186134338379, 4.024186134338379, 3.8579726219177246, 3.725229263305664, 3.616448402404785, 3.988107681274414, 3.4491524696350098, 3.398642063140869, 3.304997205734253, 3.2430882453918457, 3.1654446125030518, 3.242532730102539, 3.0132498741149902, 2.9982454776763916, 2.8048322200775146, 2.8862557411193848, 3.0235061645507812, 2.9385976791381836, 2.5513651371002197, 2.7034854888916016, 2.6902050971984863, 6.924869537353516], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 4.666600227355957, 4.665200233459473, 4.658999919891357, 4.651000022888184, 4.647900104522705, 4.646599769592285, 4.639100074768066, 4.633900165557861, 4.616300106048584, 4.611499786376953, 4.603400230407715, 4.601799964904785, 4.595799922943115, 4.586999893188477, 4.586900234222412, 4.584499835968018, 4.584199905395508, 4.582399845123291, 4.582300186157227, 4.5817999839782715, 4.580100059509277, 4.579999923706055, 4.576399803161621, 4.57289981842041, 4.572000026702881, 4.570400238037109, 4.570000171661377, 4.566800117492676, 4.565199851989746, 4.564300060272217, 4.123199939727783, 3.7044999599456787, 2.8991000652313232, 1.9973000288009644, 3.7367000579833984, 1.1820000410079956, 3.13700008392334, 2.391200065612793, 1.6312999725341797, 1.509600043296814, 2.3994998931884766, 3.3808000087738037, 3.30049991607666, 3.300100088119507, 3.299999952316284, 3.2992000579833984, 3.2983999252319336, 3.2980000972747803, 3.297499895095825, 3.2967000007629395, 3.2964000701904297, 3.2962000370025635, 3.295300006866455, 3.2946999073028564, 3.2939000129699707, 3.2939000129699707, 3.293800115585327, 3.293100118637085, 3.292799949645996, 3.2922000885009766, 3.292099952697754, 3.2920000553131104, 3.2920000553131104, 3.2916998863220215, 3.2904999256134033, 3.2904000282287598, 3.2901999950408936, 3.2899999618530273, 3.289599895477295, 3.289400100708008, 3.2883999347686768, 3.288300037384033, 3.167099952697754, 3.2435998916625977, 2.9602999687194824, 2.8715999126434326, 2.936300039291382, 2.996799945831299, 2.732599973678589, 3.081199884414673, 3.009500026702881, 3.0190000534057617, 1.7407000064849854, 2.436800003051758, 2.8429999351501465, 2.5464000701904297, 1.3875999450683594, 2.5250000953674316, -0.13930000364780426, 2.3512001037597656, -1.0006999969482422, 0.7964000105857849, 0.7964000105857849, 0.7964000105857849, 0.7962999939918518, 0.7961999773979187, 0.7961999773979187, 0.7961000204086304, 0.7961000204086304, 0.7960000038146973, 0.7960000038146973, 0.7960000038146973, 0.7958999872207642, 0.7958999872207642, 0.7958999872207642, 0.7958999872207642, 0.7958999872207642, 0.795799970626831, 0.795799970626831, 0.795799970626831, 0.795799970626831, 0.7957000136375427, 0.7957000136375427, 0.7957000136375427, 0.7957000136375427, 0.7955999970436096, 0.7955999970436096, 0.7955999970436096, 0.7955999970436096, 0.7955999970436096, 0.7955999970436096, 0.7955999970436096, 0.7387999892234802, 0.7382000088691711, 0.6744999885559082, 0.707099974155426, 0.7062000036239624, 0.6791999936103821, 0.7005000114440918, 0.5879999995231628, 0.6758999824523926, 0.7713000178337097, 0.5778999924659729, 0.5139999985694885, 0.5557000041007996, 0.7357000112533569, 0.6263999938964844, 0.6118999719619751, 0.6711000204086304, 0.5625, 0.42340001463890076, 0.5304999947547913, 0.3431999981403351, 0.4034000039100647, 0.6134999990463257, -0.04089999943971634, 0.46709999442100525, 0.5796999931335449, 0.42010000348091125, 0.19990000128746033, 0.4765999913215637, 0.1298999935388565, -0.013100000098347664, 0.16990000009536743, 0.10670000314712524, -0.39959999918937683, 0.018200000748038292, 0.05790000036358833, -0.40790000557899475, -0.5123000144958496, 0.1761000007390976, -0.2987000048160553, -0.1404999941587448, 0.6995000243186951, 0.6995000243186951, 0.699400007724762, 0.699400007724762, 0.699400007724762, 0.699400007724762, 0.699400007724762, 0.6992999911308289, 0.6992999911308289, 0.6992999911308289, 0.6991999745368958, 0.6991999745368958, 0.6991999745368958, 0.6991000175476074, 0.6990000009536743, 0.6990000009536743, 0.6990000009536743, 0.6988999843597412, 0.6988999843597412, 0.6988999843597412, 0.6988000273704529, 0.6985999941825867, 0.6985999941825867, 0.6984999775886536, 0.6984999775886536, 0.6984000205993652, 0.6984000205993652, 0.6984000205993652, 0.6983000040054321, 0.6983000040054321, 0.6940000057220459, 0.6930000185966492, 0.6773999929428101, 0.6973000168800354, 0.6980000138282776, 0.6836000084877014, 0.6672999858856201, 0.6456000208854675, 0.6488999724388123, 0.680400013923645, 0.6168000102043152, 0.6001999974250793, 0.6398000121116638, 0.6086000204086304, 0.5640000104904175, 0.6531000137329102, 0.3847000002861023, 0.5889999866485596, 0.3395000100135803, 0.34310001134872437, 0.13259999454021454, 0.5081999897956848, 0.3709999918937683, 0.4672999978065491, 0.2924000024795532, 0.43220001459121704, 0.33709999918937683, 0.11069999635219574, 0.40560001134872437, 0.4034999907016754, 0.20239999890327454, 0.3140999972820282, 0.08500000089406967, -0.020800000056624413, 0.003100000089034438, 0.05000000074505806, -0.30970001220703125, -0.10040000081062317, -0.06480000168085098, 5.028600215911865, 5.02269983291626, 5.0100998878479, 5.001500129699707, 4.986700057983398, 4.962500095367432, 4.9334001541137695, 4.928699970245361, 4.919000148773193, 4.91379976272583, 4.91349983215332, 4.91349983215332, 4.902200222015381, 4.898099899291992, 4.8958001136779785, 4.895199775695801, 4.887199878692627, 4.886899948120117, 4.873000144958496, 4.87060022354126, 4.869699954986572, 4.86959981918335, 4.8597002029418945, 4.857800006866455, 4.844200134277344, 4.843900203704834, 4.837500095367432, 4.836900234222412, 4.81279993057251, 4.805500030517578, 4.800600051879883, 4.525100231170654], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.259699821472168, -6.392899990081787, -6.584700107574463, -6.8105998039245605, -6.865699768066406, -6.918700218200684, -7.071199893951416, -7.165500164031982, -7.397200107574463, -7.498199939727783, -7.596499919891357, -7.614699840545654, -7.681700229644775, -7.665999889373779, -7.770999908447266, -7.78879976272583, -7.768199920654297, -7.7967000007629395, -7.819200038909912, -7.773200035095215, -7.830699920654297, -7.816400051116943, -7.872099876403809, -7.905200004577637, -7.912700176239014, -7.92609977722168, -7.930099964141846, -7.775599956512451, -7.963699817657471, -7.978600025177002, -5.8495001792907715, -6.6691999435424805, -5.86359977722168, -6.391600131988525, -7.501200199127197, -6.598299980163574, -7.42579984664917, -7.275599956512451, -7.22189998626709, -7.668499946594238, -7.757999897003174, -7.776599884033203, -4.60260009765625, -4.895199775695801, -2.8761000633239746, -5.370699882507324, -5.698400020599365, -5.8221001625061035, -5.946400165557861, -6.136199951171875, -6.167600154876709, -6.235199928283691, -6.39169979095459, -6.486800193786621, -6.587800025939941, -6.59660005569458, -6.606200218200684, -6.669099807739258, -6.7245001792907715, -6.746699810028076, -6.8105998039245605, -6.098999977111816, -6.726099967956543, -6.831699848175049, -6.968400001525879, -6.945000171661377, -6.998600006103516, -6.993199825286865, -6.926199913024902, -7.058599948883057, -7.149700164794922, -7.115200042724609, -4.427000045776367, -6.598299980163574, -4.654699802398682, -4.742099761962891, -5.428800106048584, -5.748899936676025, -4.875699996948242, -6.261300086975098, -6.164299964904785, -6.251399993896484, -4.965099811553955, -5.908999919891357, -6.380499839782715, -6.2617998123168945, -5.689700126647949, -6.365099906921387, -6.3007001876831055, -6.515200138092041, -6.414899826049805, -5.406099796295166, -5.507400035858154, -5.666800022125244, -6.198299884796143, -6.2967000007629395, -6.430500030517578, -6.480999946594238, -6.566500186920166, -6.761099815368652, -6.064700126647949, -6.804999828338623, -6.832600116729736, -6.841899871826172, -6.88539981842041, -6.911099910736084, -6.927999973297119, -7.0243000984191895, -7.060100078582764, -7.071599960327148, -7.087299823760986, -7.097700119018555, -6.926000118255615, -7.103099822998047, -7.168900012969971, -7.2108001708984375, -7.201300144195557, -7.222899913787842, -7.226099967956543, -7.241000175476074, -7.249800205230713, -7.247200012207031, -4.843599796295166, -5.628799915313721, -5.009399890899658, -5.653600215911865, -5.736800193786621, -5.31820011138916, -5.820499897003174, -4.999300003051758, -5.955999851226807, -6.855999946594238, -5.175099849700928, -4.7129998207092285, -5.193900108337402, -6.582900047302246, -5.795499801635742, -5.799900054931641, -6.163400173187256, -5.55810022354126, -4.841700077056885, -5.444200038909912, -4.493000030517578, -5.10699987411499, -6.021100044250488, -3.5348000526428223, -5.516499996185303, -5.890699863433838, -5.446800231933594, -4.944699764251709, -5.651400089263916, -4.917900085449219, -4.639400005340576, -5.037799835205078, -5.118000030517578, -4.632299900054932, -5.138899803161621, -5.240699768066406, -4.892499923706055, -4.8815999031066895, -5.440000057220459, -5.3379998207092285, -5.480800151824951, -4.634699821472168, -4.798799991607666, -5.513700008392334, -5.58620023727417, -5.617700099945068, -5.652200222015381, -5.814199924468994, -5.919000148773193, -6.004499912261963, -6.1579999923706055, -6.280300140380859, -6.356599807739258, -6.448400020599365, -6.599599838256836, -6.736999988555908, -6.838799953460693, -6.8354997634887695, -6.892099857330322, -6.953499794006348, -7.002900123596191, -7.122799873352051, -7.297599792480469, -7.33519983291626, -7.41480016708374, -7.455900192260742, -7.474999904632568, -7.512700080871582, -7.535799980163574, -7.564799785614014, -7.61899995803833, -5.502399921417236, -5.419400215148926, -3.9375, -6.732399940490723, -7.19920015335083, -6.40910005569458, -5.832200050354004, -4.768700122833252, -5.3846001625061035, -6.502200126647949, -5.462100028991699, -5.3454999923706055, -6.036900043487549, -5.669000148773193, -5.176199913024902, -6.279099941253662, -3.984600067138672, -5.782700061798096, -3.893199920654297, -4.141499996185303, -3.3612000942230225, -5.476099967956543, -4.999800205230713, -5.424600124359131, -4.7469000816345215, -5.293900012969971, -5.027200222015381, -4.515600204467773, -5.419300079345703, -5.43720006942749, -5.137899875640869, -5.317999839782715, -5.0721001625061035, -5.06850004196167, -5.221499919891357, -5.248499870300293, -5.145999908447266, -5.244999885559082, -5.272600173950195, -6.027400016784668, -6.163300037384033, -6.5243000984191895, -6.637599945068359, -6.929599761962891, -7.247900009155273, -7.435299873352051, -7.5441999435424805, -7.5482001304626465, -7.641300201416016, -7.689899921417236, -7.689899921417236, -7.7434000968933105, -7.782400131225586, -7.8144001960754395, -7.717100143432617, -7.870299816131592, -7.88539981842041, -7.927199840545654, -7.948599815368652, -7.973700046539307, -7.949699878692627, -8.032999992370605, -8.039799690246582, -8.120100021362305, -8.091899871826172, -8.0516996383667, -8.08080005645752, -8.246199607849121, -8.195599555969238, -8.205499649047852, -7.5355000495910645]}, \"token.table\": {\"Topic\": [3, 4, 3, 3, 4, 3, 3, 1, 5, 1, 3, 4, 3, 4, 3, 4, 4, 4, 4, 4, 3, 2, 3, 4, 3, 4, 3, 4, 3, 1, 4, 4, 3, 4, 3, 4, 2, 2, 4, 2, 2, 3, 4, 3, 2, 1, 5, 2, 2, 3, 2, 3, 3, 2, 3, 4, 2, 3, 2, 3, 4, 5, 5, 5, 3, 4, 4, 5, 2, 3, 2, 2, 3, 4, 1, 4, 5, 1, 5, 1, 4, 3, 4, 3, 4, 4, 1, 1, 2, 3, 4, 3, 4, 1, 4, 5, 3, 4, 5, 2, 3, 3, 2, 1, 3, 3, 4, 1, 3, 4, 3, 1, 1, 1, 1, 3, 4, 3, 4, 4, 5, 4, 1, 4, 2, 5, 4, 2, 4, 2, 3, 4, 5, 2, 3, 4, 3, 4, 4, 1, 3, 4, 2, 3, 4, 3, 4, 3, 4, 3, 4, 4, 2, 5, 5, 1, 3, 4, 4, 1, 3, 3, 3, 4, 5, 1, 4, 3, 2, 1, 3, 4, 1, 5, 5, 2, 3, 4, 1, 3, 4, 3, 1, 3, 4, 5, 3, 4, 1, 3, 4, 3, 4, 2, 1, 5, 4, 1, 1, 3, 4, 3, 2, 3, 4, 4, 1, 2, 3, 3, 2, 4, 3, 4, 3, 4, 1, 2, 3, 5, 4, 3, 4, 3, 4, 4, 2, 1, 3, 3, 4, 4, 3, 4, 3, 2, 2, 3, 3, 2, 3, 2, 3, 4, 2, 3, 4, 5, 3, 4, 1, 5, 2, 3, 3, 4, 3, 4, 5, 3, 4, 3, 4, 3, 4, 5, 5, 3, 3, 4, 2, 3, 4, 3, 3, 4, 1, 3, 4, 3, 4, 1, 4, 3, 4, 2, 2, 1, 3, 2, 3, 1, 2, 3, 2, 3, 4, 3, 3, 4, 2, 3, 4, 5, 2, 3, 4, 3, 4, 4, 3, 4, 3, 4, 3, 3, 2, 3, 3, 4, 3, 2, 3, 5, 5, 5, 3, 4, 1, 3, 1, 1, 1, 3, 3, 4, 4, 2, 1, 3, 4, 3, 4, 3, 4, 1, 3, 5, 3, 4, 5, 4, 2, 3, 4, 3, 4, 4, 1, 3, 4, 1], \"Freq\": [0.9407857060432434, 0.05919267609715462, 0.9989786744117737, 0.8860410451889038, 0.11344874650239944, 0.9988288283348083, 0.9989650845527649, 0.8828232884407043, 0.7860722541809082, 0.040432825684547424, 0.18599100410938263, 0.7763102650642395, 0.2346755713224411, 0.7655137777328491, 0.09445293992757797, 0.9052804112434387, 0.9997116327285767, 0.9997795820236206, 1.0000338554382324, 0.9975836873054504, 0.9993093013763428, 0.4221726059913635, 0.18997767567634583, 0.3905096650123596, 1.0000076293945312, 0.9998580813407898, 0.016076622530817986, 0.9836882948875427, 0.9981009364128113, 0.8439530730247498, 0.9989140629768372, 0.9997759461402893, 0.3917447626590729, 0.6082581877708435, 0.9433984160423279, 0.056895677000284195, 0.990561842918396, 0.9995558261871338, 0.9989025592803955, 0.9815035462379456, 0.013503989204764366, 0.03901152312755585, 0.9473423361778259, 0.9992139339447021, 0.9927285313606262, 0.9692387580871582, 0.9077163338661194, 0.9972378611564636, 0.6957429051399231, 0.30483582615852356, 0.9899032711982727, 0.999210000038147, 0.9997007250785828, 0.9988556504249573, 0.1741301715373993, 0.8258745074272156, 0.8006505370140076, 0.19063107669353485, 0.46925225853919983, 0.5307019352912903, 0.9996511340141296, 0.8295431733131409, 0.6805967688560486, 0.7776104807853699, 0.5344099998474121, 0.4656064510345459, 1.000006914138794, 0.9252026677131653, 0.384846568107605, 0.6098337769508362, 0.9901346564292908, 0.998701274394989, 0.9990760684013367, 0.000796711363364011, 0.37418505549430847, 0.614732563495636, 0.8723866939544678, 0.9156346321105957, 0.8827055096626282, 0.1654595285654068, 0.8326350450515747, 0.0186882596462965, 0.9805839657783508, 0.049475111067295074, 0.9504796266555786, 0.9999937415122986, 0.9680493474006653, 0.026605205610394478, 0.753814160823822, 0.053210411220788956, 0.1684996336698532, 0.9143327474594116, 0.08553747087717056, 0.029976366087794304, 0.9692358374595642, 0.9518052339553833, 0.785820484161377, 0.21402853727340698, 0.7130551338195801, 0.6346222758293152, 0.36385011672973633, 1.000232219696045, 0.9987479448318481, 0.5728110074996948, 0.4296082556247711, 0.5376887321472168, 0.46218743920326233, 0.10766369849443436, 0.258392870426178, 0.6459821462631226, 0.9998335242271423, 0.9192636609077454, 0.8931923508644104, 0.9227343201637268, 0.9519639015197754, 0.6862897276878357, 0.3137998580932617, 0.08671562373638153, 0.9129598736763, 0.9997316598892212, 0.7454923391342163, 0.9991493821144104, 0.896955668926239, 0.9995203018188477, 0.9977455139160156, 0.8697788715362549, 0.9998400807380676, 0.9913290739059448, 0.9973324537277222, 0.9776632189750671, 0.3023454248905182, 0.6976272463798523, 0.9385750889778137, 0.0016400881577283144, 0.0036901982966810465, 0.9943034648895264, 0.006408849731087685, 0.9933717250823975, 0.9981818795204163, 0.9356524348258972, 0.6354696154594421, 0.3645084798336029, 0.9918827414512634, 0.889114260673523, 0.11088726669549942, 0.4450054466724396, 0.5549560189247131, 0.2998848855495453, 0.7001509070396423, 0.021926656365394592, 0.9780975580215454, 0.9992906451225281, 0.993191123008728, 0.8674566745758057, 0.8387894034385681, 0.10546457767486572, 0.6855197548866272, 0.21092915534973145, 0.9993696808815002, 0.9754515290260315, 0.9977934956550598, 0.999207079410553, 0.8051074743270874, 0.19467100501060486, 0.8053195476531982, 0.8964811563491821, 0.9994478225708008, 1.0000481605529785, 0.9911273121833801, 0.9927943348884583, 0.0453556552529335, 0.9541803002357483, 0.9720222353935242, 0.7838940620422363, 0.9477341771125793, 0.9767146110534668, 0.7913512587547302, 0.20867043733596802, 0.066106416285038, 0.11017736047506332, 0.8226576447486877, 0.9991738796234131, 0.04674270749092102, 0.28629907965660095, 0.666083574295044, 0.7434377670288086, 0.9081764221191406, 0.09132817387580872, 0.8081769347190857, 0.5505791306495667, 0.44931498169898987, 0.8324534893035889, 0.16712616384029388, 0.9901183247566223, 0.28881409764289856, 0.5776281952857971, 0.9998668432235718, 0.9644410014152527, 0.9667397141456604, 0.4777906537055969, 0.5222285389900208, 0.9995050430297852, 0.9988600611686707, 0.2562901973724365, 0.743873655796051, 0.9978032112121582, 0.010004229843616486, 0.9904187917709351, 0.9992020130157471, 0.999643087387085, 0.4607763886451721, 0.5395933985710144, 0.7259517312049866, 0.2737634479999542, 0.12679636478424072, 0.8732839822769165, 0.996042013168335, 0.7114545106887817, 0.2879696786403656, 0.7454923391342163, 0.9983211159706116, 0.5016365647315979, 0.4983781576156616, 0.7538427114486694, 0.2460448145866394, 0.9994555711746216, 0.9982969164848328, 0.8513983488082886, 1.000004768371582, 0.7663635015487671, 0.23355527222156525, 1.0000361204147339, 0.0014074047794565558, 0.9978500008583069, 0.9993476867675781, 0.9919914603233337, 0.5653718709945679, 0.43412482738494873, 0.9991284608840942, 0.9983991980552673, 0.0016070811543613672, 0.989228367805481, 0.2701351046562195, 0.729859471321106, 0.21017926931381226, 0.2961617112159729, 0.49337539076805115, 0.7397857308387756, 0.20713935792446136, 0.7928750514984131, 0.953891932964325, 0.6670567989349365, 0.8742176294326782, 0.12607313692569733, 0.9757581949234009, 0.02400811016559601, 0.3040207624435425, 0.6960005760192871, 0.6637352108955383, 0.07947760820388794, 0.9205548763275146, 0.45912471413612366, 0.5409144759178162, 0.9134988188743591, 0.08657513558864594, 0.6614837050437927, 0.9250442385673523, 0.9989644289016724, 0.10455313324928284, 0.8950530290603638, 0.03207188472151756, 0.28864696621894836, 0.6790528893470764, 0.9985302686691284, 0.8116963505744934, 0.1882065236568451, 0.2260582447052002, 0.3875284194946289, 0.41982245445251465, 0.8315293788909912, 0.16834019124507904, 0.8769495487213135, 0.999915361404419, 0.33439549803733826, 0.6655681729316711, 0.9969678521156311, 0.9821083545684814, 0.3806004822254181, 0.5709007382392883, 0.9423587322235107, 0.0471179373562336, 0.9571698904037476, 0.651343047618866, 0.34851083159446716, 0.1474153995513916, 0.23645825684070587, 0.615385115146637, 0.9977787733078003, 0.03164570406079292, 0.9682475328445435, 1.0009138584136963, 0.2545374035835266, 0.7452290058135986, 0.7522364854812622, 0.9944363832473755, 0.8435481190681458, 0.15617455542087555, 0.8849425911903381, 0.11494674533605576, 0.9988850951194763, 0.8034744262695312, 0.19632883369922638, 0.05766701698303223, 0.9418945908546448, 0.9998269081115723, 0.9993529915809631, 0.7398672699928284, 0.2623642683029175, 0.5133945345878601, 0.48661327362060547, 1.000014305114746, 0.7487669587135315, 0.2495889812707901, 0.875034511089325, 0.9635465145111084, 0.692939281463623, 0.27995866537094116, 0.7199193835258484, 0.8122960925102234, 0.9982397556304932, 0.9569683074951172, 0.9871272444725037, 0.8897478580474854, 0.998796284198761, 0.9437828063964844, 0.05614320561289787, 0.9973774552345276, 0.995367705821991, 0.8752468228340149, 0.6886191964149475, 0.31134894490242004, 0.881726861000061, 0.11797753721475601, 0.7192260026931763, 0.28073015809059143, 0.2926398515701294, 0.7023356556892395, 0.9473906755447388, 0.3197508454322815, 0.6800827980041504, 0.9472370147705078, 0.999627411365509, 0.9987322688102722, 0.6749821901321411, 0.324999064207077, 0.9995893836021423, 0.9993528127670288, 0.9986762404441833, 0.9100991487503052, 0.432778000831604, 0.5672343373298645, 0.8198617100715637], \"Term\": [\"1\", \"1\", \"15\", \"2\", \"2\", \"20\", \"30\", \"aber\", \"addiction\", \"al\", \"al\", \"al\", \"also\", \"also\", \"always\", \"always\", \"amaze\", \"amazing\", \"ambiance\", \"ambience\", \"arrive\", \"artichoke\", \"artichoke\", \"artichoke\", \"ask\", \"atmosphere\", \"attentive\", \"attentive\", \"attitude\", \"ausl\\u00e3\\u00a4nder\", \"authentic\", \"awesome\", \"back\", \"back\", \"bad\", \"bad\", \"banh\", \"basil\", \"beautiful\", \"becco\", \"best\", \"best\", \"best\", \"bill\", \"bouley\", \"bridal\", \"bronte\", \"broth\", \"bun\", \"bun\", \"buns\", \"call\", \"charge\", \"cherry\", \"chicken\", \"chicken\", \"chinatown\", \"chinatown\", \"chinese\", \"chinese\", \"chocolate\", \"circuit\", \"cluny\", \"cockroach\", \"come\", \"come\", \"cozy\", \"criollo\", \"crisp\", \"crisp\", \"crunchy\", \"crust\", \"customer\", \"customer\", \"da\", \"da\", \"damage\", \"das\", \"data\", \"de\", \"de\", \"decor\", \"decor\", \"definitely\", \"definitely\", \"delicious\", \"der\", \"di\", \"di\", \"di\", \"di\", \"didnt\", \"didnt\", \"die\", \"die\", \"disk\", \"dont\", \"dont\", \"dos\", \"dough\", \"dough\", \"dry\", \"dumpling\", \"e\", \"e\", \"eat\", \"eat\", \"el\", \"el\", \"el\", \"empty\", \"en\", \"es\", \"est\", \"et\", \"even\", \"even\", \"everything\", \"everything\", \"excellent\", \"exfat\", \"falafel\", \"familie\", \"fantastic\", \"fara\", \"fat32\", \"favorite\", \"fennel\", \"flavorful\", \"flavour\", \"food\", \"food\", \"format\", \"fresh\", \"fresh\", \"fresh\", \"friendly\", \"friendly\", \"gem\", \"gericht\", \"get\", \"get\", \"ginger\", \"give\", \"give\", \"go\", \"go\", \"good\", \"good\", \"great\", \"great\", \"greek\", \"grimaldis\", \"gt\", \"hagi\", \"hat\", \"hat\", \"hat\", \"highly\", \"hood\", \"horrible\", \"hostess\", \"hour\", \"hour\", \"hourglass\", \"ich\", \"incredible\", \"instead\", \"ippudo\", \"ist\", \"italian\", \"italian\", \"je\", \"kebob\", \"ken\", \"kimchi\", \"know\", \"know\", \"la\", \"la\", \"la\", \"later\", \"le\", \"le\", \"le\", \"league\", \"leave\", \"leave\", \"les\", \"like\", \"like\", \"line\", \"line\", \"lombardis\", \"los\", \"los\", \"love\", \"macaroon\", \"mahi\", \"make\", \"make\", \"manager\", \"margherita\", \"menu\", \"menu\", \"mexican\", \"mi\", \"mi\", \"min\", \"minute\", \"mozzarella\", \"mozzarella\", \"never\", \"never\", \"nice\", \"nice\", \"nicht\", \"noodle\", \"noodle\", \"ntfs\", \"octopus\", \"one\", \"one\", \"order\", \"order\", \"outstanding\", \"oven\", \"para\", \"pay\", \"people\", \"people\", \"perfect\", \"perfectly\", \"perfectly\", \"person\", \"pho\", \"pie\", \"pie\", \"piece\", \"pizza\", \"pizza\", \"pizzeria\", \"place\", \"place\", \"pork\", \"pork\", \"pork\", \"posh\", \"price\", \"price\", \"que\", \"rai\", \"ramen\", \"ramen\", \"read\", \"read\", \"really\", \"really\", \"recomend\", \"recommend\", \"recommend\", \"restaurant\", \"restaurant\", \"review\", \"review\", \"robert\", \"ron\", \"rude\", \"salad\", \"salad\", \"sauce\", \"sauce\", \"sauce\", \"saw\", \"say\", \"say\", \"se\", \"se\", \"se\", \"seat\", \"seat\", \"sehr\", \"selection\", \"service\", \"service\", \"sesame\", \"shanghai\", \"si\", \"si\", \"sicilian\", \"sicilian\", \"sizzle\", \"slice\", \"slice\", \"soup\", \"soup\", \"soup\", \"speak\", \"spot\", \"spot\", \"spumoni\", \"staff\", \"staff\", \"stake\", \"staple\", \"star\", \"star\", \"table\", \"table\", \"taco\", \"take\", \"take\", \"tasty\", \"tasty\", \"tell\", \"terrible\", \"thin\", \"thin\", \"time\", \"time\", \"tip\", \"topping\", \"topping\", \"toros\", \"totto\", \"trans\", \"try\", \"try\", \"tr\\u00e3\\u00a8s\", \"turn\", \"un\", \"una\", \"und\", \"understand\", \"us\", \"us\", \"variety\", \"vietnamese\", \"vin\", \"wait\", \"wait\", \"waitress\", \"waitress\", \"want\", \"want\", \"war\", \"war\", \"weeknight\", \"well\", \"well\", \"windsor\", \"wonderful\", \"wonton\", \"would\", \"would\", \"wouldnt\", \"yum\", \"yummy\", \"zu\", \"\\u00e2\", \"\\u00e2\", \"\\u00e3\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2721622161769259367869054197\", ldavis_el2721622161769259367869054197_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2721622161769259367869054197\", ldavis_el2721622161769259367869054197_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2721622161769259367869054197\", ldavis_el2721622161769259367869054197_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_display = pyLDAvis.gensim.prepare(fake_model, fake_corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276491c489714231bae3a8f17ded4a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=89763), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set = []\n",
    "pbar = tqdm_notebook(total=X_test.shape[0])\n",
    "for text in X_test:\n",
    "    tokens = preprocess_text(str(text))\n",
    "    test_set.append(tokens)\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "X_test = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(58, 1)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.doc2bow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions based on topics\n",
    "y_pred = []\n",
    "\n",
    "for test_text in X_test:\n",
    "    test_doc_bow = dictionary.doc2bow(test_text)\n",
    "    real_scores = []\n",
    "    fake_scores = []\n",
    "    for i in real_model.get_document_topics(test_doc_bow):\n",
    "        #real_model.get_document_topics(new_doc_bow)[0][1] -> Fit value of doc on topic 0\n",
    "        real_scores.append(i[1])\n",
    "    for i in fake_model.get_document_topics(test_doc_bow):\n",
    "        fake_scores.append(i[1])\n",
    "        \n",
    "    #Best Fit on real model\n",
    "    real_fit = max(real_scores)\n",
    "    #Best Fit on fake model\n",
    "    fake_fit = max(fake_scores)\n",
    "    \n",
    "    if real_fit >= fake_fit:\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        y_pred.append(1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 28.068357786615866 %\n",
      "Real correct: 17772\n",
      "Fake correct: 7423\n"
     ]
    }
   ],
   "source": [
    "#Evaluating\n",
    "real_correct = 0\n",
    "fake_correct = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if y_pred[i] == y_test[i]:\n",
    "        if y_test[i] == 0:\n",
    "            real_correct = real_correct + 1\n",
    "        else:\n",
    "            fake_correct = fake_correct + 1\n",
    "        \n",
    "acc = ((real_correct+fake_correct)/len(y_test))*100\n",
    "print(\"Overall Accuracy:\", acc,\"%\")\n",
    "print(\"Real correct:\", real_correct)\n",
    "print(\"Fake correct:\", fake_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_pred.to_csv(r\"E:\\Yelp\\YelpNYC\\res_lda.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(269289, 9) (89763, 2) (269289, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\X_train\")\n",
    "X_test = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\X_test\")\n",
    "y_train = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\y_train\", header=None)\n",
    "y_test = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\y_test\", header=None)\n",
    "print(X_train.shape, y_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ive never be here and not like my food hand do...\n",
       "1         this place be great murat be the man ive love ...\n",
       "2         consistently superior food and awful sound lev...\n",
       "3         the place be unassuming but the food be great ...\n",
       "4         i may be the only reviewer whose interest in p...\n",
       "5         save your time and money youre much good off a...\n",
       "6         one of the most overrated place that make me s...\n",
       "7         i get to the restaurant around 7pm on a friday...\n",
       "8         food be so so but the people be so mean really...\n",
       "9         great experience friendly and knowledgeable se...\n",
       "10        my second time here totally mediocre the kale ...\n",
       "11        i have be eat here since it open the food have...\n",
       "12        wow well worth the wait let me start off by sa...\n",
       "13        stick out like a sore thumb in a not quite yet...\n",
       "14        best french onion soup ever i mean ever get it...\n",
       "15        be here twice and i fing love it everything iv...\n",
       "16        now how many place in new york city can you cl...\n",
       "17        have dinner at the bar we be invite to get dri...\n",
       "18        my roommate and i come here for restaurant wee...\n",
       "19        im go to give you a tip so you dont end up wai...\n",
       "20        hole in the wall but great food inexpensive an...\n",
       "21                                good hamburger and hotdog\n",
       "22        yummy the tab be not bad for a party of six an...\n",
       "23        go there last saturday and it will be in my li...\n",
       "24        love love love the hole in the wall with espec...\n",
       "25        so satisfied you know when youre gluten free t...\n",
       "26        ill be go to the williamsburg location for the...\n",
       "27        this be my goto for treat myself to brunch its...\n",
       "28        as great as this place be i dont have to say m...\n",
       "29        the food be fantastic the chicken riesling be ...\n",
       "                                ...                        \n",
       "269259    decent but probably our mistake for order take...\n",
       "269260    i love eataly but can not help but be overwhel...\n",
       "269261    the pork bun live up to the hype and be that g...\n",
       "269262    great little thai place with a good selection ...\n",
       "269263    when yelp strike back seriously be everyone ta...\n",
       "269264    decide to order pizza for pick up and after re...\n",
       "269265    its be open 5 month as of aug people â im usua...\n",
       "269266    i really really want to like it here but the i...\n",
       "269267    nacho libre corn remember those yeah they deli...\n",
       "269268    maybe i just didnt order the right food but mi...\n",
       "269269    it pain me to give any pizza place other than ...\n",
       "269270    the line be a hot mess should be a good sign i...\n",
       "269271    i have brunch there yesterday the food be grea...\n",
       "269272    que rico mmmmm can you say cubano yeah its a s...\n",
       "269273    my husband and i come here for brunch about tw...\n",
       "269274    burger be delicious and perfectly season fried...\n",
       "269275                                         yum must try\n",
       "269276    pretty good but could be much good â fairly st...\n",
       "269277    doesnt get more classic then this people quali...\n",
       "269278    hearty no mess italian fare have a great chunk...\n",
       "269279    after hear all the hype its easy to think its ...\n",
       "269280    yelp be my 1 source when it come to try out ne...\n",
       "269281    mind blown â good than i could have imagine â ...\n",
       "269282    clearly you people havent heard of this place ...\n",
       "269283    i love that there be a great restaurant i can ...\n",
       "269284    we could have not possibly pick a good day to ...\n",
       "269285    rip off im embarrass to know that my fellow ne...\n",
       "269286    such a wonderful brunch spot food i have the p...\n",
       "269287                 where be the bar steak bring it back\n",
       "269288    i wait two day since arrive from la â for the ...\n",
       "Name: 0, Length: 269289, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['0'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words= 2000)\n",
    "tokenizer.fit_on_texts(str(X_train['0']))\n",
    "sequences = tokenizer.texts_to_sequences(X_train['0'].astype(str))\n",
    "data1 = pad_sequences(sequences, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 32)           64000     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 924,673\n",
      "Trainable params: 924,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(2000, 32, input_length=100))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214000/269289 [======================>.......] - ETA: 2:21 - loss: 0.6795 - acc: 0.906 - ETA: 1:19 - loss: 0.5057 - acc: 0.909 - ETA: 59s - loss: 0.4969 - acc: 0.905 - ETA: 49s - loss: 0.4524 - acc: 0.90 - ETA: 43s - loss: 0.4298 - acc: 0.90 - ETA: 39s - loss: 0.4125 - acc: 0.90 - ETA: 36s - loss: 0.3993 - acc: 0.90 - ETA: 34s - loss: 0.3894 - acc: 0.90 - ETA: 32s - loss: 0.3863 - acc: 0.90 - ETA: 31s - loss: 0.3825 - acc: 0.90 - ETA: 30s - loss: 0.3797 - acc: 0.90 - ETA: 28s - loss: 0.3759 - acc: 0.90 - ETA: 28s - loss: 0.3711 - acc: 0.90 - ETA: 27s - loss: 0.3675 - acc: 0.90 - ETA: 26s - loss: 0.3643 - acc: 0.90 - ETA: 25s - loss: 0.3634 - acc: 0.89 - ETA: 25s - loss: 0.3612 - acc: 0.89 - ETA: 24s - loss: 0.3566 - acc: 0.90 - ETA: 24s - loss: 0.3553 - acc: 0.90 - ETA: 24s - loss: 0.3546 - acc: 0.90 - ETA: 23s - loss: 0.3569 - acc: 0.89 - ETA: 23s - loss: 0.3567 - acc: 0.89 - ETA: 22s - loss: 0.3552 - acc: 0.89 - ETA: 22s - loss: 0.3522 - acc: 0.90 - ETA: 22s - loss: 0.3522 - acc: 0.89 - ETA: 21s - loss: 0.3505 - acc: 0.89 - ETA: 21s - loss: 0.3488 - acc: 0.90 - ETA: 21s - loss: 0.3472 - acc: 0.90 - ETA: 21s - loss: 0.3459 - acc: 0.90 - ETA: 21s - loss: 0.3440 - acc: 0.90 - ETA: 20s - loss: 0.3441 - acc: 0.90 - ETA: 20s - loss: 0.3435 - acc: 0.90 - ETA: 20s - loss: 0.3442 - acc: 0.90 - ETA: 20s - loss: 0.3435 - acc: 0.90 - ETA: 19s - loss: 0.3438 - acc: 0.90 - ETA: 19s - loss: 0.3443 - acc: 0.89 - ETA: 19s - loss: 0.3436 - acc: 0.89 - ETA: 19s - loss: 0.3436 - acc: 0.89 - ETA: 19s - loss: 0.3443 - acc: 0.89 - ETA: 19s - loss: 0.3433 - acc: 0.89 - ETA: 19s - loss: 0.3432 - acc: 0.89 - ETA: 18s - loss: 0.3430 - acc: 0.89 - ETA: 18s - loss: 0.3431 - acc: 0.89 - ETA: 18s - loss: 0.3430 - acc: 0.89 - ETA: 18s - loss: 0.3428 - acc: 0.89 - ETA: 18s - loss: 0.3419 - acc: 0.89 - ETA: 18s - loss: 0.3432 - acc: 0.89 - ETA: 18s - loss: 0.3430 - acc: 0.89 - ETA: 18s - loss: 0.3421 - acc: 0.89 - ETA: 17s - loss: 0.3413 - acc: 0.89 - ETA: 17s - loss: 0.3411 - acc: 0.89 - ETA: 17s - loss: 0.3410 - acc: 0.89 - ETA: 17s - loss: 0.3404 - acc: 0.89 - ETA: 17s - loss: 0.3401 - acc: 0.89 - ETA: 17s - loss: 0.3396 - acc: 0.89 - ETA: 17s - loss: 0.3395 - acc: 0.89 - ETA: 17s - loss: 0.3386 - acc: 0.89 - ETA: 17s - loss: 0.3386 - acc: 0.89 - ETA: 16s - loss: 0.3386 - acc: 0.89 - ETA: 16s - loss: 0.3382 - acc: 0.89 - ETA: 16s - loss: 0.3384 - acc: 0.89 - ETA: 16s - loss: 0.3385 - acc: 0.89 - ETA: 16s - loss: 0.3386 - acc: 0.89 - ETA: 16s - loss: 0.3386 - acc: 0.89 - ETA: 16s - loss: 0.3382 - acc: 0.89 - ETA: 16s - loss: 0.3381 - acc: 0.89 - ETA: 16s - loss: 0.3370 - acc: 0.89 - ETA: 15s - loss: 0.3367 - acc: 0.89 - ETA: 15s - loss: 0.3366 - acc: 0.89 - ETA: 15s - loss: 0.3368 - acc: 0.89 - ETA: 15s - loss: 0.3370 - acc: 0.89 - ETA: 15s - loss: 0.3371 - acc: 0.89 - ETA: 15s - loss: 0.3366 - acc: 0.89 - ETA: 15s - loss: 0.3367 - acc: 0.89 - ETA: 15s - loss: 0.3367 - acc: 0.89 - ETA: 15s - loss: 0.3368 - acc: 0.89 - ETA: 15s - loss: 0.3364 - acc: 0.89 - ETA: 15s - loss: 0.3365 - acc: 0.89 - ETA: 14s - loss: 0.3360 - acc: 0.89 - ETA: 14s - loss: 0.3357 - acc: 0.89 - ETA: 14s - loss: 0.3356 - acc: 0.89 - ETA: 14s - loss: 0.3352 - acc: 0.89 - ETA: 14s - loss: 0.3357 - acc: 0.89 - ETA: 14s - loss: 0.3359 - acc: 0.89 - ETA: 14s - loss: 0.3357 - acc: 0.89 - ETA: 14s - loss: 0.3352 - acc: 0.89 - ETA: 14s - loss: 0.3354 - acc: 0.89 - ETA: 14s - loss: 0.3356 - acc: 0.89 - ETA: 14s - loss: 0.3353 - acc: 0.89 - ETA: 13s - loss: 0.3350 - acc: 0.89 - ETA: 13s - loss: 0.3349 - acc: 0.89 - ETA: 13s - loss: 0.3348 - acc: 0.89 - ETA: 13s - loss: 0.3344 - acc: 0.89 - ETA: 13s - loss: 0.3346 - acc: 0.89 - ETA: 13s - loss: 0.3346 - acc: 0.89 - ETA: 13s - loss: 0.3346 - acc: 0.89 - ETA: 13s - loss: 0.3346 - acc: 0.89 - ETA: 13s - loss: 0.3346 - acc: 0.89 - ETA: 13s - loss: 0.3342 - acc: 0.89 - ETA: 13s - loss: 0.3339 - acc: 0.89 - ETA: 12s - loss: 0.3336 - acc: 0.89 - ETA: 12s - loss: 0.3339 - acc: 0.89 - ETA: 12s - loss: 0.3339 - acc: 0.89 - ETA: 12s - loss: 0.3337 - acc: 0.89 - ETA: 12s - loss: 0.3336 - acc: 0.89 - ETA: 12s - loss: 0.3335 - acc: 0.89 - ETA: 12s - loss: 0.3334 - acc: 0.89 - ETA: 12s - loss: 0.3333 - acc: 0.89 - ETA: 12s - loss: 0.3330 - acc: 0.89 - ETA: 12s - loss: 0.3328 - acc: 0.89 - ETA: 12s - loss: 0.3325 - acc: 0.89 - ETA: 12s - loss: 0.3326 - acc: 0.89 - ETA: 11s - loss: 0.3327 - acc: 0.89 - ETA: 11s - loss: 0.3326 - acc: 0.89 - ETA: 11s - loss: 0.3322 - acc: 0.89 - ETA: 11s - loss: 0.3319 - acc: 0.89 - ETA: 11s - loss: 0.3317 - acc: 0.89 - ETA: 11s - loss: 0.3315 - acc: 0.89 - ETA: 11s - loss: 0.3315 - acc: 0.89 - ETA: 11s - loss: 0.3314 - acc: 0.89 - ETA: 11s - loss: 0.3311 - acc: 0.89 - ETA: 11s - loss: 0.3309 - acc: 0.89 - ETA: 11s - loss: 0.3306 - acc: 0.89 - ETA: 11s - loss: 0.3307 - acc: 0.89 - ETA: 10s - loss: 0.3309 - acc: 0.89 - ETA: 10s - loss: 0.3308 - acc: 0.89 - ETA: 10s - loss: 0.3307 - acc: 0.89 - ETA: 10s - loss: 0.3305 - acc: 0.89 - ETA: 10s - loss: 0.3303 - acc: 0.89 - ETA: 10s - loss: 0.3303 - acc: 0.89 - ETA: 10s - loss: 0.3303 - acc: 0.89 - ETA: 10s - loss: 0.3301 - acc: 0.89 - ETA: 10s - loss: 0.3300 - acc: 0.89 - ETA: 10s - loss: 0.3297 - acc: 0.89 - ETA: 10s - loss: 0.3300 - acc: 0.89 - ETA: 10s - loss: 0.3302 - acc: 0.89 - ETA: 10s - loss: 0.3303 - acc: 0.89 - ETA: 9s - loss: 0.3303 - acc: 0.8987 - ETA: 9s - loss: 0.3305 - acc: 0.898 - ETA: 9s - loss: 0.3305 - acc: 0.898 - ETA: 9s - loss: 0.3306 - acc: 0.898 - ETA: 9s - loss: 0.3308 - acc: 0.898 - ETA: 9s - loss: 0.3306 - acc: 0.898 - ETA: 9s - loss: 0.3306 - acc: 0.898 - ETA: 9s - loss: 0.3305 - acc: 0.898 - ETA: 9s - loss: 0.3305 - acc: 0.898 - ETA: 9s - loss: 0.3304 - acc: 0.898 - ETA: 9s - loss: 0.3302 - acc: 0.898 - ETA: 9s - loss: 0.3302 - acc: 0.898 - ETA: 9s - loss: 0.3301 - acc: 0.898 - ETA: 8s - loss: 0.3302 - acc: 0.898 - ETA: 8s - loss: 0.3302 - acc: 0.898 - ETA: 8s - loss: 0.3302 - acc: 0.898 - ETA: 8s - loss: 0.3302 - acc: 0.898 - ETA: 8s - loss: 0.3304 - acc: 0.898 - ETA: 8s - loss: 0.3305 - acc: 0.898 - ETA: 8s - loss: 0.3304 - acc: 0.898 - ETA: 8s - loss: 0.3305 - acc: 0.898 - ETA: 8s - loss: 0.3306 - acc: 0.897 - ETA: 8s - loss: 0.3304 - acc: 0.898 - ETA: 8s - loss: 0.3305 - acc: 0.898 - ETA: 8s - loss: 0.3306 - acc: 0.897 - ETA: 8s - loss: 0.3306 - acc: 0.897 - ETA: 7s - loss: 0.3308 - acc: 0.897 - ETA: 7s - loss: 0.3307 - acc: 0.897 - ETA: 7s - loss: 0.3305 - acc: 0.897 - ETA: 7s - loss: 0.3305 - acc: 0.897 - ETA: 7s - loss: 0.3304 - acc: 0.897 - ETA: 7s - loss: 0.3303 - acc: 0.897 - ETA: 7s - loss: 0.3303 - acc: 0.897 - ETA: 7s - loss: 0.3299 - acc: 0.898 - ETA: 7s - loss: 0.3300 - acc: 0.898 - ETA: 7s - loss: 0.3301 - acc: 0.897 - ETA: 7s - loss: 0.3301 - acc: 0.897 - ETA: 7s - loss: 0.3302 - acc: 0.897 - ETA: 7s - loss: 0.3299 - acc: 0.897 - ETA: 6s - loss: 0.3300 - acc: 0.897 - ETA: 6s - loss: 0.3299 - acc: 0.897 - ETA: 6s - loss: 0.3299 - acc: 0.897 - ETA: 6s - loss: 0.3299 - acc: 0.897 - ETA: 6s - loss: 0.3297 - acc: 0.897 - ETA: 6s - loss: 0.3298 - acc: 0.897 - ETA: 6s - loss: 0.3299 - acc: 0.897 - ETA: 6s - loss: 0.3298 - acc: 0.897 - ETA: 6s - loss: 0.3296 - acc: 0.897 - ETA: 6s - loss: 0.3295 - acc: 0.898 - ETA: 6s - loss: 0.3294 - acc: 0.898 - ETA: 6s - loss: 0.3294 - acc: 0.897 - ETA: 6s - loss: 0.3296 - acc: 0.897 - ETA: 5s - loss: 0.3296 - acc: 0.897 - ETA: 5s - loss: 0.3296 - acc: 0.897 - ETA: 5s - loss: 0.3296 - acc: 0.897 - ETA: 5s - loss: 0.3296 - acc: 0.897 - ETA: 5s - loss: 0.3294 - acc: 0.897 - ETA: 5s - loss: 0.3293 - acc: 0.897 - ETA: 5s - loss: 0.3295 - acc: 0.897 - ETA: 5s - loss: 0.3294 - acc: 0.897 - ETA: 5s - loss: 0.3294 - acc: 0.897 - ETA: 5s - loss: 0.3295 - acc: 0.897 - ETA: 5s - loss: 0.3296 - acc: 0.897 - ETA: 5s - loss: 0.3296 - acc: 0.897 - ETA: 5s - loss: 0.3297 - acc: 0.897 - ETA: 4s - loss: 0.3296 - acc: 0.897 - ETA: 4s - loss: 0.3297 - acc: 0.897 - ETA: 4s - loss: 0.3298 - acc: 0.897 - ETA: 4s - loss: 0.3297 - acc: 0.897 - ETA: 4s - loss: 0.3297 - acc: 0.897 - ETA: 4s - loss: 0.3297 - acc: 0.897 - ETA: 4s - loss: 0.3296 - acc: 0.897 - ETA: 4s - loss: 0.3295 - acc: 0.897 - ETA: 4s - loss: 0.3293 - acc: 0.897 - ETA: 4s - loss: 0.3291 - acc: 0.897 - ETA: 4s - loss: 0.3292 - acc: 0.897 - ETA: 4s - loss: 0.3293 - acc: 0.8976\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269289/269289 [==============================] - ETA: 4s - loss: 0.3293 - acc: 0.897 - ETA: 3s - loss: 0.3294 - acc: 0.897 - ETA: 3s - loss: 0.3294 - acc: 0.897 - ETA: 3s - loss: 0.3295 - acc: 0.897 - ETA: 3s - loss: 0.3295 - acc: 0.897 - ETA: 3s - loss: 0.3294 - acc: 0.897 - ETA: 3s - loss: 0.3294 - acc: 0.897 - ETA: 3s - loss: 0.3294 - acc: 0.897 - ETA: 3s - loss: 0.3295 - acc: 0.897 - ETA: 3s - loss: 0.3295 - acc: 0.897 - ETA: 3s - loss: 0.3294 - acc: 0.897 - ETA: 3s - loss: 0.3293 - acc: 0.897 - ETA: 3s - loss: 0.3292 - acc: 0.897 - ETA: 3s - loss: 0.3292 - acc: 0.897 - ETA: 2s - loss: 0.3291 - acc: 0.897 - ETA: 2s - loss: 0.3289 - acc: 0.897 - ETA: 2s - loss: 0.3287 - acc: 0.897 - ETA: 2s - loss: 0.3288 - acc: 0.897 - ETA: 2s - loss: 0.3288 - acc: 0.897 - ETA: 2s - loss: 0.3288 - acc: 0.897 - ETA: 2s - loss: 0.3287 - acc: 0.897 - ETA: 2s - loss: 0.3286 - acc: 0.897 - ETA: 2s - loss: 0.3287 - acc: 0.897 - ETA: 2s - loss: 0.3285 - acc: 0.897 - ETA: 2s - loss: 0.3284 - acc: 0.897 - ETA: 2s - loss: 0.3284 - acc: 0.897 - ETA: 2s - loss: 0.3283 - acc: 0.897 - ETA: 2s - loss: 0.3284 - acc: 0.897 - ETA: 1s - loss: 0.3284 - acc: 0.897 - ETA: 1s - loss: 0.3285 - acc: 0.897 - ETA: 1s - loss: 0.3285 - acc: 0.897 - ETA: 1s - loss: 0.3285 - acc: 0.897 - ETA: 1s - loss: 0.3285 - acc: 0.897 - ETA: 1s - loss: 0.3284 - acc: 0.897 - ETA: 1s - loss: 0.3284 - acc: 0.897 - ETA: 1s - loss: 0.3284 - acc: 0.897 - ETA: 1s - loss: 0.3283 - acc: 0.897 - ETA: 1s - loss: 0.3285 - acc: 0.897 - ETA: 1s - loss: 0.3284 - acc: 0.897 - ETA: 1s - loss: 0.3285 - acc: 0.897 - ETA: 1s - loss: 0.3285 - acc: 0.897 - ETA: 0s - loss: 0.3285 - acc: 0.897 - ETA: 0s - loss: 0.3286 - acc: 0.897 - ETA: 0s - loss: 0.3285 - acc: 0.897 - ETA: 0s - loss: 0.3285 - acc: 0.897 - ETA: 0s - loss: 0.3286 - acc: 0.897 - ETA: 0s - loss: 0.3287 - acc: 0.897 - ETA: 0s - loss: 0.3286 - acc: 0.897 - ETA: 0s - loss: 0.3286 - acc: 0.897 - ETA: 0s - loss: 0.3286 - acc: 0.897 - ETA: 0s - loss: 0.3285 - acc: 0.897 - ETA: 0s - loss: 0.3285 - acc: 0.897 - ETA: 0s - loss: 0.3285 - acc: 0.897 - ETA: 0s - loss: 0.3283 - acc: 0.897 - ETA: 0s - loss: 0.3282 - acc: 0.897 - 20s 74us/step - loss: 0.3282 - acc: 0.8976\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215000/269289 [======================>.......] - ETA: 19s - loss: 0.3226 - acc: 0.90 - ETA: 19s - loss: 0.3224 - acc: 0.90 - ETA: 19s - loss: 0.3186 - acc: 0.90 - ETA: 19s - loss: 0.3153 - acc: 0.90 - ETA: 19s - loss: 0.3217 - acc: 0.89 - ETA: 19s - loss: 0.3203 - acc: 0.89 - ETA: 19s - loss: 0.3187 - acc: 0.89 - ETA: 19s - loss: 0.3180 - acc: 0.90 - ETA: 19s - loss: 0.3211 - acc: 0.89 - ETA: 19s - loss: 0.3200 - acc: 0.89 - ETA: 18s - loss: 0.3224 - acc: 0.89 - ETA: 18s - loss: 0.3238 - acc: 0.89 - ETA: 19s - loss: 0.3225 - acc: 0.89 - ETA: 18s - loss: 0.3232 - acc: 0.89 - ETA: 18s - loss: 0.3230 - acc: 0.89 - ETA: 18s - loss: 0.3253 - acc: 0.89 - ETA: 18s - loss: 0.3254 - acc: 0.89 - ETA: 18s - loss: 0.3253 - acc: 0.89 - ETA: 18s - loss: 0.3242 - acc: 0.89 - ETA: 18s - loss: 0.3249 - acc: 0.89 - ETA: 18s - loss: 0.3243 - acc: 0.89 - ETA: 18s - loss: 0.3261 - acc: 0.89 - ETA: 18s - loss: 0.3268 - acc: 0.89 - ETA: 18s - loss: 0.3260 - acc: 0.89 - ETA: 17s - loss: 0.3275 - acc: 0.89 - ETA: 17s - loss: 0.3264 - acc: 0.89 - ETA: 17s - loss: 0.3247 - acc: 0.89 - ETA: 17s - loss: 0.3233 - acc: 0.89 - ETA: 17s - loss: 0.3251 - acc: 0.89 - ETA: 17s - loss: 0.3252 - acc: 0.89 - ETA: 17s - loss: 0.3253 - acc: 0.89 - ETA: 17s - loss: 0.3256 - acc: 0.89 - ETA: 17s - loss: 0.3258 - acc: 0.89 - ETA: 17s - loss: 0.3249 - acc: 0.89 - ETA: 17s - loss: 0.3255 - acc: 0.89 - ETA: 17s - loss: 0.3247 - acc: 0.89 - ETA: 17s - loss: 0.3247 - acc: 0.89 - ETA: 16s - loss: 0.3248 - acc: 0.89 - ETA: 16s - loss: 0.3247 - acc: 0.89 - ETA: 16s - loss: 0.3248 - acc: 0.89 - ETA: 16s - loss: 0.3247 - acc: 0.89 - ETA: 16s - loss: 0.3248 - acc: 0.89 - ETA: 16s - loss: 0.3249 - acc: 0.89 - ETA: 16s - loss: 0.3250 - acc: 0.89 - ETA: 16s - loss: 0.3249 - acc: 0.89 - ETA: 16s - loss: 0.3250 - acc: 0.89 - ETA: 16s - loss: 0.3254 - acc: 0.89 - ETA: 16s - loss: 0.3253 - acc: 0.89 - ETA: 16s - loss: 0.3245 - acc: 0.89 - ETA: 16s - loss: 0.3244 - acc: 0.89 - ETA: 16s - loss: 0.3241 - acc: 0.89 - ETA: 15s - loss: 0.3252 - acc: 0.89 - ETA: 15s - loss: 0.3250 - acc: 0.89 - ETA: 15s - loss: 0.3252 - acc: 0.89 - ETA: 15s - loss: 0.3250 - acc: 0.89 - ETA: 15s - loss: 0.3249 - acc: 0.89 - ETA: 15s - loss: 0.3244 - acc: 0.89 - ETA: 15s - loss: 0.3244 - acc: 0.89 - ETA: 15s - loss: 0.3246 - acc: 0.89 - ETA: 15s - loss: 0.3248 - acc: 0.89 - ETA: 15s - loss: 0.3254 - acc: 0.89 - ETA: 15s - loss: 0.3251 - acc: 0.89 - ETA: 15s - loss: 0.3256 - acc: 0.89 - ETA: 15s - loss: 0.3255 - acc: 0.89 - ETA: 14s - loss: 0.3252 - acc: 0.89 - ETA: 14s - loss: 0.3248 - acc: 0.89 - ETA: 14s - loss: 0.3248 - acc: 0.89 - ETA: 14s - loss: 0.3249 - acc: 0.89 - ETA: 14s - loss: 0.3247 - acc: 0.89 - ETA: 14s - loss: 0.3246 - acc: 0.89 - ETA: 14s - loss: 0.3246 - acc: 0.89 - ETA: 14s - loss: 0.3246 - acc: 0.89 - ETA: 14s - loss: 0.3245 - acc: 0.89 - ETA: 14s - loss: 0.3241 - acc: 0.89 - ETA: 14s - loss: 0.3243 - acc: 0.89 - ETA: 14s - loss: 0.3242 - acc: 0.89 - ETA: 14s - loss: 0.3237 - acc: 0.89 - ETA: 14s - loss: 0.3239 - acc: 0.89 - ETA: 13s - loss: 0.3237 - acc: 0.89 - ETA: 13s - loss: 0.3235 - acc: 0.89 - ETA: 13s - loss: 0.3232 - acc: 0.89 - ETA: 13s - loss: 0.3233 - acc: 0.89 - ETA: 13s - loss: 0.3236 - acc: 0.89 - ETA: 13s - loss: 0.3236 - acc: 0.89 - ETA: 13s - loss: 0.3236 - acc: 0.89 - ETA: 13s - loss: 0.3233 - acc: 0.89 - ETA: 13s - loss: 0.3235 - acc: 0.89 - ETA: 13s - loss: 0.3236 - acc: 0.89 - ETA: 13s - loss: 0.3232 - acc: 0.89 - ETA: 13s - loss: 0.3237 - acc: 0.89 - ETA: 13s - loss: 0.3236 - acc: 0.89 - ETA: 13s - loss: 0.3237 - acc: 0.89 - ETA: 12s - loss: 0.3237 - acc: 0.89 - ETA: 12s - loss: 0.3236 - acc: 0.89 - ETA: 12s - loss: 0.3236 - acc: 0.89 - ETA: 12s - loss: 0.3237 - acc: 0.89 - ETA: 12s - loss: 0.3239 - acc: 0.89 - ETA: 12s - loss: 0.3233 - acc: 0.89 - ETA: 12s - loss: 0.3231 - acc: 0.89 - ETA: 12s - loss: 0.3231 - acc: 0.89 - ETA: 12s - loss: 0.3231 - acc: 0.89 - ETA: 12s - loss: 0.3232 - acc: 0.89 - ETA: 12s - loss: 0.3231 - acc: 0.89 - ETA: 12s - loss: 0.3230 - acc: 0.89 - ETA: 12s - loss: 0.3228 - acc: 0.89 - ETA: 11s - loss: 0.3228 - acc: 0.89 - ETA: 11s - loss: 0.3228 - acc: 0.89 - ETA: 11s - loss: 0.3226 - acc: 0.89 - ETA: 11s - loss: 0.3230 - acc: 0.89 - ETA: 11s - loss: 0.3229 - acc: 0.89 - ETA: 11s - loss: 0.3227 - acc: 0.89 - ETA: 11s - loss: 0.3225 - acc: 0.89 - ETA: 11s - loss: 0.3226 - acc: 0.89 - ETA: 11s - loss: 0.3228 - acc: 0.89 - ETA: 11s - loss: 0.3226 - acc: 0.89 - ETA: 11s - loss: 0.3226 - acc: 0.89 - ETA: 11s - loss: 0.3225 - acc: 0.89 - ETA: 11s - loss: 0.3228 - acc: 0.89 - ETA: 11s - loss: 0.3230 - acc: 0.89 - ETA: 10s - loss: 0.3229 - acc: 0.89 - ETA: 10s - loss: 0.3227 - acc: 0.89 - ETA: 10s - loss: 0.3226 - acc: 0.89 - ETA: 10s - loss: 0.3227 - acc: 0.89 - ETA: 10s - loss: 0.3228 - acc: 0.89 - ETA: 10s - loss: 0.3228 - acc: 0.89 - ETA: 10s - loss: 0.3224 - acc: 0.89 - ETA: 10s - loss: 0.3224 - acc: 0.89 - ETA: 10s - loss: 0.3224 - acc: 0.89 - ETA: 10s - loss: 0.3224 - acc: 0.89 - ETA: 10s - loss: 0.3222 - acc: 0.89 - ETA: 10s - loss: 0.3223 - acc: 0.89 - ETA: 10s - loss: 0.3223 - acc: 0.89 - ETA: 9s - loss: 0.3222 - acc: 0.8979 - ETA: 9s - loss: 0.3222 - acc: 0.897 - ETA: 9s - loss: 0.3222 - acc: 0.897 - ETA: 9s - loss: 0.3223 - acc: 0.897 - ETA: 9s - loss: 0.3223 - acc: 0.897 - ETA: 9s - loss: 0.3227 - acc: 0.897 - ETA: 9s - loss: 0.3229 - acc: 0.897 - ETA: 9s - loss: 0.3228 - acc: 0.897 - ETA: 9s - loss: 0.3230 - acc: 0.897 - ETA: 9s - loss: 0.3231 - acc: 0.897 - ETA: 9s - loss: 0.3230 - acc: 0.897 - ETA: 9s - loss: 0.3231 - acc: 0.897 - ETA: 9s - loss: 0.3231 - acc: 0.897 - ETA: 8s - loss: 0.3231 - acc: 0.897 - ETA: 8s - loss: 0.3233 - acc: 0.897 - ETA: 8s - loss: 0.3232 - acc: 0.897 - ETA: 8s - loss: 0.3233 - acc: 0.897 - ETA: 8s - loss: 0.3232 - acc: 0.897 - ETA: 8s - loss: 0.3233 - acc: 0.897 - ETA: 8s - loss: 0.3235 - acc: 0.897 - ETA: 8s - loss: 0.3235 - acc: 0.897 - ETA: 8s - loss: 0.3233 - acc: 0.897 - ETA: 8s - loss: 0.3231 - acc: 0.897 - ETA: 8s - loss: 0.3232 - acc: 0.897 - ETA: 8s - loss: 0.3229 - acc: 0.897 - ETA: 8s - loss: 0.3230 - acc: 0.897 - ETA: 8s - loss: 0.3231 - acc: 0.897 - ETA: 8s - loss: 0.3232 - acc: 0.897 - ETA: 7s - loss: 0.3233 - acc: 0.897 - ETA: 7s - loss: 0.3233 - acc: 0.897 - ETA: 7s - loss: 0.3236 - acc: 0.897 - ETA: 7s - loss: 0.3237 - acc: 0.897 - ETA: 7s - loss: 0.3238 - acc: 0.897 - ETA: 7s - loss: 0.3239 - acc: 0.897 - ETA: 7s - loss: 0.3238 - acc: 0.897 - ETA: 7s - loss: 0.3239 - acc: 0.897 - ETA: 7s - loss: 0.3239 - acc: 0.897 - ETA: 7s - loss: 0.3240 - acc: 0.897 - ETA: 7s - loss: 0.3239 - acc: 0.897 - ETA: 7s - loss: 0.3238 - acc: 0.897 - ETA: 7s - loss: 0.3239 - acc: 0.897 - ETA: 6s - loss: 0.3238 - acc: 0.897 - ETA: 6s - loss: 0.3238 - acc: 0.897 - ETA: 6s - loss: 0.3239 - acc: 0.897 - ETA: 6s - loss: 0.3238 - acc: 0.897 - ETA: 6s - loss: 0.3236 - acc: 0.897 - ETA: 6s - loss: 0.3236 - acc: 0.897 - ETA: 6s - loss: 0.3236 - acc: 0.897 - ETA: 6s - loss: 0.3236 - acc: 0.897 - ETA: 6s - loss: 0.3236 - acc: 0.897 - ETA: 6s - loss: 0.3237 - acc: 0.897 - ETA: 6s - loss: 0.3236 - acc: 0.897 - ETA: 6s - loss: 0.3236 - acc: 0.897 - ETA: 6s - loss: 0.3236 - acc: 0.897 - ETA: 6s - loss: 0.3236 - acc: 0.897 - ETA: 5s - loss: 0.3235 - acc: 0.897 - ETA: 5s - loss: 0.3234 - acc: 0.897 - ETA: 5s - loss: 0.3234 - acc: 0.897 - ETA: 5s - loss: 0.3233 - acc: 0.897 - ETA: 5s - loss: 0.3231 - acc: 0.897 - ETA: 5s - loss: 0.3232 - acc: 0.897 - ETA: 5s - loss: 0.3233 - acc: 0.897 - ETA: 5s - loss: 0.3232 - acc: 0.897 - ETA: 5s - loss: 0.3232 - acc: 0.897 - ETA: 5s - loss: 0.3233 - acc: 0.897 - ETA: 5s - loss: 0.3231 - acc: 0.897 - ETA: 5s - loss: 0.3234 - acc: 0.897 - ETA: 5s - loss: 0.3234 - acc: 0.897 - ETA: 4s - loss: 0.3233 - acc: 0.897 - ETA: 4s - loss: 0.3232 - acc: 0.897 - ETA: 4s - loss: 0.3232 - acc: 0.897 - ETA: 4s - loss: 0.3232 - acc: 0.897 - ETA: 4s - loss: 0.3231 - acc: 0.897 - ETA: 4s - loss: 0.3232 - acc: 0.897 - ETA: 4s - loss: 0.3233 - acc: 0.897 - ETA: 4s - loss: 0.3233 - acc: 0.897 - ETA: 4s - loss: 0.3233 - acc: 0.897 - ETA: 4s - loss: 0.3234 - acc: 0.897 - ETA: 4s - loss: 0.3235 - acc: 0.897 - ETA: 4s - loss: 0.3235 - acc: 0.897 - ETA: 4s - loss: 0.3234 - acc: 0.897 - ETA: 4s - loss: 0.3235 - acc: 0.897 - ETA: 3s - loss: 0.3234 - acc: 0.8974"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269289/269289 [==============================] - ETA: 3s - loss: 0.3234 - acc: 0.897 - ETA: 3s - loss: 0.3235 - acc: 0.897 - ETA: 3s - loss: 0.3236 - acc: 0.897 - ETA: 3s - loss: 0.3237 - acc: 0.897 - ETA: 3s - loss: 0.3238 - acc: 0.897 - ETA: 3s - loss: 0.3238 - acc: 0.897 - ETA: 3s - loss: 0.3237 - acc: 0.897 - ETA: 3s - loss: 0.3236 - acc: 0.897 - ETA: 3s - loss: 0.3235 - acc: 0.897 - ETA: 3s - loss: 0.3235 - acc: 0.897 - ETA: 3s - loss: 0.3235 - acc: 0.897 - ETA: 3s - loss: 0.3235 - acc: 0.897 - ETA: 2s - loss: 0.3235 - acc: 0.897 - ETA: 2s - loss: 0.3234 - acc: 0.897 - ETA: 2s - loss: 0.3234 - acc: 0.897 - ETA: 2s - loss: 0.3235 - acc: 0.897 - ETA: 2s - loss: 0.3235 - acc: 0.897 - ETA: 2s - loss: 0.3234 - acc: 0.897 - ETA: 2s - loss: 0.3233 - acc: 0.897 - ETA: 2s - loss: 0.3234 - acc: 0.897 - ETA: 2s - loss: 0.3234 - acc: 0.897 - ETA: 2s - loss: 0.3234 - acc: 0.897 - ETA: 2s - loss: 0.3233 - acc: 0.897 - ETA: 2s - loss: 0.3233 - acc: 0.897 - ETA: 2s - loss: 0.3232 - acc: 0.897 - ETA: 2s - loss: 0.3233 - acc: 0.897 - ETA: 1s - loss: 0.3233 - acc: 0.897 - ETA: 1s - loss: 0.3233 - acc: 0.897 - ETA: 1s - loss: 0.3232 - acc: 0.897 - ETA: 1s - loss: 0.3234 - acc: 0.897 - ETA: 1s - loss: 0.3233 - acc: 0.897 - ETA: 1s - loss: 0.3233 - acc: 0.897 - ETA: 1s - loss: 0.3232 - acc: 0.897 - ETA: 1s - loss: 0.3232 - acc: 0.897 - ETA: 1s - loss: 0.3232 - acc: 0.897 - ETA: 1s - loss: 0.3232 - acc: 0.897 - ETA: 1s - loss: 0.3231 - acc: 0.897 - ETA: 1s - loss: 0.3232 - acc: 0.897 - ETA: 1s - loss: 0.3232 - acc: 0.897 - ETA: 1s - loss: 0.3231 - acc: 0.897 - ETA: 0s - loss: 0.3232 - acc: 0.897 - ETA: 0s - loss: 0.3231 - acc: 0.897 - ETA: 0s - loss: 0.3230 - acc: 0.897 - ETA: 0s - loss: 0.3228 - acc: 0.897 - ETA: 0s - loss: 0.3228 - acc: 0.897 - ETA: 0s - loss: 0.3229 - acc: 0.897 - ETA: 0s - loss: 0.3230 - acc: 0.897 - ETA: 0s - loss: 0.3231 - acc: 0.897 - ETA: 0s - loss: 0.3231 - acc: 0.897 - ETA: 0s - loss: 0.3231 - acc: 0.897 - ETA: 0s - loss: 0.3230 - acc: 0.897 - ETA: 0s - loss: 0.3228 - acc: 0.897 - ETA: 0s - loss: 0.3228 - acc: 0.897 - ETA: 0s - loss: 0.3228 - acc: 0.897 - 19s 72us/step - loss: 0.3228 - acc: 0.8976\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215000/269289 [======================>.......] - ETA: 21s - loss: 0.3017 - acc: 0.90 - ETA: 21s - loss: 0.3071 - acc: 0.90 - ETA: 20s - loss: 0.3003 - acc: 0.90 - ETA: 19s - loss: 0.3028 - acc: 0.90 - ETA: 19s - loss: 0.3072 - acc: 0.90 - ETA: 18s - loss: 0.3133 - acc: 0.90 - ETA: 18s - loss: 0.3204 - acc: 0.89 - ETA: 18s - loss: 0.3187 - acc: 0.89 - ETA: 17s - loss: 0.3171 - acc: 0.89 - ETA: 17s - loss: 0.3184 - acc: 0.89 - ETA: 17s - loss: 0.3183 - acc: 0.89 - ETA: 17s - loss: 0.3187 - acc: 0.89 - ETA: 17s - loss: 0.3188 - acc: 0.89 - ETA: 17s - loss: 0.3191 - acc: 0.89 - ETA: 17s - loss: 0.3186 - acc: 0.89 - ETA: 17s - loss: 0.3212 - acc: 0.89 - ETA: 17s - loss: 0.3213 - acc: 0.89 - ETA: 16s - loss: 0.3208 - acc: 0.89 - ETA: 16s - loss: 0.3214 - acc: 0.89 - ETA: 16s - loss: 0.3206 - acc: 0.89 - ETA: 16s - loss: 0.3199 - acc: 0.89 - ETA: 16s - loss: 0.3195 - acc: 0.89 - ETA: 16s - loss: 0.3195 - acc: 0.89 - ETA: 17s - loss: 0.3179 - acc: 0.89 - ETA: 16s - loss: 0.3171 - acc: 0.89 - ETA: 16s - loss: 0.3181 - acc: 0.89 - ETA: 16s - loss: 0.3184 - acc: 0.89 - ETA: 16s - loss: 0.3176 - acc: 0.89 - ETA: 16s - loss: 0.3173 - acc: 0.89 - ETA: 16s - loss: 0.3186 - acc: 0.89 - ETA: 16s - loss: 0.3187 - acc: 0.89 - ETA: 16s - loss: 0.3186 - acc: 0.89 - ETA: 16s - loss: 0.3181 - acc: 0.89 - ETA: 16s - loss: 0.3182 - acc: 0.89 - ETA: 16s - loss: 0.3194 - acc: 0.89 - ETA: 15s - loss: 0.3195 - acc: 0.89 - ETA: 15s - loss: 0.3196 - acc: 0.89 - ETA: 15s - loss: 0.3194 - acc: 0.89 - ETA: 15s - loss: 0.3200 - acc: 0.89 - ETA: 15s - loss: 0.3203 - acc: 0.89 - ETA: 15s - loss: 0.3200 - acc: 0.89 - ETA: 15s - loss: 0.3196 - acc: 0.89 - ETA: 15s - loss: 0.3198 - acc: 0.89 - ETA: 15s - loss: 0.3205 - acc: 0.89 - ETA: 15s - loss: 0.3208 - acc: 0.89 - ETA: 15s - loss: 0.3215 - acc: 0.89 - ETA: 15s - loss: 0.3214 - acc: 0.89 - ETA: 15s - loss: 0.3218 - acc: 0.89 - ETA: 14s - loss: 0.3218 - acc: 0.89 - ETA: 14s - loss: 0.3213 - acc: 0.89 - ETA: 14s - loss: 0.3217 - acc: 0.89 - ETA: 14s - loss: 0.3217 - acc: 0.89 - ETA: 14s - loss: 0.3215 - acc: 0.89 - ETA: 14s - loss: 0.3211 - acc: 0.89 - ETA: 14s - loss: 0.3212 - acc: 0.89 - ETA: 14s - loss: 0.3210 - acc: 0.89 - ETA: 14s - loss: 0.3212 - acc: 0.89 - ETA: 14s - loss: 0.3210 - acc: 0.89 - ETA: 14s - loss: 0.3209 - acc: 0.89 - ETA: 14s - loss: 0.3210 - acc: 0.89 - ETA: 14s - loss: 0.3206 - acc: 0.89 - ETA: 14s - loss: 0.3206 - acc: 0.89 - ETA: 13s - loss: 0.3205 - acc: 0.89 - ETA: 13s - loss: 0.3204 - acc: 0.89 - ETA: 13s - loss: 0.3203 - acc: 0.89 - ETA: 13s - loss: 0.3199 - acc: 0.89 - ETA: 13s - loss: 0.3207 - acc: 0.89 - ETA: 13s - loss: 0.3209 - acc: 0.89 - ETA: 13s - loss: 0.3213 - acc: 0.89 - ETA: 13s - loss: 0.3211 - acc: 0.89 - ETA: 13s - loss: 0.3208 - acc: 0.89 - ETA: 13s - loss: 0.3209 - acc: 0.89 - ETA: 13s - loss: 0.3211 - acc: 0.89 - ETA: 13s - loss: 0.3211 - acc: 0.89 - ETA: 13s - loss: 0.3213 - acc: 0.89 - ETA: 13s - loss: 0.3216 - acc: 0.89 - ETA: 13s - loss: 0.3219 - acc: 0.89 - ETA: 12s - loss: 0.3220 - acc: 0.89 - ETA: 12s - loss: 0.3218 - acc: 0.89 - ETA: 12s - loss: 0.3220 - acc: 0.89 - ETA: 12s - loss: 0.3221 - acc: 0.89 - ETA: 12s - loss: 0.3219 - acc: 0.89 - ETA: 12s - loss: 0.3220 - acc: 0.89 - ETA: 12s - loss: 0.3224 - acc: 0.89 - ETA: 12s - loss: 0.3221 - acc: 0.89 - ETA: 12s - loss: 0.3223 - acc: 0.89 - ETA: 12s - loss: 0.3224 - acc: 0.89 - ETA: 12s - loss: 0.3221 - acc: 0.89 - ETA: 12s - loss: 0.3215 - acc: 0.89 - ETA: 12s - loss: 0.3215 - acc: 0.89 - ETA: 12s - loss: 0.3218 - acc: 0.89 - ETA: 12s - loss: 0.3217 - acc: 0.89 - ETA: 11s - loss: 0.3216 - acc: 0.89 - ETA: 11s - loss: 0.3217 - acc: 0.89 - ETA: 11s - loss: 0.3221 - acc: 0.89 - ETA: 11s - loss: 0.3221 - acc: 0.89 - ETA: 11s - loss: 0.3222 - acc: 0.89 - ETA: 11s - loss: 0.3221 - acc: 0.89 - ETA: 11s - loss: 0.3224 - acc: 0.89 - ETA: 11s - loss: 0.3226 - acc: 0.89 - ETA: 11s - loss: 0.3227 - acc: 0.89 - ETA: 11s - loss: 0.3228 - acc: 0.89 - ETA: 11s - loss: 0.3226 - acc: 0.89 - ETA: 11s - loss: 0.3227 - acc: 0.89 - ETA: 11s - loss: 0.3227 - acc: 0.89 - ETA: 11s - loss: 0.3227 - acc: 0.89 - ETA: 10s - loss: 0.3227 - acc: 0.89 - ETA: 10s - loss: 0.3229 - acc: 0.89 - ETA: 10s - loss: 0.3228 - acc: 0.89 - ETA: 10s - loss: 0.3227 - acc: 0.89 - ETA: 10s - loss: 0.3228 - acc: 0.89 - ETA: 10s - loss: 0.3229 - acc: 0.89 - ETA: 10s - loss: 0.3229 - acc: 0.89 - ETA: 10s - loss: 0.3227 - acc: 0.89 - ETA: 10s - loss: 0.3226 - acc: 0.89 - ETA: 10s - loss: 0.3225 - acc: 0.89 - ETA: 10s - loss: 0.3226 - acc: 0.89 - ETA: 10s - loss: 0.3225 - acc: 0.89 - ETA: 10s - loss: 0.3226 - acc: 0.89 - ETA: 10s - loss: 0.3224 - acc: 0.89 - ETA: 10s - loss: 0.3224 - acc: 0.89 - ETA: 9s - loss: 0.3225 - acc: 0.8974 - ETA: 9s - loss: 0.3224 - acc: 0.897 - ETA: 9s - loss: 0.3225 - acc: 0.897 - ETA: 9s - loss: 0.3224 - acc: 0.897 - ETA: 9s - loss: 0.3223 - acc: 0.897 - ETA: 9s - loss: 0.3221 - acc: 0.897 - ETA: 9s - loss: 0.3217 - acc: 0.897 - ETA: 9s - loss: 0.3216 - acc: 0.897 - ETA: 9s - loss: 0.3216 - acc: 0.897 - ETA: 9s - loss: 0.3216 - acc: 0.897 - ETA: 9s - loss: 0.3214 - acc: 0.897 - ETA: 9s - loss: 0.3213 - acc: 0.897 - ETA: 9s - loss: 0.3215 - acc: 0.897 - ETA: 9s - loss: 0.3214 - acc: 0.897 - ETA: 8s - loss: 0.3213 - acc: 0.897 - ETA: 8s - loss: 0.3213 - acc: 0.897 - ETA: 8s - loss: 0.3214 - acc: 0.897 - ETA: 8s - loss: 0.3214 - acc: 0.897 - ETA: 8s - loss: 0.3214 - acc: 0.897 - ETA: 8s - loss: 0.3215 - acc: 0.897 - ETA: 8s - loss: 0.3216 - acc: 0.897 - ETA: 8s - loss: 0.3213 - acc: 0.897 - ETA: 8s - loss: 0.3215 - acc: 0.897 - ETA: 8s - loss: 0.3215 - acc: 0.897 - ETA: 8s - loss: 0.3215 - acc: 0.897 - ETA: 8s - loss: 0.3214 - acc: 0.897 - ETA: 8s - loss: 0.3215 - acc: 0.897 - ETA: 8s - loss: 0.3214 - acc: 0.897 - ETA: 8s - loss: 0.3215 - acc: 0.897 - ETA: 7s - loss: 0.3216 - acc: 0.897 - ETA: 7s - loss: 0.3215 - acc: 0.897 - ETA: 7s - loss: 0.3215 - acc: 0.897 - ETA: 7s - loss: 0.3217 - acc: 0.897 - ETA: 7s - loss: 0.3216 - acc: 0.897 - ETA: 7s - loss: 0.3216 - acc: 0.897 - ETA: 7s - loss: 0.3217 - acc: 0.897 - ETA: 7s - loss: 0.3216 - acc: 0.897 - ETA: 7s - loss: 0.3216 - acc: 0.897 - ETA: 7s - loss: 0.3218 - acc: 0.897 - ETA: 7s - loss: 0.3221 - acc: 0.897 - ETA: 7s - loss: 0.3220 - acc: 0.897 - ETA: 7s - loss: 0.3220 - acc: 0.897 - ETA: 7s - loss: 0.3221 - acc: 0.897 - ETA: 6s - loss: 0.3220 - acc: 0.897 - ETA: 6s - loss: 0.3218 - acc: 0.897 - ETA: 6s - loss: 0.3218 - acc: 0.897 - ETA: 6s - loss: 0.3219 - acc: 0.897 - ETA: 6s - loss: 0.3219 - acc: 0.897 - ETA: 6s - loss: 0.3220 - acc: 0.897 - ETA: 6s - loss: 0.3221 - acc: 0.897 - ETA: 6s - loss: 0.3221 - acc: 0.897 - ETA: 6s - loss: 0.3221 - acc: 0.897 - ETA: 6s - loss: 0.3222 - acc: 0.897 - ETA: 6s - loss: 0.3222 - acc: 0.897 - ETA: 6s - loss: 0.3221 - acc: 0.897 - ETA: 6s - loss: 0.3222 - acc: 0.897 - ETA: 6s - loss: 0.3221 - acc: 0.897 - ETA: 6s - loss: 0.3222 - acc: 0.897 - ETA: 5s - loss: 0.3222 - acc: 0.897 - ETA: 5s - loss: 0.3224 - acc: 0.897 - ETA: 5s - loss: 0.3225 - acc: 0.897 - ETA: 5s - loss: 0.3224 - acc: 0.897 - ETA: 5s - loss: 0.3224 - acc: 0.897 - ETA: 5s - loss: 0.3226 - acc: 0.897 - ETA: 5s - loss: 0.3227 - acc: 0.897 - ETA: 5s - loss: 0.3226 - acc: 0.897 - ETA: 5s - loss: 0.3224 - acc: 0.897 - ETA: 5s - loss: 0.3224 - acc: 0.897 - ETA: 5s - loss: 0.3225 - acc: 0.897 - ETA: 5s - loss: 0.3225 - acc: 0.897 - ETA: 5s - loss: 0.3223 - acc: 0.897 - ETA: 5s - loss: 0.3222 - acc: 0.897 - ETA: 5s - loss: 0.3221 - acc: 0.897 - ETA: 4s - loss: 0.3221 - acc: 0.897 - ETA: 4s - loss: 0.3220 - acc: 0.897 - ETA: 4s - loss: 0.3220 - acc: 0.897 - ETA: 4s - loss: 0.3219 - acc: 0.897 - ETA: 4s - loss: 0.3218 - acc: 0.897 - ETA: 4s - loss: 0.3217 - acc: 0.897 - ETA: 4s - loss: 0.3217 - acc: 0.897 - ETA: 4s - loss: 0.3217 - acc: 0.897 - ETA: 4s - loss: 0.3217 - acc: 0.897 - ETA: 4s - loss: 0.3215 - acc: 0.897 - ETA: 4s - loss: 0.3215 - acc: 0.897 - ETA: 4s - loss: 0.3215 - acc: 0.897 - ETA: 4s - loss: 0.3216 - acc: 0.897 - ETA: 4s - loss: 0.3215 - acc: 0.897 - ETA: 4s - loss: 0.3216 - acc: 0.897 - ETA: 3s - loss: 0.3215 - acc: 0.897 - ETA: 3s - loss: 0.3217 - acc: 0.897 - ETA: 3s - loss: 0.3219 - acc: 0.897 - ETA: 3s - loss: 0.3218 - acc: 0.897 - ETA: 3s - loss: 0.3220 - acc: 0.897 - ETA: 3s - loss: 0.3220 - acc: 0.8976"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269289/269289 [==============================] - ETA: 3s - loss: 0.3219 - acc: 0.897 - ETA: 3s - loss: 0.3221 - acc: 0.897 - ETA: 3s - loss: 0.3220 - acc: 0.897 - ETA: 3s - loss: 0.3218 - acc: 0.897 - ETA: 3s - loss: 0.3217 - acc: 0.897 - ETA: 3s - loss: 0.3217 - acc: 0.897 - ETA: 3s - loss: 0.3218 - acc: 0.897 - ETA: 3s - loss: 0.3216 - acc: 0.897 - ETA: 3s - loss: 0.3216 - acc: 0.897 - ETA: 2s - loss: 0.3217 - acc: 0.897 - ETA: 2s - loss: 0.3216 - acc: 0.897 - ETA: 2s - loss: 0.3217 - acc: 0.897 - ETA: 2s - loss: 0.3219 - acc: 0.897 - ETA: 2s - loss: 0.3219 - acc: 0.897 - ETA: 2s - loss: 0.3219 - acc: 0.897 - ETA: 2s - loss: 0.3219 - acc: 0.897 - ETA: 2s - loss: 0.3218 - acc: 0.897 - ETA: 2s - loss: 0.3217 - acc: 0.897 - ETA: 2s - loss: 0.3217 - acc: 0.897 - ETA: 2s - loss: 0.3217 - acc: 0.897 - ETA: 2s - loss: 0.3216 - acc: 0.897 - ETA: 2s - loss: 0.3216 - acc: 0.897 - ETA: 2s - loss: 0.3216 - acc: 0.897 - ETA: 2s - loss: 0.3216 - acc: 0.897 - ETA: 1s - loss: 0.3217 - acc: 0.897 - ETA: 1s - loss: 0.3217 - acc: 0.897 - ETA: 1s - loss: 0.3216 - acc: 0.897 - ETA: 1s - loss: 0.3215 - acc: 0.897 - ETA: 1s - loss: 0.3216 - acc: 0.897 - ETA: 1s - loss: 0.3216 - acc: 0.897 - ETA: 1s - loss: 0.3217 - acc: 0.897 - ETA: 1s - loss: 0.3217 - acc: 0.897 - ETA: 1s - loss: 0.3216 - acc: 0.897 - ETA: 1s - loss: 0.3215 - acc: 0.897 - ETA: 1s - loss: 0.3213 - acc: 0.897 - ETA: 1s - loss: 0.3214 - acc: 0.897 - ETA: 1s - loss: 0.3215 - acc: 0.897 - ETA: 1s - loss: 0.3215 - acc: 0.897 - ETA: 1s - loss: 0.3215 - acc: 0.897 - ETA: 0s - loss: 0.3216 - acc: 0.897 - ETA: 0s - loss: 0.3215 - acc: 0.897 - ETA: 0s - loss: 0.3217 - acc: 0.897 - ETA: 0s - loss: 0.3218 - acc: 0.897 - ETA: 0s - loss: 0.3218 - acc: 0.897 - ETA: 0s - loss: 0.3218 - acc: 0.897 - ETA: 0s - loss: 0.3218 - acc: 0.897 - ETA: 0s - loss: 0.3219 - acc: 0.897 - ETA: 0s - loss: 0.3219 - acc: 0.897 - ETA: 0s - loss: 0.3220 - acc: 0.897 - ETA: 0s - loss: 0.3221 - acc: 0.897 - ETA: 0s - loss: 0.3222 - acc: 0.897 - ETA: 0s - loss: 0.3221 - acc: 0.897 - ETA: 0s - loss: 0.3220 - acc: 0.897 - ETA: 0s - loss: 0.3219 - acc: 0.897 - 18s 67us/step - loss: 0.3219 - acc: 0.8976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203247ebb38>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data1, y_train[1], batch_size=1000, epochs=3, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(X_test['0'].astype(str))\n",
    "test_sequences_matrix = pad_sequences(test_sequences,maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_sequences_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.51      0.66     80456\n",
      "           1       0.14      0.67      0.23      9307\n",
      "\n",
      "   micro avg       0.52      0.52      0.52     89763\n",
      "   macro avg       0.53      0.59      0.44     89763\n",
      "weighted avg       0.85      0.52      0.61     89763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tst = []\n",
    "for i in y_pred:\n",
    "    if i >= 0.14:\n",
    "        tst.append(1)\n",
    "    else:\n",
    "        tst.append(0)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test[1], tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89763/89763 [==============================] - ETA: 7: - ETA: 46s - ETA: 29 - ETA: 17 - ETA: 13 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 6s 62us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_sequences_matrix, y_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.63158539710125 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", results[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "for i in range(len(tst)):\n",
    "    if tst[i] == y_test[1][i]:\n",
    "        a = a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.45943656949274"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a/89736)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(tst)\n",
    "y_pred.to_csv(r\"E:\\Yelp\\YelpNYC\\res_nn.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\res_lda.csv\", header=None)\n",
    "res2 = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\res_nn.csv\", header=None)\n",
    "res3 = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\res_features.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89763, 2) (89763, 2) (89763, 2)\n"
     ]
    }
   ],
   "source": [
    "print(res1.shape, res2.shape, res3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = pd.read_csv(r\"E:\\Yelp\\YelpNYC\\y_test\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape\n",
    "X = pd.DataFrame({'a':res1[1], 'b':res2[1], 'c':res3[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89763, 3)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 16\n",
      "Trainable params: 16\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(3, activation='sigmoid', input_dim=3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_test[1], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60141/60141 [==============================] - ETA: 11:34 - loss: 0.5161 - acc: 0.93 - ETA: 14s - loss: 0.5133 - acc: 0.8976 - ETA: 8s - loss: 0.4953 - acc: 0.8950 - ETA: 5s - loss: 0.4781 - acc: 0.894 - ETA: 4s - loss: 0.4660 - acc: 0.890 - ETA: 4s - loss: 0.4549 - acc: 0.891 - ETA: 3s - loss: 0.4479 - acc: 0.890 - ETA: 3s - loss: 0.4372 - acc: 0.891 - ETA: 3s - loss: 0.4296 - acc: 0.891 - ETA: 2s - loss: 0.4211 - acc: 0.892 - ETA: 2s - loss: 0.4158 - acc: 0.891 - ETA: 2s - loss: 0.4107 - acc: 0.892 - ETA: 2s - loss: 0.4057 - acc: 0.892 - ETA: 2s - loss: 0.4024 - acc: 0.892 - ETA: 2s - loss: 0.3978 - acc: 0.893 - ETA: 2s - loss: 0.3958 - acc: 0.893 - ETA: 2s - loss: 0.3933 - acc: 0.892 - ETA: 1s - loss: 0.3897 - acc: 0.893 - ETA: 1s - loss: 0.3872 - acc: 0.893 - ETA: 1s - loss: 0.3817 - acc: 0.895 - ETA: 1s - loss: 0.3784 - acc: 0.895 - ETA: 1s - loss: 0.3773 - acc: 0.895 - ETA: 1s - loss: 0.3734 - acc: 0.896 - ETA: 1s - loss: 0.3707 - acc: 0.896 - ETA: 1s - loss: 0.3689 - acc: 0.896 - ETA: 1s - loss: 0.3681 - acc: 0.896 - ETA: 1s - loss: 0.3668 - acc: 0.896 - ETA: 1s - loss: 0.3646 - acc: 0.896 - ETA: 1s - loss: 0.3626 - acc: 0.897 - ETA: 0s - loss: 0.3606 - acc: 0.897 - ETA: 0s - loss: 0.3598 - acc: 0.897 - ETA: 0s - loss: 0.3591 - acc: 0.897 - ETA: 0s - loss: 0.3591 - acc: 0.896 - ETA: 0s - loss: 0.3584 - acc: 0.896 - ETA: 0s - loss: 0.3580 - acc: 0.896 - ETA: 0s - loss: 0.3571 - acc: 0.896 - ETA: 0s - loss: 0.3559 - acc: 0.897 - ETA: 0s - loss: 0.3547 - acc: 0.897 - ETA: 0s - loss: 0.3538 - acc: 0.897 - ETA: 0s - loss: 0.3531 - acc: 0.897 - ETA: 0s - loss: 0.3525 - acc: 0.897 - ETA: 0s - loss: 0.3524 - acc: 0.897 - ETA: 0s - loss: 0.3525 - acc: 0.896 - ETA: 0s - loss: 0.3522 - acc: 0.896 - 3s 43us/step - loss: 0.3521 - acc: 0.8966\n",
      "Epoch 2/10\n",
      "60141/60141 [==============================] - ETA: 9s - loss: 0.4486 - acc: 0.843 - ETA: 2s - loss: 0.3302 - acc: 0.897 - ETA: 2s - loss: 0.3229 - acc: 0.900 - ETA: 2s - loss: 0.3250 - acc: 0.899 - ETA: 2s - loss: 0.3268 - acc: 0.898 - ETA: 1s - loss: 0.3296 - acc: 0.897 - ETA: 1s - loss: 0.3299 - acc: 0.897 - ETA: 1s - loss: 0.3305 - acc: 0.896 - ETA: 1s - loss: 0.3314 - acc: 0.896 - ETA: 1s - loss: 0.3290 - acc: 0.897 - ETA: 1s - loss: 0.3284 - acc: 0.897 - ETA: 1s - loss: 0.3296 - acc: 0.897 - ETA: 1s - loss: 0.3289 - acc: 0.897 - ETA: 1s - loss: 0.3313 - acc: 0.896 - ETA: 1s - loss: 0.3314 - acc: 0.896 - ETA: 1s - loss: 0.3322 - acc: 0.895 - ETA: 1s - loss: 0.3322 - acc: 0.895 - ETA: 1s - loss: 0.3324 - acc: 0.895 - ETA: 1s - loss: 0.3328 - acc: 0.895 - ETA: 1s - loss: 0.3321 - acc: 0.895 - ETA: 1s - loss: 0.3311 - acc: 0.896 - ETA: 1s - loss: 0.3318 - acc: 0.895 - ETA: 1s - loss: 0.3313 - acc: 0.895 - ETA: 1s - loss: 0.3312 - acc: 0.895 - ETA: 0s - loss: 0.3298 - acc: 0.896 - ETA: 0s - loss: 0.3313 - acc: 0.895 - ETA: 0s - loss: 0.3312 - acc: 0.895 - ETA: 0s - loss: 0.3319 - acc: 0.895 - ETA: 0s - loss: 0.3312 - acc: 0.895 - ETA: 0s - loss: 0.3306 - acc: 0.896 - ETA: 0s - loss: 0.3304 - acc: 0.896 - ETA: 0s - loss: 0.3293 - acc: 0.896 - ETA: 0s - loss: 0.3298 - acc: 0.896 - ETA: 0s - loss: 0.3290 - acc: 0.896 - ETA: 0s - loss: 0.3287 - acc: 0.896 - ETA: 0s - loss: 0.3291 - acc: 0.896 - ETA: 0s - loss: 0.3290 - acc: 0.896 - ETA: 0s - loss: 0.3293 - acc: 0.896 - ETA: 0s - loss: 0.3299 - acc: 0.896 - ETA: 0s - loss: 0.3293 - acc: 0.896 - ETA: 0s - loss: 0.3299 - acc: 0.896 - ETA: 0s - loss: 0.3295 - acc: 0.896 - ETA: 0s - loss: 0.3290 - acc: 0.896 - ETA: 0s - loss: 0.3292 - acc: 0.896 - 2s 37us/step - loss: 0.3291 - acc: 0.8966\n",
      "Epoch 3/10\n",
      "60141/60141 [==============================] - ETA: 9s - loss: 0.3974 - acc: 0.875 - ETA: 2s - loss: 0.3321 - acc: 0.894 - ETA: 2s - loss: 0.3318 - acc: 0.894 - ETA: 2s - loss: 0.3257 - acc: 0.897 - ETA: 2s - loss: 0.3221 - acc: 0.899 - ETA: 2s - loss: 0.3227 - acc: 0.899 - ETA: 2s - loss: 0.3205 - acc: 0.900 - ETA: 1s - loss: 0.3219 - acc: 0.899 - ETA: 1s - loss: 0.3228 - acc: 0.898 - ETA: 1s - loss: 0.3242 - acc: 0.898 - ETA: 1s - loss: 0.3235 - acc: 0.898 - ETA: 1s - loss: 0.3242 - acc: 0.898 - ETA: 1s - loss: 0.3261 - acc: 0.897 - ETA: 1s - loss: 0.3265 - acc: 0.897 - ETA: 1s - loss: 0.3285 - acc: 0.896 - ETA: 1s - loss: 0.3289 - acc: 0.896 - ETA: 1s - loss: 0.3295 - acc: 0.895 - ETA: 1s - loss: 0.3302 - acc: 0.895 - ETA: 1s - loss: 0.3284 - acc: 0.896 - ETA: 1s - loss: 0.3290 - acc: 0.896 - ETA: 1s - loss: 0.3285 - acc: 0.896 - ETA: 1s - loss: 0.3290 - acc: 0.896 - ETA: 1s - loss: 0.3288 - acc: 0.896 - ETA: 1s - loss: 0.3288 - acc: 0.896 - ETA: 1s - loss: 0.3295 - acc: 0.895 - ETA: 1s - loss: 0.3291 - acc: 0.896 - ETA: 0s - loss: 0.3285 - acc: 0.896 - ETA: 0s - loss: 0.3289 - acc: 0.896 - ETA: 0s - loss: 0.3287 - acc: 0.896 - ETA: 0s - loss: 0.3290 - acc: 0.896 - ETA: 0s - loss: 0.3281 - acc: 0.896 - ETA: 0s - loss: 0.3279 - acc: 0.896 - ETA: 0s - loss: 0.3279 - acc: 0.896 - ETA: 0s - loss: 0.3273 - acc: 0.896 - ETA: 0s - loss: 0.3271 - acc: 0.896 - ETA: 0s - loss: 0.3271 - acc: 0.896 - ETA: 0s - loss: 0.3269 - acc: 0.896 - ETA: 0s - loss: 0.3269 - acc: 0.896 - ETA: 0s - loss: 0.3274 - acc: 0.896 - ETA: 0s - loss: 0.3273 - acc: 0.896 - ETA: 0s - loss: 0.3276 - acc: 0.896 - ETA: 0s - loss: 0.3270 - acc: 0.896 - ETA: 0s - loss: 0.3271 - acc: 0.896 - ETA: 0s - loss: 0.3273 - acc: 0.896 - ETA: 0s - loss: 0.3272 - acc: 0.896 - 2s 38us/step - loss: 0.3273 - acc: 0.8966\n",
      "Epoch 4/10\n",
      "60141/60141 [==============================] - ETA: 7s - loss: 0.3227 - acc: 0.906 - ETA: 2s - loss: 0.3003 - acc: 0.908 - ETA: 2s - loss: 0.3157 - acc: 0.900 - ETA: 2s - loss: 0.3136 - acc: 0.902 - ETA: 2s - loss: 0.3222 - acc: 0.898 - ETA: 2s - loss: 0.3238 - acc: 0.897 - ETA: 1s - loss: 0.3248 - acc: 0.896 - ETA: 1s - loss: 0.3231 - acc: 0.897 - ETA: 1s - loss: 0.3261 - acc: 0.896 - ETA: 1s - loss: 0.3225 - acc: 0.898 - ETA: 1s - loss: 0.3239 - acc: 0.897 - ETA: 1s - loss: 0.3264 - acc: 0.896 - ETA: 1s - loss: 0.3256 - acc: 0.897 - ETA: 1s - loss: 0.3274 - acc: 0.896 - ETA: 1s - loss: 0.3263 - acc: 0.896 - ETA: 1s - loss: 0.3267 - acc: 0.896 - ETA: 1s - loss: 0.3279 - acc: 0.896 - ETA: 1s - loss: 0.3296 - acc: 0.895 - ETA: 1s - loss: 0.3285 - acc: 0.895 - ETA: 1s - loss: 0.3271 - acc: 0.896 - ETA: 1s - loss: 0.3276 - acc: 0.896 - ETA: 1s - loss: 0.3282 - acc: 0.896 - ETA: 1s - loss: 0.3276 - acc: 0.896 - ETA: 1s - loss: 0.3285 - acc: 0.895 - ETA: 1s - loss: 0.3276 - acc: 0.896 - ETA: 0s - loss: 0.3272 - acc: 0.896 - ETA: 0s - loss: 0.3267 - acc: 0.896 - ETA: 0s - loss: 0.3267 - acc: 0.896 - ETA: 0s - loss: 0.3266 - acc: 0.896 - ETA: 0s - loss: 0.3266 - acc: 0.896 - ETA: 0s - loss: 0.3274 - acc: 0.896 - ETA: 0s - loss: 0.3276 - acc: 0.896 - ETA: 0s - loss: 0.3280 - acc: 0.896 - ETA: 0s - loss: 0.3274 - acc: 0.896 - ETA: 0s - loss: 0.3266 - acc: 0.896 - ETA: 0s - loss: 0.3264 - acc: 0.896 - ETA: 0s - loss: 0.3261 - acc: 0.897 - ETA: 0s - loss: 0.3260 - acc: 0.897 - ETA: 0s - loss: 0.3256 - acc: 0.897 - ETA: 0s - loss: 0.3258 - acc: 0.897 - ETA: 0s - loss: 0.3265 - acc: 0.896 - ETA: 0s - loss: 0.3263 - acc: 0.896 - ETA: 0s - loss: 0.3266 - acc: 0.896 - ETA: 0s - loss: 0.3264 - acc: 0.896 - ETA: 0s - loss: 0.3269 - acc: 0.896 - 2s 38us/step - loss: 0.3268 - acc: 0.8966\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60141/60141 [==============================] - ETA: 9s - loss: 0.4997 - acc: 0.812 - ETA: 2s - loss: 0.3442 - acc: 0.888 - ETA: 2s - loss: 0.3481 - acc: 0.885 - ETA: 2s - loss: 0.3403 - acc: 0.889 - ETA: 2s - loss: 0.3356 - acc: 0.892 - ETA: 2s - loss: 0.3290 - acc: 0.895 - ETA: 2s - loss: 0.3306 - acc: 0.894 - ETA: 2s - loss: 0.3322 - acc: 0.893 - ETA: 2s - loss: 0.3290 - acc: 0.895 - ETA: 1s - loss: 0.3296 - acc: 0.895 - ETA: 1s - loss: 0.3299 - acc: 0.895 - ETA: 1s - loss: 0.3289 - acc: 0.895 - ETA: 1s - loss: 0.3298 - acc: 0.895 - ETA: 1s - loss: 0.3311 - acc: 0.894 - ETA: 1s - loss: 0.3308 - acc: 0.894 - ETA: 1s - loss: 0.3325 - acc: 0.893 - ETA: 1s - loss: 0.3313 - acc: 0.894 - ETA: 1s - loss: 0.3308 - acc: 0.894 - ETA: 1s - loss: 0.3309 - acc: 0.894 - ETA: 1s - loss: 0.3314 - acc: 0.894 - ETA: 1s - loss: 0.3315 - acc: 0.894 - ETA: 1s - loss: 0.3305 - acc: 0.894 - ETA: 1s - loss: 0.3303 - acc: 0.894 - ETA: 1s - loss: 0.3303 - acc: 0.894 - ETA: 1s - loss: 0.3328 - acc: 0.893 - ETA: 1s - loss: 0.3325 - acc: 0.893 - ETA: 1s - loss: 0.3322 - acc: 0.894 - ETA: 0s - loss: 0.3310 - acc: 0.894 - ETA: 0s - loss: 0.3311 - acc: 0.894 - ETA: 0s - loss: 0.3306 - acc: 0.894 - ETA: 0s - loss: 0.3304 - acc: 0.895 - ETA: 0s - loss: 0.3295 - acc: 0.895 - ETA: 0s - loss: 0.3292 - acc: 0.895 - ETA: 0s - loss: 0.3288 - acc: 0.895 - ETA: 0s - loss: 0.3285 - acc: 0.895 - ETA: 0s - loss: 0.3284 - acc: 0.895 - ETA: 0s - loss: 0.3282 - acc: 0.895 - ETA: 0s - loss: 0.3284 - acc: 0.895 - ETA: 0s - loss: 0.3286 - acc: 0.895 - ETA: 0s - loss: 0.3287 - acc: 0.895 - ETA: 0s - loss: 0.3281 - acc: 0.896 - ETA: 0s - loss: 0.3275 - acc: 0.896 - ETA: 0s - loss: 0.3271 - acc: 0.896 - ETA: 0s - loss: 0.3268 - acc: 0.896 - ETA: 0s - loss: 0.3270 - acc: 0.896 - 2s 38us/step - loss: 0.3266 - acc: 0.8966\n",
      "Epoch 6/10\n",
      "60141/60141 [==============================] - ETA: 9s - loss: 0.2263 - acc: 0.937 - ETA: 2s - loss: 0.3117 - acc: 0.902 - ETA: 2s - loss: 0.3187 - acc: 0.898 - ETA: 2s - loss: 0.3136 - acc: 0.901 - ETA: 2s - loss: 0.3167 - acc: 0.900 - ETA: 2s - loss: 0.3164 - acc: 0.900 - ETA: 2s - loss: 0.3275 - acc: 0.895 - ETA: 2s - loss: 0.3264 - acc: 0.895 - ETA: 1s - loss: 0.3277 - acc: 0.895 - ETA: 1s - loss: 0.3276 - acc: 0.895 - ETA: 1s - loss: 0.3262 - acc: 0.896 - ETA: 1s - loss: 0.3223 - acc: 0.898 - ETA: 1s - loss: 0.3232 - acc: 0.897 - ETA: 1s - loss: 0.3228 - acc: 0.897 - ETA: 1s - loss: 0.3218 - acc: 0.898 - ETA: 1s - loss: 0.3222 - acc: 0.898 - ETA: 1s - loss: 0.3208 - acc: 0.898 - ETA: 1s - loss: 0.3212 - acc: 0.898 - ETA: 1s - loss: 0.3211 - acc: 0.898 - ETA: 1s - loss: 0.3217 - acc: 0.898 - ETA: 1s - loss: 0.3237 - acc: 0.897 - ETA: 1s - loss: 0.3240 - acc: 0.897 - ETA: 1s - loss: 0.3239 - acc: 0.897 - ETA: 1s - loss: 0.3239 - acc: 0.897 - ETA: 1s - loss: 0.3232 - acc: 0.898 - ETA: 1s - loss: 0.3238 - acc: 0.897 - ETA: 0s - loss: 0.3237 - acc: 0.897 - ETA: 0s - loss: 0.3248 - acc: 0.897 - ETA: 0s - loss: 0.3249 - acc: 0.897 - ETA: 0s - loss: 0.3263 - acc: 0.896 - ETA: 0s - loss: 0.3268 - acc: 0.896 - ETA: 0s - loss: 0.3269 - acc: 0.896 - ETA: 0s - loss: 0.3279 - acc: 0.895 - ETA: 0s - loss: 0.3284 - acc: 0.895 - ETA: 0s - loss: 0.3287 - acc: 0.895 - ETA: 0s - loss: 0.3280 - acc: 0.895 - ETA: 0s - loss: 0.3274 - acc: 0.896 - ETA: 0s - loss: 0.3271 - acc: 0.896 - ETA: 0s - loss: 0.3270 - acc: 0.896 - ETA: 0s - loss: 0.3273 - acc: 0.896 - ETA: 0s - loss: 0.3271 - acc: 0.896 - ETA: 0s - loss: 0.3270 - acc: 0.896 - ETA: 0s - loss: 0.3266 - acc: 0.896 - ETA: 0s - loss: 0.3265 - acc: 0.896 - ETA: 0s - loss: 0.3270 - acc: 0.896 - ETA: 0s - loss: 0.3268 - acc: 0.896 - 2s 39us/step - loss: 0.3266 - acc: 0.8966\n",
      "Epoch 7/10\n",
      "60141/60141 [==============================] - ETA: 7s - loss: 0.2353 - acc: 0.937 - ETA: 2s - loss: 0.2828 - acc: 0.917 - ETA: 2s - loss: 0.3177 - acc: 0.901 - ETA: 2s - loss: 0.3119 - acc: 0.904 - ETA: 2s - loss: 0.3096 - acc: 0.904 - ETA: 2s - loss: 0.3111 - acc: 0.903 - ETA: 2s - loss: 0.3154 - acc: 0.902 - ETA: 2s - loss: 0.3124 - acc: 0.903 - ETA: 2s - loss: 0.3159 - acc: 0.901 - ETA: 1s - loss: 0.3198 - acc: 0.899 - ETA: 1s - loss: 0.3232 - acc: 0.897 - ETA: 1s - loss: 0.3230 - acc: 0.897 - ETA: 1s - loss: 0.3231 - acc: 0.897 - ETA: 1s - loss: 0.3222 - acc: 0.898 - ETA: 1s - loss: 0.3235 - acc: 0.897 - ETA: 1s - loss: 0.3228 - acc: 0.898 - ETA: 1s - loss: 0.3223 - acc: 0.898 - ETA: 1s - loss: 0.3220 - acc: 0.898 - ETA: 1s - loss: 0.3220 - acc: 0.898 - ETA: 1s - loss: 0.3228 - acc: 0.898 - ETA: 1s - loss: 0.3229 - acc: 0.898 - ETA: 1s - loss: 0.3227 - acc: 0.898 - ETA: 1s - loss: 0.3238 - acc: 0.897 - ETA: 1s - loss: 0.3243 - acc: 0.897 - ETA: 1s - loss: 0.3257 - acc: 0.896 - ETA: 1s - loss: 0.3262 - acc: 0.896 - ETA: 0s - loss: 0.3265 - acc: 0.896 - ETA: 0s - loss: 0.3265 - acc: 0.896 - ETA: 0s - loss: 0.3269 - acc: 0.896 - ETA: 0s - loss: 0.3263 - acc: 0.896 - ETA: 0s - loss: 0.3254 - acc: 0.897 - ETA: 0s - loss: 0.3262 - acc: 0.896 - ETA: 0s - loss: 0.3262 - acc: 0.896 - ETA: 0s - loss: 0.3263 - acc: 0.896 - ETA: 0s - loss: 0.3266 - acc: 0.896 - ETA: 0s - loss: 0.3264 - acc: 0.896 - ETA: 0s - loss: 0.3271 - acc: 0.896 - ETA: 0s - loss: 0.3279 - acc: 0.895 - ETA: 0s - loss: 0.3278 - acc: 0.895 - ETA: 0s - loss: 0.3275 - acc: 0.896 - ETA: 0s - loss: 0.3271 - acc: 0.896 - ETA: 0s - loss: 0.3268 - acc: 0.896 - ETA: 0s - loss: 0.3267 - acc: 0.896 - ETA: 0s - loss: 0.3266 - acc: 0.896 - ETA: 0s - loss: 0.3267 - acc: 0.896 - ETA: 0s - loss: 0.3272 - acc: 0.896 - 2s 39us/step - loss: 0.3266 - acc: 0.8966\n",
      "Epoch 8/10\n",
      "60141/60141 [==============================] - ETA: 5s - loss: 0.1638 - acc: 0.968 - ETA: 2s - loss: 0.3320 - acc: 0.893 - ETA: 2s - loss: 0.3266 - acc: 0.896 - ETA: 2s - loss: 0.3243 - acc: 0.897 - ETA: 2s - loss: 0.3253 - acc: 0.897 - ETA: 2s - loss: 0.3269 - acc: 0.897 - ETA: 2s - loss: 0.3286 - acc: 0.896 - ETA: 1s - loss: 0.3281 - acc: 0.896 - ETA: 1s - loss: 0.3292 - acc: 0.896 - ETA: 1s - loss: 0.3331 - acc: 0.894 - ETA: 1s - loss: 0.3332 - acc: 0.893 - ETA: 1s - loss: 0.3343 - acc: 0.893 - ETA: 1s - loss: 0.3338 - acc: 0.893 - ETA: 1s - loss: 0.3321 - acc: 0.894 - ETA: 1s - loss: 0.3295 - acc: 0.895 - ETA: 1s - loss: 0.3308 - acc: 0.895 - ETA: 1s - loss: 0.3310 - acc: 0.894 - ETA: 1s - loss: 0.3301 - acc: 0.895 - ETA: 1s - loss: 0.3300 - acc: 0.895 - ETA: 1s - loss: 0.3304 - acc: 0.895 - ETA: 1s - loss: 0.3304 - acc: 0.895 - ETA: 1s - loss: 0.3298 - acc: 0.895 - ETA: 1s - loss: 0.3289 - acc: 0.895 - ETA: 1s - loss: 0.3291 - acc: 0.895 - ETA: 1s - loss: 0.3286 - acc: 0.895 - ETA: 1s - loss: 0.3291 - acc: 0.895 - ETA: 1s - loss: 0.3293 - acc: 0.895 - ETA: 0s - loss: 0.3301 - acc: 0.895 - ETA: 0s - loss: 0.3299 - acc: 0.895 - ETA: 0s - loss: 0.3296 - acc: 0.895 - ETA: 0s - loss: 0.3293 - acc: 0.895 - ETA: 0s - loss: 0.3286 - acc: 0.895 - ETA: 0s - loss: 0.3294 - acc: 0.895 - ETA: 0s - loss: 0.3296 - acc: 0.895 - ETA: 0s - loss: 0.3293 - acc: 0.895 - ETA: 0s - loss: 0.3281 - acc: 0.896 - ETA: 0s - loss: 0.3277 - acc: 0.896 - ETA: 0s - loss: 0.3276 - acc: 0.896 - ETA: 0s - loss: 0.3274 - acc: 0.896 - ETA: 0s - loss: 0.3275 - acc: 0.896 - ETA: 0s - loss: 0.3273 - acc: 0.896 - ETA: 0s - loss: 0.3277 - acc: 0.896 - ETA: 0s - loss: 0.3277 - acc: 0.896 - ETA: 0s - loss: 0.3278 - acc: 0.896 - ETA: 0s - loss: 0.3270 - acc: 0.896 - ETA: 0s - loss: 0.3264 - acc: 0.896 - ETA: 0s - loss: 0.3267 - acc: 0.896 - 2s 40us/step - loss: 0.3266 - acc: 0.8966\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60141/60141 [==============================] - ETA: 13s - loss: 0.4223 - acc: 0.84 - ETA: 2s - loss: 0.3240 - acc: 0.8986 - ETA: 2s - loss: 0.3251 - acc: 0.897 - ETA: 2s - loss: 0.3281 - acc: 0.895 - ETA: 2s - loss: 0.3241 - acc: 0.897 - ETA: 2s - loss: 0.3222 - acc: 0.897 - ETA: 1s - loss: 0.3236 - acc: 0.897 - ETA: 1s - loss: 0.3210 - acc: 0.898 - ETA: 1s - loss: 0.3215 - acc: 0.898 - ETA: 1s - loss: 0.3210 - acc: 0.898 - ETA: 1s - loss: 0.3197 - acc: 0.899 - ETA: 1s - loss: 0.3209 - acc: 0.898 - ETA: 1s - loss: 0.3219 - acc: 0.898 - ETA: 1s - loss: 0.3241 - acc: 0.897 - ETA: 1s - loss: 0.3247 - acc: 0.897 - ETA: 1s - loss: 0.3237 - acc: 0.897 - ETA: 1s - loss: 0.3244 - acc: 0.897 - ETA: 1s - loss: 0.3257 - acc: 0.896 - ETA: 1s - loss: 0.3255 - acc: 0.897 - ETA: 1s - loss: 0.3249 - acc: 0.897 - ETA: 1s - loss: 0.3252 - acc: 0.897 - ETA: 1s - loss: 0.3249 - acc: 0.897 - ETA: 1s - loss: 0.3257 - acc: 0.897 - ETA: 1s - loss: 0.3253 - acc: 0.897 - ETA: 1s - loss: 0.3259 - acc: 0.897 - ETA: 1s - loss: 0.3270 - acc: 0.896 - ETA: 0s - loss: 0.3268 - acc: 0.896 - ETA: 0s - loss: 0.3274 - acc: 0.896 - ETA: 0s - loss: 0.3278 - acc: 0.896 - ETA: 0s - loss: 0.3270 - acc: 0.896 - ETA: 0s - loss: 0.3263 - acc: 0.896 - ETA: 0s - loss: 0.3269 - acc: 0.896 - ETA: 0s - loss: 0.3270 - acc: 0.896 - ETA: 0s - loss: 0.3274 - acc: 0.896 - ETA: 0s - loss: 0.3282 - acc: 0.895 - ETA: 0s - loss: 0.3271 - acc: 0.896 - ETA: 0s - loss: 0.3279 - acc: 0.896 - ETA: 0s - loss: 0.3285 - acc: 0.895 - ETA: 0s - loss: 0.3279 - acc: 0.896 - ETA: 0s - loss: 0.3282 - acc: 0.895 - ETA: 0s - loss: 0.3283 - acc: 0.895 - ETA: 0s - loss: 0.3281 - acc: 0.896 - ETA: 0s - loss: 0.3279 - acc: 0.896 - ETA: 0s - loss: 0.3271 - acc: 0.896 - 2s 37us/step - loss: 0.3266 - acc: 0.8966\n",
      "Epoch 10/10\n",
      "60141/60141 [==============================] - ETA: 9s - loss: 0.2389 - acc: 0.937 - ETA: 1s - loss: 0.3479 - acc: 0.885 - ETA: 1s - loss: 0.3446 - acc: 0.888 - ETA: 1s - loss: 0.3260 - acc: 0.897 - ETA: 1s - loss: 0.3223 - acc: 0.899 - ETA: 1s - loss: 0.3224 - acc: 0.899 - ETA: 1s - loss: 0.3207 - acc: 0.899 - ETA: 1s - loss: 0.3241 - acc: 0.898 - ETA: 1s - loss: 0.3273 - acc: 0.897 - ETA: 1s - loss: 0.3251 - acc: 0.897 - ETA: 1s - loss: 0.3239 - acc: 0.898 - ETA: 1s - loss: 0.3247 - acc: 0.897 - ETA: 1s - loss: 0.3243 - acc: 0.897 - ETA: 1s - loss: 0.3236 - acc: 0.898 - ETA: 1s - loss: 0.3248 - acc: 0.897 - ETA: 1s - loss: 0.3238 - acc: 0.898 - ETA: 1s - loss: 0.3235 - acc: 0.898 - ETA: 1s - loss: 0.3239 - acc: 0.898 - ETA: 1s - loss: 0.3246 - acc: 0.897 - ETA: 1s - loss: 0.3245 - acc: 0.897 - ETA: 1s - loss: 0.3244 - acc: 0.897 - ETA: 1s - loss: 0.3250 - acc: 0.897 - ETA: 1s - loss: 0.3245 - acc: 0.897 - ETA: 1s - loss: 0.3241 - acc: 0.897 - ETA: 1s - loss: 0.3250 - acc: 0.897 - ETA: 1s - loss: 0.3251 - acc: 0.897 - ETA: 1s - loss: 0.3248 - acc: 0.897 - ETA: 0s - loss: 0.3249 - acc: 0.897 - ETA: 0s - loss: 0.3241 - acc: 0.897 - ETA: 0s - loss: 0.3235 - acc: 0.898 - ETA: 0s - loss: 0.3252 - acc: 0.897 - ETA: 0s - loss: 0.3249 - acc: 0.897 - ETA: 0s - loss: 0.3260 - acc: 0.897 - ETA: 0s - loss: 0.3261 - acc: 0.896 - ETA: 0s - loss: 0.3270 - acc: 0.896 - ETA: 0s - loss: 0.3270 - acc: 0.896 - ETA: 0s - loss: 0.3265 - acc: 0.896 - ETA: 0s - loss: 0.3269 - acc: 0.896 - ETA: 0s - loss: 0.3271 - acc: 0.896 - ETA: 0s - loss: 0.3267 - acc: 0.896 - ETA: 0s - loss: 0.3258 - acc: 0.897 - ETA: 0s - loss: 0.3258 - acc: 0.897 - ETA: 0s - loss: 0.3262 - acc: 0.896 - ETA: 0s - loss: 0.3263 - acc: 0.896 - ETA: 0s - loss: 0.3263 - acc: 0.896 - 2s 38us/step - loss: 0.3266 - acc: 0.8966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2032e858ef0>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29622/29622 [==============================] - ETA: 1: - ETA: 0s - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 1s 18us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.56856390480316 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",scores[1]*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.51      0.66     26532\n",
      "           1       0.14      0.67      0.23      3090\n",
      "\n",
      "   micro avg       0.53      0.53      0.53     29622\n",
      "   macro avg       0.53      0.59      0.44     29622\n",
      "weighted avg       0.85      0.53      0.61     29622\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "tst = []\n",
    "for i in y_pred:\n",
    "    if i >= 0.10:\n",
    "        tst.append(1)\n",
    "    else:\n",
    "        tst.append(0)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, tst))\n",
    "\n",
    "a = 0\n",
    "for i in range(len(tst)):\n",
    "    if tst[i] == y_test.tolist()[i]:\n",
    "        a = a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
