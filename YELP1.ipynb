{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "import gmplot\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "#To flatten the JSON data in checkin\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin = pd.read_csv(\"E://Yelp//refined_DATA//checkin_old.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin.drop(columns='Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin1 = pd.read_json(\"E:\\\\Yelp\\\\yelp_academic_dataset_checkin.json\", lines = True)\n",
    "checkin1\n",
    "checkin1 = pd.DataFrame.from_dict(json_normalize(checkin1.time), orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = checkin1.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we have to plot checkin['business_id'] vs sum\n",
    "\n",
    "sum1 = sum.sort_values(ascending=False)\n",
    "\n",
    "plt.scatter(range(157075), sum1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1.value_counts\n",
    "plt.scatter(range(157075), sum1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1 = sum\n",
    "\n",
    "count0 = 0\n",
    "for i in sum1:\n",
    "    if i == 0:\n",
    "        count0 += 1\n",
    "print(\"Number of restaurants with 0 checkins:\",count0)\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in sum1:\n",
    "    if i == 1:\n",
    "        count += 1\n",
    "print(\"Number of restaurants with 1 checkin: \",count)\n",
    "\n",
    "count1 = 0\n",
    "for i in sum1:\n",
    "    if i > 100:\n",
    "        count1 += 1\n",
    "print(\"Number of restaurants with more than 100 checkins:\",count1)\n",
    "\n",
    "count2 = 0\n",
    "for i in sum1:\n",
    "    if i > 500:\n",
    "        count2 += 1\n",
    "print(\"Number of restaurants with more than 500 checkins:\",count2)\n",
    "\n",
    "count3 = 0\n",
    "for i in sum1:\n",
    "    if i > 1000:\n",
    "        count3 += 1\n",
    "print(\"Number of restaurants with over 1000 checkins:\",count3)\n",
    "\n",
    "\n",
    "print(\"Mean of number of checkins of all restaurants:\",sum1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the Tip Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_data = pd.read_csv(\"E:\\\\Yelp\\\\DATA\\\\tip.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_data.columns\n",
    "#tip_data.drop(\"Unnamed: 0\", inplace = True, axis=1)\n",
    "print(tip_data.head())\n",
    "print(tip_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_data['word_count'] = tip_data['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "tip_data.head()\n",
    "#We add word count for the text attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_data.sort_values('word_count', inplace=True)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,1,1)\n",
    "plt.plot( tip_data['word_count'], tip_data['likes'], color = 'orange')\n",
    "plt.xlabel = \"Word Count\"\n",
    "plt.ylabel = \"Likes\"\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the Review Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = pd.read_csv(\"E:\\\\Yelp\\\\DATA\\\\review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data.head()\n",
    "review_data.shape\n",
    "review_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(review_data.cool[review_data.cool == 0].count()/review_data.shape[0] * 100)\n",
    "print(review_data.funny[review_data.funny == 0].count()/review_data.shape[0] * 100)\n",
    "print(review_data.useful[review_data.useful == 0].count()/review_data.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data.groupby(['stars']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool = pd.Series([256, 123686, 18858, 4473, 1359, 525, 466])\n",
    "useful = pd.Series([2191, 85992, 31571, 14065, 6904, 3718, 5182])\n",
    "funny = pd.Series([412, 126724, 15314, 4154, 1519, 757, 743])\n",
    "x = [0, 1, 2, 3, 4, 5,]\n",
    "width = 0.25\n",
    "plt.figure(figsize=(10, 6))\n",
    "cool.plot(kind = 'bar', width = width, color = 'blue', position = 0, label = 'Cool', rot = 0)\n",
    "useful.plot(kind = 'bar', width = width, color = 'green', position = 1, label = 'Useful', rot = 0)\n",
    "funny.plot(kind = 'bar', width = width, color = 'red', position = 2, label = 'Funny', rot = 0)\n",
    "plt.legend()\n",
    "plt.xlabel('Stars')\n",
    "plt.ylabel('Cool/Useful/Funny Count')\n",
    "\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erroneous Data:\",review_data.stars[review_data.stars > 5].count()/review_data.shape[0]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data.groupby(review_data.stars).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the User Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "user_data = pd.read_csv(\"E:\\\\Yelp\\\\DATA\\\\user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data.head()\n",
    "user_data.columns\n",
    "user_data['yelping_since'] = pd.to_datetime(user_data['yelping_since'])\n",
    "user_data['yelping_since']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data['years_on_yelp'] = pd.to_datetime(\"2018-08-06\") - pd.to_datetime(user_data['yelping_since'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data['years_on_yelp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data['years_on_yelp'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data.sort_values('years_on_yelp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data['years_on_yelp']\n",
    "user_data.drop(\"Unnamed: 0\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_count = user_data.groupby(['years_on_yelp']).sum()['review_count']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(review_count, marker = '.', color = 'blue')\n",
    "plt.xlabel(\"Days on Yelp\")\n",
    "plt.ylabel(\"Reviews Writen\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(review_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(user_data['elite'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data['friends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to evaluate feature importance using Random Forrest Classifier\n",
    "\n",
    "test_data = user_data[['cool','funny', 'review_count', 'useful']].copy()\n",
    "\n",
    "eval_data = user_data.years_on_yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#'fans', 'friends', 'name', \n",
    "X_train, X_test, y_train, y_test = train_test_split(test_data, eval_data, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=1)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(feat_labels, clf.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "# user_data = pd.read_csv(\"E:\\\\Yelp\\\\DATA\\\\user.csv\")\n",
    "# user_data['yelping_since'] = pd.to_datetime(user_data['yelping_since'])\n",
    "# user_data['years_on_yelp'] = pd.to_datetime(\"2018-08-06\") - pd.to_datetime(user_data['yelping_since'])\n",
    "# user_data.drop(\"Unnamed: 0\", inplace=True, axis=1)\n",
    "# test_data = user_data[['cool','funny', 'review_count', 'useful']].copy()\n",
    "# eval_data = user_data.average_stars\n",
    "# X_train, X_test, y_train, y_test = train_test_split(test_data, eval_data, test_size=0.4, random_state=0)\n",
    "\n",
    "# from xgboost import XGBRegressor #The library to be imported\n",
    "# model = XGBRegressor()\n",
    "# model.fit(X_train, y_train, verbose=False)\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# print(\"Mean Absolute Error : \" + str(mean_absolute_error(predictions, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>address</th>\n",
       "      <th>attributes</th>\n",
       "      <th>business_id</th>\n",
       "      <th>categories</th>\n",
       "      <th>city</th>\n",
       "      <th>hours</th>\n",
       "      <th>is_open</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>name</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1314 44 Avenue NE</td>\n",
       "      <td>{'BikeParking': 'False', 'BusinessAcceptsCredi...</td>\n",
       "      <td>Apn5Q_b6Nz61Tq4XzPdf9A</td>\n",
       "      <td>Tours, Breweries, Pizza, Restaurants, Food, Ho...</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>{'Monday': '8:30-17:0', 'Tuesday': '11:0-21:0'...</td>\n",
       "      <td>1</td>\n",
       "      <td>51.091813</td>\n",
       "      <td>-114.031675</td>\n",
       "      <td>Minhas Micro Brewery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T2E 6L6</td>\n",
       "      <td>24</td>\n",
       "      <td>4.0</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Alcohol': 'none', 'BikeParking': 'False', 'B...</td>\n",
       "      <td>AjEbIBw6ZFfln7ePHha9PA</td>\n",
       "      <td>Chicken Wings, Burgers, Caterers, Street Vendo...</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>{'Friday': '17:0-23:0', 'Saturday': '17:0-23:0...</td>\n",
       "      <td>0</td>\n",
       "      <td>35.960734</td>\n",
       "      <td>-114.939821</td>\n",
       "      <td>CK'S BBQ &amp; Catering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89002</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1335 rue Beaubien E</td>\n",
       "      <td>{'Alcohol': 'beer_and_wine', 'Ambience': \"{'ro...</td>\n",
       "      <td>O8S5hYJ1SMc8fA4QBtVujA</td>\n",
       "      <td>Breakfast &amp; Brunch, Restaurants, French, Sandw...</td>\n",
       "      <td>MontrÃ©al</td>\n",
       "      <td>{'Monday': '10:0-22:0', 'Tuesday': '10:0-22:0'...</td>\n",
       "      <td>0</td>\n",
       "      <td>45.540503</td>\n",
       "      <td>-73.599300</td>\n",
       "      <td>La Bastringue</td>\n",
       "      <td>Rosemont-La Petite-Patrie</td>\n",
       "      <td>H2G 1K7</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>QC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>211 W Monroe St</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bFzdJJ3wp3PZssNEsyU23g</td>\n",
       "      <td>Insurance, Financial Services</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>33.449999</td>\n",
       "      <td>-112.076979</td>\n",
       "      <td>Geico Insurance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85003</td>\n",
       "      <td>8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2005 Alyth Place SE</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True'}</td>\n",
       "      <td>8USyCYqpScwiNEb58Bt6CA</td>\n",
       "      <td>Home &amp; Garden, Nurseries &amp; Gardening, Shopping...</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>{'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>51.035591</td>\n",
       "      <td>-114.027366</td>\n",
       "      <td>Action Engine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>T2H 0N5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              address  \\\n",
       "0           0    1314 44 Avenue NE   \n",
       "1           1                  NaN   \n",
       "2           2  1335 rue Beaubien E   \n",
       "3           3      211 W Monroe St   \n",
       "4           4  2005 Alyth Place SE   \n",
       "\n",
       "                                          attributes             business_id  \\\n",
       "0  {'BikeParking': 'False', 'BusinessAcceptsCredi...  Apn5Q_b6Nz61Tq4XzPdf9A   \n",
       "1  {'Alcohol': 'none', 'BikeParking': 'False', 'B...  AjEbIBw6ZFfln7ePHha9PA   \n",
       "2  {'Alcohol': 'beer_and_wine', 'Ambience': \"{'ro...  O8S5hYJ1SMc8fA4QBtVujA   \n",
       "3                                                NaN  bFzdJJ3wp3PZssNEsyU23g   \n",
       "4             {'BusinessAcceptsCreditCards': 'True'}  8USyCYqpScwiNEb58Bt6CA   \n",
       "\n",
       "                                          categories       city  \\\n",
       "0  Tours, Breweries, Pizza, Restaurants, Food, Ho...    Calgary   \n",
       "1  Chicken Wings, Burgers, Caterers, Street Vendo...  Henderson   \n",
       "2  Breakfast & Brunch, Restaurants, French, Sandw...  MontrÃ©al   \n",
       "3                      Insurance, Financial Services    Phoenix   \n",
       "4  Home & Garden, Nurseries & Gardening, Shopping...    Calgary   \n",
       "\n",
       "                                               hours  is_open   latitude  \\\n",
       "0  {'Monday': '8:30-17:0', 'Tuesday': '11:0-21:0'...        1  51.091813   \n",
       "1  {'Friday': '17:0-23:0', 'Saturday': '17:0-23:0...        0  35.960734   \n",
       "2  {'Monday': '10:0-22:0', 'Tuesday': '10:0-22:0'...        0  45.540503   \n",
       "3                                                NaN        1  33.449999   \n",
       "4  {'Monday': '8:0-17:0', 'Tuesday': '8:0-17:0', ...        1  51.035591   \n",
       "\n",
       "    longitude                  name               neighborhood postal_code  \\\n",
       "0 -114.031675  Minhas Micro Brewery                        NaN     T2E 6L6   \n",
       "1 -114.939821   CK'S BBQ & Catering                        NaN       89002   \n",
       "2  -73.599300         La Bastringue  Rosemont-La Petite-Patrie     H2G 1K7   \n",
       "3 -112.076979       Geico Insurance                        NaN       85003   \n",
       "4 -114.027366         Action Engine                        NaN     T2H 0N5   \n",
       "\n",
       "   review_count  stars state  \n",
       "0            24    4.0    AB  \n",
       "1             3    4.5    NV  \n",
       "2             5    4.0    QC  \n",
       "3             8    1.5    AZ  \n",
       "4             4    2.0    AB  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"E:\\\\Yelp\\\\DATA\\\\business.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'address', 'attributes', 'business_id', 'categories',\n",
       "       'city', 'hours', 'is_open', 'latitude', 'longitude', 'name',\n",
       "       'neighborhood', 'postal_code', 'review_count', 'stars', 'state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 12)                60        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 65        \n",
      "=================================================================\n",
      "Total params: 437\n",
      "Trainable params: 437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "train = data[['review_count', 'latitude', 'longitude', 'is_open']]\n",
    "test = data[['stars']].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, test, test_size=0.4, random_state=0)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(12, activation='relu', input_shape=(4,)))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_8 to have shape (5,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-8675df81dc60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    956\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    790\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 792\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    134\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    137\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_8 to have shape (5,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75438/75438 [==============================] - 1s 13us/step\n",
      "\n",
      "acc: 0.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
